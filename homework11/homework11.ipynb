{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12135,
     "status": "ok",
     "timestamp": 1620144116857,
     "user": {
      "displayName": "Roman Zakharov",
      "photoUrl": "",
      "userId": "18255168926005506833"
     },
     "user_tz": -180
    },
    "id": "XFG0NDRu5mYQ",
    "outputId": "22120829-8a6d-417d-8ad6-6885c63b6450"
   },
   "outputs": [],
   "source": [
    "# !pip install -q tfds-nightly\n",
    "\n",
    "# # Pin matplotlib version to 3.2.2 since in the latest version\n",
    "# # transformer.ipynb fails with the following error:\n",
    "# # https://stackoverflow.com/questions/62953704/valueerror-the-number-of-fixedlocator-locations-5-usually-from-a-call-to-set\n",
    "# !pip install matplotlib==3.2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 3615,
     "status": "ok",
     "timestamp": 1620144129166,
     "user": {
      "displayName": "Roman Zakharov",
      "photoUrl": "",
      "userId": "18255168926005506833"
     },
     "user_tz": -180
    },
    "id": "JjJJyJTZYebt"
   },
   "outputs": [],
   "source": [
    "#import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import unicodedata\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "import io\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 698,
     "status": "ok",
     "timestamp": 1620144902226,
     "user": {
      "displayName": "Roman Zakharov",
      "photoUrl": "",
      "userId": "18255168926005506833"
     },
     "user_tz": -180
    },
    "id": "bcRp7VcQ5m6g"
   },
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 20000\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the file\n",
    "path_to_file = \"rus-eng\\\\rus.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(w):\n",
    "  w = w.lower().strip()\n",
    "\n",
    "  # creating a space between a word and the punctuation following it\n",
    "  # eg: \"he is a boy.\" => \"he is a boy .\"\n",
    "  # Reference:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n",
    "  w = re.sub(r\"([?.!,])\", r\" \\1 \", w)\n",
    "  w = re.sub(r'[\" \"]+', \" \", w)\n",
    "\n",
    "  # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
    "  w = re.sub(r\"[^a-zA-Zа-яА-Я?.!,']+\", \" \", w)\n",
    "\n",
    "  w = w.strip()\n",
    "\n",
    "  # adding a start and an end token to the sentence\n",
    "  # so that the model know when to start and stop predicting.\n",
    "  w = '<start> ' + w + ' <end>'\n",
    "  return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<start> i can't go . <end>\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_sentence(\"I can't go.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Remove the accents\n",
    "# 2. Clean the sentences\n",
    "# 3. Return word pairs in the format: [ENG, RUS]\n",
    "def create_dataset(path, num_examples):\n",
    "  lines = io.open(path, encoding='UTF-8').read().strip().split('\\n')\n",
    "\n",
    "  word_pairs = [[preprocess_sentence(w) for w in l.split('\\t')[:2]]  for l in lines[:num_examples]]\n",
    "\n",
    "  return zip(*word_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> doubtless there exists in this world precisely the right woman for any given man to marry and vice versa but when you consider that a human being has the opportunity of being acquainted with only a few hundred people , and out of the few hundred that there are but a dozen or less whom he knows intimately , and out of the dozen , one or two friends at most , it will easily be seen , when we remember the number of millions who inhabit this world , that probably , since the earth was created , the right man has never yet met the right woman . <end>\n",
      "<start> несомненно , для каждого мужчины в этом мире где то есть подходящая женщина , которая может стать ему женой , обратное верно и для женщин . но если учесть , что у человека может быть максимум несколько сотен знакомых , из которых лишь дюжина , а то и меньше , тех , кого он знает близко , а из этой дюжины у него один или от силы два друга , то можно легко увидеть , что с уч том миллионов живущих на земле людей , ни один подходящий мужчина , возможно , ещ не встретил подходящую женщину . <end>\n"
     ]
    }
   ],
   "source": [
    "en, ru = create_dataset(path_to_file, None)\n",
    "print(en[-1])\n",
    "print(ru[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(lang):\n",
    "  lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "      filters='')\n",
    "  lang_tokenizer.fit_on_texts(lang)\n",
    "\n",
    "  tensor = lang_tokenizer.texts_to_sequences(lang)\n",
    "\n",
    "  tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,\n",
    "                                                         padding='post')\n",
    "\n",
    "  return tensor, lang_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(path, num_examples=None):\n",
    "  # creating cleaned input, output pairs\n",
    "  targ_lang, inp_lang = create_dataset(path, num_examples)\n",
    "\n",
    "  input_tensor, inp_lang_tokenizer = tokenize(inp_lang)\n",
    "  target_tensor, targ_lang_tokenizer = tokenize(targ_lang)\n",
    "\n",
    "  return input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try experimenting with the size of that dataset\n",
    "num_examples = 100000\n",
    "input_tensor, target_tensor, inp_lang, targ_lang = load_dataset(path_to_file, num_examples)\n",
    "\n",
    "# Calculate max_length of the target tensors\n",
    "max_length_targ, max_length_inp = target_tensor.shape[1], input_tensor.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80000 80000 20000 20000\n"
     ]
    }
   ],
   "source": [
    "# Creating training and validation sets using an 80-20 split\n",
    "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
    "\n",
    "# Show length\n",
    "print(len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(lang, tensor):\n",
    "  for t in tensor:\n",
    "    if t!=0:\n",
    "      print (\"%d ----> %s\" % (t, lang.index_word[t]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Language; index to word mapping\n",
      "1 ----> <start>\n",
      "12 ----> вы\n",
      "7 ----> не\n",
      "4 ----> я\n",
      "3 ----> .\n",
      "2 ----> <end>\n",
      "\n",
      "Target Language; index to word mapping\n",
      "1 ----> <start>\n",
      "29 ----> you're\n",
      "32 ----> not\n",
      "14 ----> me\n",
      "3 ----> .\n",
      "2 ----> <end>\n"
     ]
    }
   ],
   "source": [
    "print (\"Input Language; index to word mapping\")\n",
    "convert(inp_lang, input_tensor_train[0])\n",
    "print ()\n",
    "print (\"Target Language; index to word mapping\")\n",
    "convert(targ_lang, target_tensor_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = len(input_tensor_train)\n",
    "BATCH_SIZE = 64\n",
    "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n",
    "embedding_dim = 128\n",
    "units = 512\n",
    "\n",
    "vocab_inp_size = len(inp_lang.word_index)+1\n",
    "vocab_tar_size = len(targ_lang.word_index)+1\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([64, 15]), TensorShape([64, 11]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_input_batch, example_target_batch = next(iter(dataset))\n",
    "example_input_batch.shape, example_target_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "executionInfo": {
     "elapsed": 972,
     "status": "ok",
     "timestamp": 1620144945437,
     "user": {
      "displayName": "Roman Zakharov",
      "photoUrl": "",
      "userId": "18255168926005506833"
     },
     "user_tz": -180
    },
    "id": "WhIOZjMNKujn"
   },
   "outputs": [],
   "source": [
    "def get_angles(pos, i, d_model):\n",
    "  angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
    "  return pos * angle_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "executionInfo": {
     "elapsed": 960,
     "status": "ok",
     "timestamp": 1620144947699,
     "user": {
      "displayName": "Roman Zakharov",
      "photoUrl": "",
      "userId": "18255168926005506833"
     },
     "user_tz": -180
    },
    "id": "1Rz82wEs5biZ"
   },
   "outputs": [],
   "source": [
    "def positional_encoding(position, d_model):\n",
    "  angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
    "                          np.arange(d_model)[np.newaxis, :],\n",
    "                          d_model)\n",
    "  \n",
    "  # apply sin to even indices in the array; 2i\n",
    "  angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "  \n",
    "  # apply cos to odd indices in the array; 2i+1\n",
    "  angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "    \n",
    "  pos_encoding = angle_rads[np.newaxis, ...]\n",
    "    \n",
    "  return tf.cast(pos_encoding, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 301
    },
    "executionInfo": {
     "elapsed": 1097,
     "status": "ok",
     "timestamp": 1620144953983,
     "user": {
      "displayName": "Roman Zakharov",
      "photoUrl": "",
      "userId": "18255168926005506833"
     },
     "user_tz": -180
    },
    "id": "1kLCla68EloE",
    "outputId": "b40be847-4819-44b0-fc33-af56bc5c28df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 50, 512)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pos_encoding = positional_encoding(50, 512)\n",
    "print (pos_encoding.shape)\n",
    "\n",
    "plt.pcolormesh(pos_encoding[0], cmap='RdBu')\n",
    "plt.xlabel('Depth')\n",
    "plt.xlim((0, 512))\n",
    "plt.ylabel('Position')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a_b4ou4TYqUN"
   },
   "source": [
    "## Masking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s42Uydjkv0hF"
   },
   "source": [
    "Замаскируйте все маркеры площадок в пакете последовательности. Это гарантирует, что модель не обрабатывает отступы как входные данные. Маска указывает, где присутствует значение пэда 0 : она выводит 1 в этих местах и 0 противном случае."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "executionInfo": {
     "elapsed": 1292,
     "status": "ok",
     "timestamp": 1620144964896,
     "user": {
      "displayName": "Roman Zakharov",
      "photoUrl": "",
      "userId": "18255168926005506833"
     },
     "user_tz": -180
    },
    "id": "U2i8-e1s8ti9"
   },
   "outputs": [],
   "source": [
    "def create_padding_mask(seq):\n",
    "  seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "  \n",
    "  # add extra dimensions to add the padding\n",
    "  # to the attention logits.\n",
    "  return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 927,
     "status": "ok",
     "timestamp": 1620144965202,
     "user": {
      "displayName": "Roman Zakharov",
      "photoUrl": "",
      "userId": "18255168926005506833"
     },
     "user_tz": -180
    },
    "id": "A7BYeBCNvi7n",
    "outputId": "91f881be-6317-4814-a70b-d150444c2bc9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 1, 1, 5), dtype=float32, numpy=\n",
       "array([[[[0., 0., 1., 1., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0., 0., 1., 1.]]],\n",
       "\n",
       "\n",
       "       [[[1., 1., 1., 0., 0.]]]], dtype=float32)>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.constant([[7, 6, 0, 0, 1], [1, 2, 3, 0, 0], [0, 0, 0, 4, 5]])\n",
    "create_padding_mask(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z0hzukDBgVom"
   },
   "source": [
    "Маска упреждающего просмотра используется для маскировки будущих токенов в последовательности. Другими словами, маска указывает, какие записи не следует использовать.\n",
    "\n",
    "Это означает, что для предсказания третьего слова будут использоваться только первое и второе слово. Аналогично для предсказания четвертого слова будут использоваться только первое, второе и третье слово и так далее.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "executionInfo": {
     "elapsed": 659,
     "status": "ok",
     "timestamp": 1620145003845,
     "user": {
      "displayName": "Roman Zakharov",
      "photoUrl": "",
      "userId": "18255168926005506833"
     },
     "user_tz": -180
    },
    "id": "dVxS8OPI9uI0"
   },
   "outputs": [],
   "source": [
    "def create_look_ahead_mask(size):\n",
    "  mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "  return mask  # (seq_len, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 610,
     "status": "ok",
     "timestamp": 1620145005320,
     "user": {
      "displayName": "Roman Zakharov",
      "photoUrl": "",
      "userId": "18255168926005506833"
     },
     "user_tz": -180
    },
    "id": "yxKGuXxaBeeE",
    "outputId": "e6b6bba8-63e8-404d-b114-02ac332716ea"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n",
       "array([[0., 1., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.random.uniform((1, 3))\n",
    "temp = create_look_ahead_mask(x.shape[1])\n",
    "temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xluDl5cXYy4y"
   },
   "source": [
    "## Scaled dot product attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vsxEE_-Wa1gF"
   },
   "source": [
    "<img src=\"https://www.tensorflow.org/images/tutorials/transformer/scaled_attention.png\" width=\"500\" alt=\"scaled_dot_product_attention\">\n",
    "\n",
    "Функция внимания, используемая преобразователем, принимает три входа: Q (запрос), K (ключ), V (значение). Уравнение, используемое для расчета весов внимания:\n",
    "\n",
    "\n",
    "$$\\Large{Attention(Q, K, V) = softmax_k(\\frac{QK^T}{\\sqrt{d_k}}) V} $$\n",
    "\n",
    "Внимание скалярного произведения масштабируется с коэффициентом квадратного корня из глубины. Это сделано потому, что для больших значений глубины скалярное произведение увеличивается по величине, подталкивая функцию softmax, где у него есть небольшие градиенты, что приводит к очень жесткому softmax.\n",
    "\n",
    "Например, предположим, что Q и K имеют среднее значение 0 и дисперсию 1. Их матричное умножение будет иметь среднее значение 0 и дисперсию dk . Следовательно, для масштабирования используется квадратный корень из dk (а не какое-либо другое число), потому что матрица Q и K должна иметь среднее значение 0 и дисперсию 1, и вы получите более мягкий softmax.\n",
    "\n",
    "Маска умножается на -1e9 (близко к отрицательной бесконечности). Это сделано потому, что маска суммируется с умножением масштабированной матрицы Q и K и применяется непосредственно перед softmax. Цель состоит в том, чтобы обнулить эти ячейки, и большие отрицательные входные данные для softmax близки к нулю на выходе.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "executionInfo": {
     "elapsed": 927,
     "status": "ok",
     "timestamp": 1620145034523,
     "user": {
      "displayName": "Roman Zakharov",
      "photoUrl": "",
      "userId": "18255168926005506833"
     },
     "user_tz": -180
    },
    "id": "LazzUq3bJ5SH"
   },
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(q, k, v, mask):\n",
    "  \"\"\"Calculate the attention weights.\n",
    "  q, k, v must have matching leading dimensions.\n",
    "  k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.\n",
    "  The mask has different shapes depending on its type(padding or look ahead) \n",
    "  but it must be broadcastable for addition.\n",
    "  \n",
    "  Args:\n",
    "    q: query shape == (..., seq_len_q, depth)\n",
    "    k: key shape == (..., seq_len_k, depth)\n",
    "    v: value shape == (..., seq_len_v, depth_v)\n",
    "    mask: Float tensor with shape broadcastable \n",
    "          to (..., seq_len_q, seq_len_k). Defaults to None.\n",
    "    \n",
    "  Returns:\n",
    "    output, attention_weights\n",
    "  \"\"\"\n",
    "\n",
    "  matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
    "  \n",
    "  # scale matmul_qk\n",
    "  dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "  scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "\n",
    "  # add the mask to the scaled tensor.\n",
    "  if mask is not None:\n",
    "    scaled_attention_logits += (mask * -1e9)  \n",
    "\n",
    "  # softmax is normalized on the last axis (seq_len_k) so that the scores\n",
    "  # add up to 1.\n",
    "  attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n",
    "\n",
    "  output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
    "\n",
    "  return output, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FiqETnhCkoXh"
   },
   "source": [
    "Поскольку нормализация softmax выполняется для K, его значения определяют степень важности, придаваемой Q.\n",
    "\n",
    "Выходные данные представляют собой умножение весов внимания и вектора V (значения). Это гарантирует, что слова, на которых вы хотите сосредоточиться, останутся как есть, а нерелевантные слова будут удалены.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "executionInfo": {
     "elapsed": 998,
     "status": "ok",
     "timestamp": 1620145040771,
     "user": {
      "displayName": "Roman Zakharov",
      "photoUrl": "",
      "userId": "18255168926005506833"
     },
     "user_tz": -180
    },
    "id": "n90YjClyInFy"
   },
   "outputs": [],
   "source": [
    "def print_out(q, k, v):\n",
    "  temp_out, temp_attn = scaled_dot_product_attention(\n",
    "      q, k, v, None)\n",
    "  print ('Attention weights are:')\n",
    "  print (temp_attn)\n",
    "  print ('Output is:')\n",
    "  print (temp_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2634,
     "status": "ok",
     "timestamp": 1620145050376,
     "user": {
      "displayName": "Roman Zakharov",
      "photoUrl": "",
      "userId": "18255168926005506833"
     },
     "user_tz": -180
    },
    "id": "yAzUAf2DPlNt",
    "outputId": "c9b87c52-8762-443f-f07d-a228e0ba07ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights are:\n",
      "tf.Tensor([[0. 1. 0. 0.]], shape=(1, 4), dtype=float32)\n",
      "Output is:\n",
      "tf.Tensor([[10.  0.]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "temp_k = tf.constant([[10,0,0],\n",
    "                      [0,10,0],\n",
    "                      [0,0,10],\n",
    "                      [0,0,10]], dtype=tf.float32)  # (4, 3)\n",
    "\n",
    "temp_v = tf.constant([[   1,0],\n",
    "                      [  10,0],\n",
    "                      [ 100,5],\n",
    "                      [1000,6]], dtype=tf.float32)  # (4, 2)\n",
    "\n",
    "# This `query` aligns with the second `key`,\n",
    "# so the second `value` is returned.\n",
    "temp_q = tf.constant([[0, 10, 0]], dtype=tf.float32)  # (1, 3)\n",
    "print_out(temp_q, temp_k, temp_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 778,
     "status": "ok",
     "timestamp": 1620145054804,
     "user": {
      "displayName": "Roman Zakharov",
      "photoUrl": "",
      "userId": "18255168926005506833"
     },
     "user_tz": -180
    },
    "id": "zg6k-fGhgXra",
    "outputId": "a634527e-5113-4e88-f21f-05a22dfdb09d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights are:\n",
      "tf.Tensor([[0.  0.  0.5 0.5]], shape=(1, 4), dtype=float32)\n",
      "Output is:\n",
      "tf.Tensor([[550.    5.5]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# This query aligns with a repeated key (third and fourth), \n",
    "# so all associated values get averaged.\n",
    "temp_q = tf.constant([[0, 0, 10]], dtype=tf.float32)  # (1, 3)\n",
    "print_out(temp_q, temp_k, temp_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 709,
     "status": "ok",
     "timestamp": 1620145056276,
     "user": {
      "displayName": "Roman Zakharov",
      "photoUrl": "",
      "userId": "18255168926005506833"
     },
     "user_tz": -180
    },
    "id": "UAq3YOzUgXhb",
    "outputId": "60c17003-a170-4e8d-831d-5d647fa7782d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights are:\n",
      "tf.Tensor([[0.5 0.5 0.  0. ]], shape=(1, 4), dtype=float32)\n",
      "Output is:\n",
      "tf.Tensor([[5.5 0. ]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# This query aligns equally with the first and second key, \n",
    "# so their values get averaged.\n",
    "temp_q = tf.constant([[10, 10, 0]], dtype=tf.float32)  # (1, 3)\n",
    "print_out(temp_q, temp_k, temp_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aOz-4_XIhaTP"
   },
   "source": [
    "Pass all the queries together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1372,
     "status": "ok",
     "timestamp": 1620145060436,
     "user": {
      "displayName": "Roman Zakharov",
      "photoUrl": "",
      "userId": "18255168926005506833"
     },
     "user_tz": -180
    },
    "id": "6dlU8Tm-hYrF",
    "outputId": "1751e607-a1da-433a-c2ca-12f1abaaefb0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights are:\n",
      "tf.Tensor(\n",
      "[[0.  0.  0.5 0.5]\n",
      " [0.  1.  0.  0. ]\n",
      " [0.5 0.5 0.  0. ]], shape=(3, 4), dtype=float32)\n",
      "Output is:\n",
      "tf.Tensor(\n",
      "[[550.    5.5]\n",
      " [ 10.    0. ]\n",
      " [  5.5   0. ]], shape=(3, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "temp_q = tf.constant([[0, 0, 10], [0, 10, 0], [10, 10, 0]], dtype=tf.float32)  # (3, 3)\n",
    "print_out(temp_q, temp_k, temp_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kmzGPEy64qmA"
   },
   "source": [
    "## Multi-head attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fz5BMC8Kaoqo"
   },
   "source": [
    "<img src=\"https://www.tensorflow.org/images/tutorials/transformer/multi_head_attention.png\" width=\"500\" alt=\"multi-head attention\">\n",
    "\n",
    "\n",
    "Многоголовое внимание состоит из четырех частей:\n",
    "\n",
    "* Слои линейные и разбиваются на головы.\n",
    "* Повышенное внимание к скалярному продукту\n",
    "* Конкатенация голов.\n",
    "* Финальный линейный слой."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JPmbr6F1C-v_"
   },
   "source": [
    "Каждый блок внимания с несколькими головами получает три входа; Q (запрос), K (ключ), V (значение). Они проходят через линейные (плотные) слои и разбиваются на несколько головок.\n",
    "\n",
    "scaled_dot_product_attention определенный выше, применяется к каждой голове (транслируется для эффективности). На этапе внимания необходимо использовать соответствующую маску. Затем вывод внимания для каждой головы объединяется (с использованием tf.transpose и tf.reshape ) и пропускается через последний слой Dense .\n",
    "\n",
    "Вместо одной единственной головы внимания Q, K и V разделены на несколько голов, потому что это позволяет модели совместно обращать внимание на информацию в разных положениях из разных пространств представления. После разделения каждая голова имеет уменьшенную размерность, поэтому общая стоимость вычислений такая же, как и внимание одной головы с полной размерностью.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "executionInfo": {
     "elapsed": 659,
     "status": "ok",
     "timestamp": 1620145376299,
     "user": {
      "displayName": "Roman Zakharov",
      "photoUrl": "",
      "userId": "18255168926005506833"
     },
     "user_tz": -180
    },
    "id": "BSV3PPKsYecw"
   },
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "  def __init__(self, d_model, num_heads):\n",
    "    super(MultiHeadAttention, self).__init__()\n",
    "    self.num_heads = num_heads\n",
    "    self.d_model = d_model\n",
    "    \n",
    "    assert d_model % self.num_heads == 0\n",
    "    \n",
    "    self.depth = d_model // self.num_heads\n",
    "    \n",
    "    self.wq = tf.keras.layers.Dense(d_model)\n",
    "    self.wk = tf.keras.layers.Dense(d_model)\n",
    "    self.wv = tf.keras.layers.Dense(d_model)\n",
    "    \n",
    "    self.dense = tf.keras.layers.Dense(d_model)\n",
    "        \n",
    "  def split_heads(self, x, batch_size):\n",
    "    \"\"\"Split the last dimension into (num_heads, depth).\n",
    "    Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
    "    \"\"\"\n",
    "    x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "    return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "    \n",
    "  def call(self, v, k, q, mask):\n",
    "    batch_size = tf.shape(q)[0]\n",
    "    \n",
    "    q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
    "    k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
    "    v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
    "    \n",
    "    q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
    "    k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
    "    v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
    "    \n",
    "    # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
    "    # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
    "    scaled_attention, attention_weights = scaled_dot_product_attention(\n",
    "        q, k, v, mask)\n",
    "    \n",
    "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
    "\n",
    "    concat_attention = tf.reshape(scaled_attention, \n",
    "                                  (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
    "\n",
    "    output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
    "        \n",
    "    return output, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0D8FJue5lDyZ"
   },
   "source": [
    "Создайте слой MultiHeadAttention чтобы попробовать. В каждом месте в последовательности y MultiHeadAttention запускает все 8 головок внимания по всем другим местам в последовательности, возвращая новый вектор той же длины в каждом месте.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 965,
     "status": "ok",
     "timestamp": 1620145378692,
     "user": {
      "displayName": "Roman Zakharov",
      "photoUrl": "",
      "userId": "18255168926005506833"
     },
     "user_tz": -180
    },
    "id": "Hu94p-_-2_BX",
    "outputId": "4aa4d573-3e54-4a49-f32e-211795836931"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([1, 60, 512]), TensorShape([1, 8, 60, 60]))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_mha = MultiHeadAttention(d_model=512, num_heads=8)\n",
    "y = tf.random.uniform((1, 60, 512))  # (batch_size, encoder_sequence, d_model)\n",
    "out, attn = temp_mha(y, k=y, q=y, mask=None)\n",
    "out.shape, attn.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RdDqGayx67vv"
   },
   "source": [
    "## Point wise feed forward network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gBqzJXGfHK3X"
   },
   "source": [
    "Сеть с точечной прямой связью состоит из двух полностью связанных слоев с активацией ReLU между ними.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "executionInfo": {
     "elapsed": 692,
     "status": "ok",
     "timestamp": 1620145383202,
     "user": {
      "displayName": "Roman Zakharov",
      "photoUrl": "",
      "userId": "18255168926005506833"
     },
     "user_tz": -180
    },
    "id": "ET7xLt0yCT6Z"
   },
   "outputs": [],
   "source": [
    "def point_wise_feed_forward_network(d_model, dff):\n",
    "  return tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n",
    "      tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n",
    "  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 965,
     "status": "ok",
     "timestamp": 1620145384427,
     "user": {
      "displayName": "Roman Zakharov",
      "photoUrl": "",
      "userId": "18255168926005506833"
     },
     "user_tz": -180
    },
    "id": "mytb1lPyOHLB",
    "outputId": "bb30191c-7f18-496a-e7cc-e6c9099a756a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 50, 512])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_ffn = point_wise_feed_forward_network(512, 2048)\n",
    "sample_ffn(tf.random.uniform((64, 50, 512))).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7e7hKcxn6-zd"
   },
   "source": [
    "## Encoder and decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yScbC0MUH8dS"
   },
   "source": [
    "<img src=\"https://www.tensorflow.org/images/tutorials/transformer/transformer.png\" width=\"600\" alt=\"transformer\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MfYJG-Kvgwy2"
   },
   "source": [
    "Модель трансформера следует той же общей схеме, что и стандартная последовательность действий с моделью внимания .\n",
    "\n",
    "Входное предложение проходит через N уровней кодировщика, которые генерируют выходные данные для каждого слова / токена в последовательности.\n",
    "Декодер отслеживает вывод кодировщика и свой собственный ввод (самовнимание), чтобы предсказать следующее слово.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QFv-FNYUmvpn"
   },
   "source": [
    "### Encoder layer\n",
    "\n",
    "Каждый уровень кодировщика состоит из подслоев:\n",
    "\n",
    "Многоголовое внимание (с дополнительной маской)\n",
    "Точечные сети прямого распространения.\n",
    "Каждый из этих подуровней имеет остаточную связь вокруг себя, за которой следует нормализация уровня. Остаточные соединения помогают избежать проблемы исчезающего градиента в глубоких сетях.\n",
    "\n",
    "Результатом каждого подслоя является LayerNorm(x + Sublayer(x)) . Нормализация выполняется по d_model (последняя). В трансформаторе N слоев кодировщика.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "executionInfo": {
     "elapsed": 739,
     "status": "ok",
     "timestamp": 1620145708052,
     "user": {
      "displayName": "Roman Zakharov",
      "photoUrl": "",
      "userId": "18255168926005506833"
     },
     "user_tz": -180
    },
    "id": "ncyS-Ms3i2x_"
   },
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "  def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "    super(EncoderLayer, self).__init__()\n",
    "\n",
    "    self.mha = MultiHeadAttention(d_model, num_heads)\n",
    "    self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "    \n",
    "    self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "    self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "    \n",
    "  def call(self, x, training, mask):\n",
    "\n",
    "    attn_output, _ = self.mha(x, x, x, mask)  # (batch_size, input_seq_len, d_model)\n",
    "    attn_output = self.dropout1(attn_output, training=training)\n",
    "    out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
    "    \n",
    "    ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
    "    ffn_output = self.dropout2(ffn_output, training=training)\n",
    "    out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n",
    "    \n",
    "    return out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 491,
     "status": "ok",
     "timestamp": 1620145708054,
     "user": {
      "displayName": "Roman Zakharov",
      "photoUrl": "",
      "userId": "18255168926005506833"
     },
     "user_tz": -180
    },
    "id": "AzZRXdO0mI48",
    "outputId": "d5bcbf5e-15ce-49b1-a3ba-3f73945df75a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 43, 512])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_encoder_layer = EncoderLayer(512, 8, 2048)\n",
    "\n",
    "sample_encoder_layer_output = sample_encoder_layer(\n",
    "    tf.random.uniform((64, 43, 512)), False, None)\n",
    "\n",
    "sample_encoder_layer_output.shape  # (batch_size, input_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6LO_48Owmx_o"
   },
   "source": [
    "### Decoder layer\n",
    "\n",
    "Каждый слой декодера состоит из подслоев:\n",
    "\n",
    "Замаскированное внимание с несколькими головами (с опережающей маской и дополнительной маской)\n",
    "Многоголовое внимание (с дополнительной маской). V (значение) и K (ключ) получают выходной сигнал энкодера в качестве входных данных. Q (запрос) получает выходные данные от подуровня замаскированного многоголового внимания.\n",
    "Точечные сети прямого распространения\n",
    "Каждый из этих подуровней имеет остаточную связь вокруг себя, за которой следует нормализация уровня. Результатом каждого подслоя является LayerNorm(x + Sublayer(x)) . Нормализация выполняется по d_model (последняя).\n",
    "\n",
    "В трансформаторе N слоев декодера.\n",
    "\n",
    "Поскольку Q принимает выходные данные от первого блока внимания декодера, а K принимает выходные данные кодировщика, веса внимания представляют важность, придаваемую входу декодера на основе выходных данных кодера. Другими словами, декодер предсказывает следующее слово, глядя на выходные данные кодировщика и самостоятельно присматриваясь к своим собственным выходным данным. См. Демонстрацию выше в разделе «Внимание к скалярному произведению».\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "executionInfo": {
     "elapsed": 872,
     "status": "ok",
     "timestamp": 1620145710171,
     "user": {
      "displayName": "Roman Zakharov",
      "photoUrl": "",
      "userId": "18255168926005506833"
     },
     "user_tz": -180
    },
    "id": "9SoX0-vd1hue"
   },
   "outputs": [],
   "source": [
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "  def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "    super(DecoderLayer, self).__init__()\n",
    "\n",
    "    self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
    "    self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
    "\n",
    "    self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    " \n",
    "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "    self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "    \n",
    "    self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "    self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "    self.dropout3 = tf.keras.layers.Dropout(rate)\n",
    "    \n",
    "    \n",
    "  def call(self, x, enc_output, training, \n",
    "           look_ahead_mask, padding_mask):\n",
    "    # enc_output.shape == (batch_size, input_seq_len, d_model)\n",
    "\n",
    "    attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)  # (batch_size, target_seq_len, d_model)\n",
    "    attn1 = self.dropout1(attn1, training=training)\n",
    "    out1 = self.layernorm1(attn1 + x)\n",
    "    \n",
    "    attn2, attn_weights_block2 = self.mha2(\n",
    "        enc_output, enc_output, out1, padding_mask)  # (batch_size, target_seq_len, d_model)\n",
    "    attn2 = self.dropout2(attn2, training=training)\n",
    "    out2 = self.layernorm2(attn2 + out1)  # (batch_size, target_seq_len, d_model)\n",
    "    \n",
    "    ffn_output = self.ffn(out2)  # (batch_size, target_seq_len, d_model)\n",
    "    ffn_output = self.dropout3(ffn_output, training=training)\n",
    "    out3 = self.layernorm3(ffn_output + out2)  # (batch_size, target_seq_len, d_model)\n",
    "    \n",
    "    return out3, attn_weights_block1, attn_weights_block2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 876,
     "status": "ok",
     "timestamp": 1620145719854,
     "user": {
      "displayName": "Roman Zakharov",
      "photoUrl": "",
      "userId": "18255168926005506833"
     },
     "user_tz": -180
    },
    "id": "Ne2Bqx8k71l0",
    "outputId": "a537f2ba-b617-4591-f380-e5879fa25c4c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 50, 512])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_decoder_layer = DecoderLayer(512, 8, 2048)\n",
    "\n",
    "sample_decoder_layer_output, _, _ = sample_decoder_layer(\n",
    "    tf.random.uniform((64, 50, 512)), sample_encoder_layer_output, \n",
    "    False, None, None)\n",
    "\n",
    "sample_decoder_layer_output.shape  # (batch_size, target_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SE1H51Ajm0q1"
   },
   "source": [
    "### Encoder\n",
    "\n",
    "The `Encoder` consists of:\n",
    "1.   Input Embedding\n",
    "2.   Positional Encoding\n",
    "3.   N encoder layers\n",
    "\n",
    "The input is put through an embedding which is summed with the positional encoding. The output of this summation is the input to the encoder layers. The output of the encoder is the input to the decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "executionInfo": {
     "elapsed": 724,
     "status": "ok",
     "timestamp": 1620145775500,
     "user": {
      "displayName": "Roman Zakharov",
      "photoUrl": "",
      "userId": "18255168926005506833"
     },
     "user_tz": -180
    },
    "id": "jpEox7gJ8FCI"
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "  def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n",
    "               maximum_position_encoding, rate=0.1):\n",
    "    super(Encoder, self).__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.num_layers = num_layers\n",
    "    \n",
    "    self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
    "    self.pos_encoding = positional_encoding(maximum_position_encoding, \n",
    "                                            self.d_model)\n",
    "    \n",
    "    \n",
    "    self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate) \n",
    "                       for _ in range(num_layers)]\n",
    "  \n",
    "    self.dropout = tf.keras.layers.Dropout(rate)\n",
    "        \n",
    "  def call(self, x, training, mask):\n",
    "\n",
    "    seq_len = tf.shape(x)[1]\n",
    "    \n",
    "    # adding embedding and position encoding.\n",
    "    x = self.embedding(x)  # (batch_size, input_seq_len, d_model)\n",
    "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "    x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "    x = self.dropout(x, training=training)\n",
    "    \n",
    "    for i in range(self.num_layers):\n",
    "      x = self.enc_layers[i](x, training, mask)\n",
    "    \n",
    "    return x  # (batch_size, input_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 909,
     "status": "ok",
     "timestamp": 1620145778132,
     "user": {
      "displayName": "Roman Zakharov",
      "photoUrl": "",
      "userId": "18255168926005506833"
     },
     "user_tz": -180
    },
    "id": "8QG9nueFQKXx",
    "outputId": "8fb6f2d7-b253-4b1d-922c-d3972981ca41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 62, 512)\n"
     ]
    }
   ],
   "source": [
    "sample_encoder = Encoder(num_layers=2, d_model=512, num_heads=8, \n",
    "                         dff=2048, input_vocab_size=8500,\n",
    "                         maximum_position_encoding=10000)\n",
    "temp_input = tf.random.uniform((64, 62), dtype=tf.int64, minval=0, maxval=200)\n",
    "\n",
    "sample_encoder_output = sample_encoder(temp_input, training=False, mask=None)\n",
    "\n",
    "print (sample_encoder_output.shape)  # (batch_size, input_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p-uO6ls8m2O5"
   },
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZtT7PKzrXkNr"
   },
   "source": [
    " The `Decoder` consists of:\n",
    "1.   Output Embedding\n",
    "2.   Positional Encoding\n",
    "3.   N decoder layers\n",
    "\n",
    "The target is put through an embedding which is summed with the positional encoding. The output of this summation is the input to the decoder layers. The output of the decoder is the input to the final linear layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "executionInfo": {
     "elapsed": 975,
     "status": "ok",
     "timestamp": 1620145783692,
     "user": {
      "displayName": "Roman Zakharov",
      "photoUrl": "",
      "userId": "18255168926005506833"
     },
     "user_tz": -180
    },
    "id": "d5_d5-PLQXwY"
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "  def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size,\n",
    "               maximum_position_encoding, rate=0.1):\n",
    "    super(Decoder, self).__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.num_layers = num_layers\n",
    "    \n",
    "    self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
    "    self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
    "    \n",
    "    self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate) \n",
    "                       for _ in range(num_layers)]\n",
    "    self.dropout = tf.keras.layers.Dropout(rate)\n",
    "    \n",
    "  def call(self, x, enc_output, training, \n",
    "           look_ahead_mask, padding_mask):\n",
    "\n",
    "    seq_len = tf.shape(x)[1]\n",
    "    attention_weights = {}\n",
    "    \n",
    "    x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
    "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "    x += self.pos_encoding[:, :seq_len, :]\n",
    "    \n",
    "    x = self.dropout(x, training=training)\n",
    "\n",
    "    for i in range(self.num_layers):\n",
    "      x, block1, block2 = self.dec_layers[i](x, enc_output, training,\n",
    "                                             look_ahead_mask, padding_mask)\n",
    "      \n",
    "      attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
    "      attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
    "    \n",
    "    # x.shape == (batch_size, target_seq_len, d_model)\n",
    "    return x, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 974,
     "status": "ok",
     "timestamp": 1620145798614,
     "user": {
      "displayName": "Roman Zakharov",
      "photoUrl": "",
      "userId": "18255168926005506833"
     },
     "user_tz": -180
    },
    "id": "a1jXoAMRZyvu",
    "outputId": "f8a09609-877a-4e2a-87aa-50d226afba7d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([64, 26, 512]), TensorShape([64, 8, 26, 62]))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_decoder = Decoder(num_layers=2, d_model=512, num_heads=8, \n",
    "                         dff=2048, target_vocab_size=8000,\n",
    "                         maximum_position_encoding=5000)\n",
    "temp_input = tf.random.uniform((64, 26), dtype=tf.int64, minval=0, maxval=200)\n",
    "\n",
    "output, attn = sample_decoder(temp_input, \n",
    "                              enc_output=sample_encoder_output, \n",
    "                              training=False,\n",
    "                              look_ahead_mask=None, \n",
    "                              padding_mask=None)\n",
    "\n",
    "output.shape, attn['decoder_layer2_block2'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y54xnJnuYgJ7"
   },
   "source": [
    "## Create the Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uERO1y54cOKq"
   },
   "source": [
    "Transformer consists of the encoder, decoder and a final linear layer. The output of the decoder is the input to the linear layer and its output is returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "executionInfo": {
     "elapsed": 860,
     "status": "ok",
     "timestamp": 1620145843448,
     "user": {
      "displayName": "Roman Zakharov",
      "photoUrl": "",
      "userId": "18255168926005506833"
     },
     "user_tz": -180
    },
    "id": "PED3bIpOYkBu"
   },
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "  def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, \n",
    "               target_vocab_size, pe_input, pe_target, rate=0.1):\n",
    "    super(Transformer, self).__init__()\n",
    "\n",
    "    self.encoder = Encoder(num_layers, d_model, num_heads, dff, \n",
    "                           input_vocab_size, pe_input, rate)\n",
    "\n",
    "    self.decoder = Decoder(num_layers, d_model, num_heads, dff, \n",
    "                           target_vocab_size, pe_target, rate)\n",
    "\n",
    "    self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
    "    \n",
    "  def call(self, inp, tar, training, enc_padding_mask, \n",
    "           look_ahead_mask, dec_padding_mask):\n",
    "\n",
    "    enc_output = self.encoder(inp, training, enc_padding_mask)  # (batch_size, inp_seq_len, d_model)\n",
    "    \n",
    "    # dec_output.shape == (batch_size, tar_seq_len, d_model)\n",
    "    dec_output, attention_weights = self.decoder(\n",
    "        tar, enc_output, training, look_ahead_mask, dec_padding_mask)\n",
    "    \n",
    "    final_output = self.final_layer(dec_output)  # (batch_size, tar_seq_len, target_vocab_size)\n",
    "    \n",
    "    return final_output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1127,
     "status": "ok",
     "timestamp": 1620145851329,
     "user": {
      "displayName": "Roman Zakharov",
      "photoUrl": "",
      "userId": "18255168926005506833"
     },
     "user_tz": -180
    },
    "id": "tJ4fbQcIkHW1",
    "outputId": "b260d0b1-3050-498e-cb9e-a6d9e1802fe0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 36, 8000])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_transformer = Transformer(\n",
    "    num_layers=2, d_model=512, num_heads=8, dff=2048, \n",
    "    input_vocab_size=8500, target_vocab_size=8000, \n",
    "    pe_input=10000, pe_target=6000)\n",
    "\n",
    "temp_input = tf.random.uniform((64, 38), dtype=tf.int64, minval=0, maxval=200)\n",
    "temp_target = tf.random.uniform((64, 36), dtype=tf.int64, minval=0, maxval=200)\n",
    "\n",
    "fn_out, _ = sample_transformer(temp_input, temp_target, training=False, \n",
    "                               enc_padding_mask=None, \n",
    "                               look_ahead_mask=None,\n",
    "                               dec_padding_mask=None)\n",
    "\n",
    "fn_out.shape  # (batch_size, tar_seq_len, target_vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wsINyf1VEQLC"
   },
   "source": [
    "## Set hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zVjWCxFNcgbt"
   },
   "source": [
    "To keep this example small and relatively fast, the values for *num_layers, d_model, and dff* have been reduced. \n",
    "\n",
    "The values used in the base model of transformer were; *num_layers=6*, *d_model = 512*, *dff = 2048*. See the [paper](https://arxiv.org/abs/1706.03762) for all the other versions of the transformer.\n",
    "\n",
    "Note: By changing the values below, you can get the model that achieved state of the art on many tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inp_lang, targ_lang "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20206"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(inp_lang.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "executionInfo": {
     "elapsed": 969,
     "status": "ok",
     "timestamp": 1620145865102,
     "user": {
      "displayName": "Roman Zakharov",
      "photoUrl": "",
      "userId": "18255168926005506833"
     },
     "user_tz": -180
    },
    "id": "lnJn5SLA2ahP"
   },
   "outputs": [],
   "source": [
    "num_layers = 4\n",
    "d_model = 128\n",
    "dff = 512\n",
    "num_heads = 8\n",
    "\n",
    "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n",
    "\n",
    "input_vocab_size = len(inp_lang.word_index) + 2\n",
    "target_vocab_size = len(targ_lang.word_index) + 2\n",
    "dropout_rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7149"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xYEGhEOtzn5W"
   },
   "source": [
    "## Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GOmWW--yP3zx"
   },
   "source": [
    "Use the Adam optimizer with a custom learning rate scheduler according to the formula in the [paper](https://arxiv.org/abs/1706.03762).\n",
    "\n",
    "$$\\Large{lrate = d_{model}^{-0.5} * min(step{\\_}num^{-0.5}, step{\\_}num * warmup{\\_}steps^{-1.5})}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "executionInfo": {
     "elapsed": 688,
     "status": "ok",
     "timestamp": 1620145904767,
     "user": {
      "displayName": "Roman Zakharov",
      "photoUrl": "",
      "userId": "18255168926005506833"
     },
     "user_tz": -180
    },
    "id": "iYQdOO1axwEI"
   },
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "  def __init__(self, d_model, warmup_steps=4000):\n",
    "    super(CustomSchedule, self).__init__()\n",
    "    \n",
    "    self.d_model = d_model\n",
    "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "    self.warmup_steps = warmup_steps\n",
    "    \n",
    "  def __call__(self, step):\n",
    "    arg1 = tf.math.rsqrt(step)\n",
    "    arg2 = step * (self.warmup_steps ** -1.5)\n",
    "    \n",
    "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "executionInfo": {
     "elapsed": 1136,
     "status": "ok",
     "timestamp": 1620145908522,
     "user": {
      "displayName": "Roman Zakharov",
      "photoUrl": "",
      "userId": "18255168926005506833"
     },
     "user_tz": -180
    },
    "id": "7r4scdulztRx"
   },
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(d_model)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, \n",
    "                                     epsilon=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "executionInfo": {
     "elapsed": 745,
     "status": "ok",
     "timestamp": 1620145913762,
     "user": {
      "displayName": "Roman Zakharov",
      "photoUrl": "",
      "userId": "18255168926005506833"
     },
     "user_tz": -180
    },
    "id": "f33ZCgvHpPdG",
    "outputId": "8c4adffc-6867-4625-aacc-dc3e41cd9b63"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Train Step')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp_learning_rate_schedule = CustomSchedule(d_model)\n",
    "\n",
    "plt.plot(temp_learning_rate_schedule(tf.range(40000, dtype=tf.float32)))\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.xlabel(\"Train Step\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YgkDE7hzo8r5"
   },
   "source": [
    "## Loss and metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oxGJtoDuYIHL"
   },
   "source": [
    "Since the target sequences are padded, it is important to apply a padding mask when calculating the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "executionInfo": {
     "elapsed": 1184,
     "status": "ok",
     "timestamp": 1620145934706,
     "user": {
      "displayName": "Roman Zakharov",
      "photoUrl": "",
      "userId": "18255168926005506833"
     },
     "user_tz": -180
    },
    "id": "MlhsJMm0TW_B"
   },
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "executionInfo": {
     "elapsed": 726,
     "status": "ok",
     "timestamp": 1620145936871,
     "user": {
      "displayName": "Roman Zakharov",
      "photoUrl": "",
      "userId": "18255168926005506833"
     },
     "user_tz": -180
    },
    "id": "67oqVHiT0Eiu"
   },
   "outputs": [],
   "source": [
    "def loss_function(real, pred):\n",
    "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "  loss_ = loss_object(real, pred)\n",
    "\n",
    "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "  loss_ *= mask\n",
    "  \n",
    "  return tf.reduce_sum(loss_)/tf.reduce_sum(mask)\n",
    "\n",
    "\n",
    "def accuracy_function(real, pred):\n",
    "  accuracies = tf.equal(real, tf.argmax(pred, axis=2))\n",
    "  \n",
    "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "  accuracies = tf.math.logical_and(mask, accuracies)\n",
    "\n",
    "  accuracies = tf.cast(accuracies, dtype=tf.float32)\n",
    "  mask = tf.cast(mask, dtype=tf.float32)\n",
    "  return tf.reduce_sum(accuracies)/tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "executionInfo": {
     "elapsed": 844,
     "status": "ok",
     "timestamp": 1620145942315,
     "user": {
      "displayName": "Roman Zakharov",
      "photoUrl": "",
      "userId": "18255168926005506833"
     },
     "user_tz": -180
    },
    "id": "phlyxMnm-Tpx"
   },
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "# train_accuracy = tf.keras.metrics.Mean(name='train_accuracy')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
    "    name='train_accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aeHumfr7zmMa"
   },
   "source": [
    "## Training and checkpointing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "executionInfo": {
     "elapsed": 1127,
     "status": "ok",
     "timestamp": 1620145945220,
     "user": {
      "displayName": "Roman Zakharov",
      "photoUrl": "",
      "userId": "18255168926005506833"
     },
     "user_tz": -180
    },
    "id": "UiysUa--4tOU"
   },
   "outputs": [],
   "source": [
    "transformer = Transformer(num_layers, d_model, num_heads, dff,\n",
    "                          input_vocab_size, target_vocab_size, \n",
    "                          pe_input=input_vocab_size, \n",
    "                          pe_target=target_vocab_size,\n",
    "                          rate=dropout_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "executionInfo": {
     "elapsed": 388,
     "status": "ok",
     "timestamp": 1620145946238,
     "user": {
      "displayName": "Roman Zakharov",
      "photoUrl": "",
      "userId": "18255168926005506833"
     },
     "user_tz": -180
    },
    "id": "ZOJUSB1T8GjM"
   },
   "outputs": [],
   "source": [
    "def create_masks(inp, tar):\n",
    "  # Encoder padding mask\n",
    "  enc_padding_mask = create_padding_mask(inp)\n",
    "  \n",
    "  # Used in the 2nd attention block in the decoder.\n",
    "  # This padding mask is used to mask the encoder outputs.\n",
    "  dec_padding_mask = create_padding_mask(inp)\n",
    "  \n",
    "  # Used in the 1st attention block in the decoder.\n",
    "  # It is used to pad and mask future tokens in the input received by \n",
    "  # the decoder.\n",
    "  look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
    "  dec_target_padding_mask = create_padding_mask(tar)\n",
    "  combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
    "  \n",
    "  return enc_padding_mask, combined_mask, dec_padding_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fzuf06YZp66w"
   },
   "source": [
    "Create the checkpoint path and the checkpoint manager. This will be used to save checkpoints every `n` epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "executionInfo": {
     "elapsed": 698,
     "status": "ok",
     "timestamp": 1620145951903,
     "user": {
      "displayName": "Roman Zakharov",
      "photoUrl": "",
      "userId": "18255168926005506833"
     },
     "user_tz": -180
    },
    "id": "hNhuYfllndLZ"
   },
   "outputs": [],
   "source": [
    "checkpoint_path = \"./checkpoints/train\"\n",
    "\n",
    "ckpt = tf.train.Checkpoint(transformer=transformer,\n",
    "                           optimizer=optimizer)\n",
    "\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
    "\n",
    "# if a checkpoint exists, restore the latest checkpoint.\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "  ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "  print ('Latest checkpoint restored!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Di_Yaa1gf9r"
   },
   "source": [
    "Цель делится на tar_inp и tar_real. tar_inp передается декодеру в качестве входных данных. tar_real - это тот же самый ввод, сдвинутый на 1: в каждом месте tar_input tar_real содержит следующий токен, который должен быть предсказан.\n",
    "\n",
    "Например, sentence = \"SOS Лев в джунглях спит EOS\"\n",
    "\n",
    "tar_inp = \"SOS tar_inp лев в джунглях\"\n",
    "\n",
    "tar_real = \"Лев в джунглях спит EOS\"\n",
    "\n",
    "Преобразователь - это авторегрессивная модель: он делает прогнозы по частям и использует свои выходные данные, чтобы решить, что делать дальше.\n",
    "\n",
    "Во время обучения в этом примере используется принуждение учителя (как в учебнике по созданию текста ). Принуждение учителя передает истинный результат следующему временному шагу независимо от того, что модель предсказывает на текущем временном шаге.\n",
    "\n",
    "Поскольку преобразователь предсказывает каждое слово, самовнимание позволяет ему смотреть на предыдущие слова во входной последовательности, чтобы лучше предсказать следующее слово.\n",
    "\n",
    "Чтобы модель не просматривала ожидаемый результат, в модели используется маска просмотра вперед.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "executionInfo": {
     "elapsed": 688,
     "status": "ok",
     "timestamp": 1620146341654,
     "user": {
      "displayName": "Roman Zakharov",
      "photoUrl": "",
      "userId": "18255168926005506833"
     },
     "user_tz": -180
    },
    "id": "LKpoA6q1sJFj"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "executionInfo": {
     "elapsed": 777,
     "status": "ok",
     "timestamp": 1620146343318,
     "user": {
      "displayName": "Roman Zakharov",
      "photoUrl": "",
      "userId": "18255168926005506833"
     },
     "user_tz": -180
    },
    "id": "iJwmp9OE29oj"
   },
   "outputs": [],
   "source": [
    "# The @tf.function trace-compiles train_step into a TF graph for faster\n",
    "# execution. The function specializes to the precise shape of the argument\n",
    "# tensors. To avoid re-tracing due to the variable sequence lengths or variable\n",
    "# batch sizes (the last batch is smaller), use input_signature to specify\n",
    "# more generic shapes.\n",
    "\n",
    "train_step_signature = [\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int32),\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int32),\n",
    "]\n",
    "\n",
    "@tf.function(input_signature=train_step_signature)\n",
    "def train_step(inp, tar):\n",
    "  tar_inp = tar[:, :-1]\n",
    "  tar_real = tar[:, 1:]\n",
    "  \n",
    "  enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n",
    "  \n",
    "  with tf.GradientTape() as tape:\n",
    "    predictions, _ = transformer(inp, tar_inp, \n",
    "                                 True, \n",
    "                                 enc_padding_mask, \n",
    "                                 combined_mask, \n",
    "                                 dec_padding_mask)\n",
    "    loss = loss_function(tar_real, predictions)\n",
    "\n",
    "  gradients = tape.gradient(loss, transformer.trainable_variables)    \n",
    "  optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
    "  \n",
    "  train_loss(loss)\n",
    "  train_accuracy(tar_real, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inp.shape, tar.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qM2PDWGDJ_8V"
   },
   "source": [
    "Ru is used as the input language and English is the target language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1151206,
     "status": "ok",
     "timestamp": 1620147496303,
     "user": {
      "displayName": "Roman Zakharov",
      "photoUrl": "",
      "userId": "18255168926005506833"
     },
     "user_tz": -180
    },
    "id": "bbvmaKNiznHZ",
    "outputId": "a9fd937b-43e0-426e-8565-f640bf934653"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 8.8735 Accuracy 0.0000\n",
      "Epoch 1 Batch 50 Loss 8.7565 Accuracy 0.0318\n",
      "Epoch 1 Batch 100 Loss 8.5803 Accuracy 0.0653\n",
      "Epoch 1 Batch 150 Loss 8.4105 Accuracy 0.0774\n",
      "Epoch 1 Batch 200 Loss 8.2155 Accuracy 0.0849\n",
      "Epoch 1 Batch 250 Loss 7.9783 Accuracy 0.1028\n",
      "Epoch 1 Batch 300 Loss 7.7102 Accuracy 0.1160\n",
      "Epoch 1 Batch 350 Loss 7.4278 Accuracy 0.1255\n",
      "Epoch 1 Batch 400 Loss 7.1507 Accuracy 0.1331\n",
      "Epoch 1 Batch 450 Loss 6.8870 Accuracy 0.1417\n",
      "Epoch 1 Batch 500 Loss 6.6449 Accuracy 0.1505\n",
      "Epoch 1 Batch 550 Loss 6.4220 Accuracy 0.1585\n",
      "Epoch 1 Batch 600 Loss 6.2172 Accuracy 0.1659\n",
      "Epoch 1 Batch 650 Loss 6.0309 Accuracy 0.1724\n",
      "Epoch 1 Batch 700 Loss 5.8609 Accuracy 0.1784\n",
      "Epoch 1 Batch 750 Loss 5.7047 Accuracy 0.1840\n",
      "Epoch 1 Batch 800 Loss 5.5615 Accuracy 0.1893\n",
      "Epoch 1 Batch 850 Loss 5.4288 Accuracy 0.1944\n",
      "Epoch 1 Batch 900 Loss 5.3074 Accuracy 0.1991\n",
      "Epoch 1 Batch 950 Loss 5.1945 Accuracy 0.2036\n",
      "Epoch 1 Batch 1000 Loss 5.0883 Accuracy 0.2079\n",
      "Epoch 1 Batch 1050 Loss 4.9891 Accuracy 0.2120\n",
      "Epoch 1 Batch 1100 Loss 4.8965 Accuracy 0.2158\n",
      "Epoch 1 Batch 1150 Loss 4.8092 Accuracy 0.2195\n",
      "Epoch 1 Batch 1200 Loss 4.7275 Accuracy 0.2231\n",
      "Epoch 1 Loss 4.6520 Accuracy 0.2263\n",
      "Time taken for 1 epoch: 117.4274218082428 secs\n",
      "\n",
      "Epoch 2 Batch 0 Loss 2.7025 Accuracy 0.3172\n",
      "Epoch 2 Batch 50 Loss 2.7068 Accuracy 0.3103\n",
      "Epoch 2 Batch 100 Loss 2.6806 Accuracy 0.3121\n",
      "Epoch 2 Batch 150 Loss 2.6589 Accuracy 0.3132\n",
      "Epoch 2 Batch 200 Loss 2.6429 Accuracy 0.3144\n",
      "Epoch 2 Batch 250 Loss 2.6268 Accuracy 0.3160\n",
      "Epoch 2 Batch 300 Loss 2.6102 Accuracy 0.3178\n",
      "Epoch 2 Batch 350 Loss 2.5916 Accuracy 0.3190\n",
      "Epoch 2 Batch 400 Loss 2.5743 Accuracy 0.3203\n",
      "Epoch 2 Batch 450 Loss 2.5579 Accuracy 0.3220\n",
      "Epoch 2 Batch 500 Loss 2.5388 Accuracy 0.3237\n",
      "Epoch 2 Batch 550 Loss 2.5263 Accuracy 0.3247\n",
      "Epoch 2 Batch 600 Loss 2.5090 Accuracy 0.3260\n",
      "Epoch 2 Batch 650 Loss 2.4925 Accuracy 0.3273\n",
      "Epoch 2 Batch 700 Loss 2.4774 Accuracy 0.3288\n",
      "Epoch 2 Batch 750 Loss 2.4618 Accuracy 0.3301\n",
      "Epoch 2 Batch 800 Loss 2.4482 Accuracy 0.3313\n",
      "Epoch 2 Batch 850 Loss 2.4334 Accuracy 0.3326\n",
      "Epoch 2 Batch 900 Loss 2.4190 Accuracy 0.3338\n",
      "Epoch 2 Batch 950 Loss 2.4042 Accuracy 0.3350\n",
      "Epoch 2 Batch 1000 Loss 2.3917 Accuracy 0.3360\n",
      "Epoch 2 Batch 1050 Loss 2.3785 Accuracy 0.3372\n",
      "Epoch 2 Batch 1100 Loss 2.3654 Accuracy 0.3382\n",
      "Epoch 2 Batch 1150 Loss 2.3527 Accuracy 0.3391\n",
      "Epoch 2 Batch 1200 Loss 2.3410 Accuracy 0.3400\n",
      "Epoch 2 Loss 2.3278 Accuracy 0.3412\n",
      "Time taken for 1 epoch: 104.21847295761108 secs\n",
      "\n",
      "Epoch 3 Batch 0 Loss 2.0443 Accuracy 0.3672\n",
      "Epoch 3 Batch 50 Loss 1.9051 Accuracy 0.3743\n",
      "Epoch 3 Batch 100 Loss 1.9029 Accuracy 0.3735\n",
      "Epoch 3 Batch 150 Loss 1.8949 Accuracy 0.3751\n",
      "Epoch 3 Batch 200 Loss 1.8897 Accuracy 0.3756\n",
      "Epoch 3 Batch 250 Loss 1.8813 Accuracy 0.3764\n",
      "Epoch 3 Batch 300 Loss 1.8752 Accuracy 0.3768\n",
      "Epoch 3 Batch 350 Loss 1.8670 Accuracy 0.3775\n",
      "Epoch 3 Batch 400 Loss 1.8577 Accuracy 0.3784\n",
      "Epoch 3 Batch 450 Loss 1.8495 Accuracy 0.3789\n",
      "Epoch 3 Batch 500 Loss 1.8436 Accuracy 0.3795\n",
      "Epoch 3 Batch 550 Loss 1.8353 Accuracy 0.3802\n",
      "Epoch 3 Batch 600 Loss 1.8256 Accuracy 0.3813\n",
      "Epoch 3 Batch 650 Loss 1.8146 Accuracy 0.3825\n",
      "Epoch 3 Batch 700 Loss 1.8053 Accuracy 0.3834\n",
      "Epoch 3 Batch 750 Loss 1.7971 Accuracy 0.3845\n",
      "Epoch 3 Batch 800 Loss 1.7885 Accuracy 0.3855\n",
      "Epoch 3 Batch 850 Loss 1.7782 Accuracy 0.3867\n",
      "Epoch 3 Batch 900 Loss 1.7687 Accuracy 0.3878\n",
      "Epoch 3 Batch 950 Loss 1.7582 Accuracy 0.3890\n",
      "Epoch 3 Batch 1000 Loss 1.7477 Accuracy 0.3900\n",
      "Epoch 3 Batch 1050 Loss 1.7372 Accuracy 0.3911\n",
      "Epoch 3 Batch 1100 Loss 1.7277 Accuracy 0.3922\n",
      "Epoch 3 Batch 1150 Loss 1.7171 Accuracy 0.3933\n",
      "Epoch 3 Batch 1200 Loss 1.7081 Accuracy 0.3943\n",
      "Epoch 3 Loss 1.6975 Accuracy 0.3954\n",
      "Time taken for 1 epoch: 103.42106318473816 secs\n",
      "\n",
      "Epoch 4 Batch 0 Loss 1.2973 Accuracy 0.4250\n",
      "Epoch 4 Batch 50 Loss 1.3266 Accuracy 0.4287\n",
      "Epoch 4 Batch 100 Loss 1.3297 Accuracy 0.4289\n",
      "Epoch 4 Batch 150 Loss 1.3317 Accuracy 0.4287\n",
      "Epoch 4 Batch 200 Loss 1.3343 Accuracy 0.4287\n",
      "Epoch 4 Batch 250 Loss 1.3325 Accuracy 0.4290\n",
      "Epoch 4 Batch 300 Loss 1.3361 Accuracy 0.4291\n",
      "Epoch 4 Batch 350 Loss 1.3314 Accuracy 0.4298\n",
      "Epoch 4 Batch 400 Loss 1.3278 Accuracy 0.4303\n",
      "Epoch 4 Batch 450 Loss 1.3238 Accuracy 0.4309\n",
      "Epoch 4 Batch 500 Loss 1.3210 Accuracy 0.4313\n",
      "Epoch 4 Batch 550 Loss 1.3146 Accuracy 0.4320\n",
      "Epoch 4 Batch 600 Loss 1.3099 Accuracy 0.4325\n",
      "Epoch 4 Batch 650 Loss 1.3035 Accuracy 0.4333\n",
      "Epoch 4 Batch 700 Loss 1.3015 Accuracy 0.4335\n",
      "Epoch 4 Batch 750 Loss 1.2973 Accuracy 0.4340\n",
      "Epoch 4 Batch 800 Loss 1.2925 Accuracy 0.4348\n",
      "Epoch 4 Batch 850 Loss 1.2886 Accuracy 0.4352\n",
      "Epoch 4 Batch 900 Loss 1.2843 Accuracy 0.4358\n",
      "Epoch 4 Batch 950 Loss 1.2793 Accuracy 0.4365\n",
      "Epoch 4 Batch 1000 Loss 1.2737 Accuracy 0.4373\n",
      "Epoch 4 Batch 1050 Loss 1.2708 Accuracy 0.4377\n",
      "Epoch 4 Batch 1100 Loss 1.2671 Accuracy 0.4380\n",
      "Epoch 4 Batch 1150 Loss 1.2637 Accuracy 0.4385\n",
      "Epoch 4 Batch 1200 Loss 1.2603 Accuracy 0.4390\n",
      "Epoch 4 Loss 1.2560 Accuracy 0.4395\n",
      "Time taken for 1 epoch: 103.60748291015625 secs\n",
      "\n",
      "Epoch 5 Batch 0 Loss 1.0570 Accuracy 0.4656\n",
      "Epoch 5 Batch 50 Loss 0.9836 Accuracy 0.4621\n",
      "Epoch 5 Batch 100 Loss 0.9839 Accuracy 0.4631\n",
      "Epoch 5 Batch 150 Loss 0.9883 Accuracy 0.4627\n",
      "Epoch 5 Batch 200 Loss 0.9952 Accuracy 0.4629\n",
      "Epoch 5 Batch 250 Loss 0.9997 Accuracy 0.4634\n",
      "Epoch 5 Batch 300 Loss 1.0013 Accuracy 0.4633\n",
      "Epoch 5 Batch 350 Loss 1.0026 Accuracy 0.4632\n",
      "Epoch 5 Batch 400 Loss 1.0020 Accuracy 0.4637\n",
      "Epoch 5 Batch 450 Loss 1.0039 Accuracy 0.4640\n",
      "Epoch 5 Batch 500 Loss 1.0003 Accuracy 0.4643\n",
      "Epoch 5 Batch 550 Loss 1.0001 Accuracy 0.4646\n",
      "Epoch 5 Batch 600 Loss 1.0012 Accuracy 0.4647\n",
      "Epoch 5 Batch 650 Loss 1.0011 Accuracy 0.4649\n",
      "Epoch 5 Batch 700 Loss 0.9990 Accuracy 0.4651\n",
      "Epoch 5 Batch 750 Loss 1.0001 Accuracy 0.4651\n",
      "Epoch 5 Batch 800 Loss 0.9990 Accuracy 0.4652\n",
      "Epoch 5 Batch 850 Loss 0.9995 Accuracy 0.4651\n",
      "Epoch 5 Batch 900 Loss 1.0000 Accuracy 0.4652\n",
      "Epoch 5 Batch 950 Loss 0.9999 Accuracy 0.4653\n",
      "Epoch 5 Batch 1000 Loss 0.9995 Accuracy 0.4654\n",
      "Epoch 5 Batch 1050 Loss 0.9987 Accuracy 0.4654\n",
      "Epoch 5 Batch 1100 Loss 0.9992 Accuracy 0.4655\n",
      "Epoch 5 Batch 1150 Loss 0.9995 Accuracy 0.4655\n",
      "Epoch 5 Batch 1200 Loss 0.9968 Accuracy 0.4659\n",
      "Saving checkpoint for epoch 5 at ./checkpoints/train\\ckpt-1\n",
      "Epoch 5 Loss 0.9958 Accuracy 0.4661\n",
      "Time taken for 1 epoch: 104.14616250991821 secs\n",
      "\n",
      "Epoch 6 Batch 0 Loss 0.7256 Accuracy 0.4875\n",
      "Epoch 6 Batch 50 Loss 0.8227 Accuracy 0.4794\n",
      "Epoch 6 Batch 100 Loss 0.8394 Accuracy 0.4786\n",
      "Epoch 6 Batch 150 Loss 0.8372 Accuracy 0.4797\n",
      "Epoch 6 Batch 200 Loss 0.8488 Accuracy 0.4787\n",
      "Epoch 6 Batch 250 Loss 0.8494 Accuracy 0.4793\n",
      "Epoch 6 Batch 300 Loss 0.8484 Accuracy 0.4797\n",
      "Epoch 6 Batch 350 Loss 0.8470 Accuracy 0.4799\n",
      "Epoch 6 Batch 400 Loss 0.8483 Accuracy 0.4798\n",
      "Epoch 6 Batch 450 Loss 0.8500 Accuracy 0.4796\n",
      "Epoch 6 Batch 500 Loss 0.8529 Accuracy 0.4795\n",
      "Epoch 6 Batch 550 Loss 0.8539 Accuracy 0.4799\n",
      "Epoch 6 Batch 600 Loss 0.8521 Accuracy 0.4803\n",
      "Epoch 6 Batch 650 Loss 0.8533 Accuracy 0.4804\n",
      "Epoch 6 Batch 700 Loss 0.8513 Accuracy 0.4807\n",
      "Epoch 6 Batch 750 Loss 0.8519 Accuracy 0.4811\n",
      "Epoch 6 Batch 800 Loss 0.8526 Accuracy 0.4810\n",
      "Epoch 6 Batch 850 Loss 0.8530 Accuracy 0.4810\n",
      "Epoch 6 Batch 900 Loss 0.8531 Accuracy 0.4809\n",
      "Epoch 6 Batch 950 Loss 0.8541 Accuracy 0.4810\n",
      "Epoch 6 Batch 1000 Loss 0.8545 Accuracy 0.4811\n",
      "Epoch 6 Batch 1050 Loss 0.8540 Accuracy 0.4811\n",
      "Epoch 6 Batch 1100 Loss 0.8546 Accuracy 0.4811\n",
      "Epoch 6 Batch 1150 Loss 0.8526 Accuracy 0.4813\n",
      "Epoch 6 Batch 1200 Loss 0.8533 Accuracy 0.4813\n",
      "Epoch 6 Loss 0.8539 Accuracy 0.4814\n",
      "Time taken for 1 epoch: 103.39574003219604 secs\n",
      "\n",
      "Epoch 7 Batch 0 Loss 0.7719 Accuracy 0.4969\n",
      "Epoch 7 Batch 50 Loss 0.7061 Accuracy 0.4945\n",
      "Epoch 7 Batch 100 Loss 0.7106 Accuracy 0.4949\n",
      "Epoch 7 Batch 150 Loss 0.7213 Accuracy 0.4936\n",
      "Epoch 7 Batch 200 Loss 0.7302 Accuracy 0.4932\n",
      "Epoch 7 Batch 250 Loss 0.7337 Accuracy 0.4927\n",
      "Epoch 7 Batch 300 Loss 0.7366 Accuracy 0.4929\n",
      "Epoch 7 Batch 350 Loss 0.7399 Accuracy 0.4922\n",
      "Epoch 7 Batch 400 Loss 0.7420 Accuracy 0.4924\n",
      "Epoch 7 Batch 450 Loss 0.7441 Accuracy 0.4921\n",
      "Epoch 7 Batch 500 Loss 0.7455 Accuracy 0.4920\n",
      "Epoch 7 Batch 550 Loss 0.7485 Accuracy 0.4916\n",
      "Epoch 7 Batch 600 Loss 0.7478 Accuracy 0.4916\n",
      "Epoch 7 Batch 650 Loss 0.7512 Accuracy 0.4914\n",
      "Epoch 7 Batch 700 Loss 0.7523 Accuracy 0.4912\n",
      "Epoch 7 Batch 750 Loss 0.7534 Accuracy 0.4913\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 Batch 800 Loss 0.7532 Accuracy 0.4913\n",
      "Epoch 7 Batch 850 Loss 0.7550 Accuracy 0.4912\n",
      "Epoch 7 Batch 900 Loss 0.7550 Accuracy 0.4914\n",
      "Epoch 7 Batch 950 Loss 0.7575 Accuracy 0.4912\n",
      "Epoch 7 Batch 1000 Loss 0.7576 Accuracy 0.4914\n",
      "Epoch 7 Batch 1050 Loss 0.7586 Accuracy 0.4913\n",
      "Epoch 7 Batch 1100 Loss 0.7588 Accuracy 0.4912\n",
      "Epoch 7 Batch 1150 Loss 0.7592 Accuracy 0.4912\n",
      "Epoch 7 Batch 1200 Loss 0.7591 Accuracy 0.4914\n",
      "Epoch 7 Loss 0.7597 Accuracy 0.4914\n",
      "Time taken for 1 epoch: 103.4976909160614 secs\n",
      "\n",
      "Epoch 8 Batch 0 Loss 0.7509 Accuracy 0.4969\n",
      "Epoch 8 Batch 50 Loss 0.6395 Accuracy 0.5027\n",
      "Epoch 8 Batch 100 Loss 0.6371 Accuracy 0.5033\n",
      "Epoch 8 Batch 150 Loss 0.6518 Accuracy 0.5010\n",
      "Epoch 8 Batch 200 Loss 0.6537 Accuracy 0.5006\n",
      "Epoch 8 Batch 250 Loss 0.6578 Accuracy 0.5006\n",
      "Epoch 8 Batch 300 Loss 0.6621 Accuracy 0.5006\n",
      "Epoch 8 Batch 350 Loss 0.6654 Accuracy 0.5005\n",
      "Epoch 8 Batch 400 Loss 0.6651 Accuracy 0.5000\n",
      "Epoch 8 Batch 450 Loss 0.6682 Accuracy 0.4999\n",
      "Epoch 8 Batch 500 Loss 0.6720 Accuracy 0.4995\n",
      "Epoch 8 Batch 550 Loss 0.6736 Accuracy 0.4993\n",
      "Epoch 8 Batch 600 Loss 0.6759 Accuracy 0.4992\n",
      "Epoch 8 Batch 650 Loss 0.6774 Accuracy 0.4992\n",
      "Epoch 8 Batch 700 Loss 0.6797 Accuracy 0.4991\n",
      "Epoch 8 Batch 750 Loss 0.6807 Accuracy 0.4993\n",
      "Epoch 8 Batch 800 Loss 0.6813 Accuracy 0.4991\n",
      "Epoch 8 Batch 850 Loss 0.6828 Accuracy 0.4991\n",
      "Epoch 8 Batch 900 Loss 0.6843 Accuracy 0.4992\n",
      "Epoch 8 Batch 950 Loss 0.6858 Accuracy 0.4990\n",
      "Epoch 8 Batch 1000 Loss 0.6875 Accuracy 0.4989\n",
      "Epoch 8 Batch 1050 Loss 0.6899 Accuracy 0.4988\n",
      "Epoch 8 Batch 1100 Loss 0.6908 Accuracy 0.4987\n",
      "Epoch 8 Batch 1150 Loss 0.6934 Accuracy 0.4986\n",
      "Epoch 8 Batch 1200 Loss 0.6951 Accuracy 0.4983\n",
      "Epoch 8 Loss 0.6964 Accuracy 0.4982\n",
      "Time taken for 1 epoch: 103.4454984664917 secs\n",
      "\n",
      "Epoch 9 Batch 0 Loss 0.5628 Accuracy 0.5203\n",
      "Epoch 9 Batch 50 Loss 0.6125 Accuracy 0.5097\n",
      "Epoch 9 Batch 100 Loss 0.6040 Accuracy 0.5096\n",
      "Epoch 9 Batch 150 Loss 0.6103 Accuracy 0.5084\n",
      "Epoch 9 Batch 200 Loss 0.6087 Accuracy 0.5079\n",
      "Epoch 9 Batch 250 Loss 0.6123 Accuracy 0.5070\n",
      "Epoch 9 Batch 300 Loss 0.6132 Accuracy 0.5065\n",
      "Epoch 9 Batch 350 Loss 0.6123 Accuracy 0.5064\n",
      "Epoch 9 Batch 400 Loss 0.6157 Accuracy 0.5061\n",
      "Epoch 9 Batch 450 Loss 0.6170 Accuracy 0.5058\n",
      "Epoch 9 Batch 500 Loss 0.6172 Accuracy 0.5062\n",
      "Epoch 9 Batch 550 Loss 0.6185 Accuracy 0.5061\n",
      "Epoch 9 Batch 600 Loss 0.6229 Accuracy 0.5058\n",
      "Epoch 9 Batch 650 Loss 0.6253 Accuracy 0.5057\n",
      "Epoch 9 Batch 700 Loss 0.6262 Accuracy 0.5056\n",
      "Epoch 9 Batch 750 Loss 0.6295 Accuracy 0.5054\n",
      "Epoch 9 Batch 800 Loss 0.6313 Accuracy 0.5053\n",
      "Epoch 9 Batch 850 Loss 0.6328 Accuracy 0.5051\n",
      "Epoch 9 Batch 900 Loss 0.6346 Accuracy 0.5050\n",
      "Epoch 9 Batch 950 Loss 0.6360 Accuracy 0.5048\n",
      "Epoch 9 Batch 1000 Loss 0.6371 Accuracy 0.5047\n",
      "Epoch 9 Batch 1050 Loss 0.6389 Accuracy 0.5046\n",
      "Epoch 9 Batch 1100 Loss 0.6399 Accuracy 0.5045\n",
      "Epoch 9 Batch 1150 Loss 0.6413 Accuracy 0.5044\n",
      "Epoch 9 Batch 1200 Loss 0.6436 Accuracy 0.5043\n",
      "Epoch 9 Loss 0.6448 Accuracy 0.5041\n",
      "Time taken for 1 epoch: 103.282381772995 secs\n",
      "\n",
      "Epoch 10 Batch 0 Loss 0.5059 Accuracy 0.5219\n",
      "Epoch 10 Batch 50 Loss 0.5512 Accuracy 0.5142\n",
      "Epoch 10 Batch 100 Loss 0.5581 Accuracy 0.5117\n",
      "Epoch 10 Batch 150 Loss 0.5595 Accuracy 0.5116\n",
      "Epoch 10 Batch 200 Loss 0.5655 Accuracy 0.5113\n",
      "Epoch 10 Batch 250 Loss 0.5711 Accuracy 0.5111\n",
      "Epoch 10 Batch 300 Loss 0.5743 Accuracy 0.5108\n",
      "Epoch 10 Batch 350 Loss 0.5775 Accuracy 0.5104\n",
      "Epoch 10 Batch 400 Loss 0.5761 Accuracy 0.5106\n",
      "Epoch 10 Batch 450 Loss 0.5775 Accuracy 0.5105\n",
      "Epoch 10 Batch 500 Loss 0.5817 Accuracy 0.5103\n",
      "Epoch 10 Batch 550 Loss 0.5834 Accuracy 0.5102\n",
      "Epoch 10 Batch 600 Loss 0.5855 Accuracy 0.5101\n",
      "Epoch 10 Batch 650 Loss 0.5875 Accuracy 0.5098\n",
      "Epoch 10 Batch 700 Loss 0.5913 Accuracy 0.5096\n",
      "Epoch 10 Batch 750 Loss 0.5947 Accuracy 0.5093\n",
      "Epoch 10 Batch 800 Loss 0.5959 Accuracy 0.5092\n",
      "Epoch 10 Batch 850 Loss 0.5972 Accuracy 0.5092\n",
      "Epoch 10 Batch 900 Loss 0.5983 Accuracy 0.5091\n",
      "Epoch 10 Batch 950 Loss 0.5987 Accuracy 0.5091\n",
      "Epoch 10 Batch 1000 Loss 0.6007 Accuracy 0.5090\n",
      "Epoch 10 Batch 1050 Loss 0.6016 Accuracy 0.5089\n",
      "Epoch 10 Batch 1100 Loss 0.6032 Accuracy 0.5088\n",
      "Epoch 10 Batch 1150 Loss 0.6057 Accuracy 0.5086\n",
      "Epoch 10 Batch 1200 Loss 0.6061 Accuracy 0.5086\n",
      "Saving checkpoint for epoch 10 at ./checkpoints/train\\ckpt-2\n",
      "Epoch 10 Loss 0.6065 Accuracy 0.5086\n",
      "Time taken for 1 epoch: 103.7632577419281 secs\n",
      "\n",
      "Epoch 11 Batch 0 Loss 0.5138 Accuracy 0.5063\n",
      "Epoch 11 Batch 50 Loss 0.5196 Accuracy 0.5159\n",
      "Epoch 11 Batch 100 Loss 0.5207 Accuracy 0.5166\n",
      "Epoch 11 Batch 150 Loss 0.5289 Accuracy 0.5150\n",
      "Epoch 11 Batch 200 Loss 0.5349 Accuracy 0.5158\n",
      "Epoch 11 Batch 250 Loss 0.5365 Accuracy 0.5155\n",
      "Epoch 11 Batch 300 Loss 0.5429 Accuracy 0.5152\n",
      "Epoch 11 Batch 350 Loss 0.5446 Accuracy 0.5151\n",
      "Epoch 11 Batch 400 Loss 0.5499 Accuracy 0.5147\n",
      "Epoch 11 Batch 450 Loss 0.5519 Accuracy 0.5142\n",
      "Epoch 11 Batch 500 Loss 0.5526 Accuracy 0.5137\n",
      "Epoch 11 Batch 550 Loss 0.5541 Accuracy 0.5136\n",
      "Epoch 11 Batch 600 Loss 0.5552 Accuracy 0.5137\n",
      "Epoch 11 Batch 650 Loss 0.5582 Accuracy 0.5134\n",
      "Epoch 11 Batch 700 Loss 0.5598 Accuracy 0.5135\n",
      "Epoch 11 Batch 750 Loss 0.5602 Accuracy 0.5135\n",
      "Epoch 11 Batch 800 Loss 0.5624 Accuracy 0.5134\n",
      "Epoch 11 Batch 850 Loss 0.5655 Accuracy 0.5130\n",
      "Epoch 11 Batch 900 Loss 0.5669 Accuracy 0.5129\n",
      "Epoch 11 Batch 950 Loss 0.5691 Accuracy 0.5126\n",
      "Epoch 11 Batch 1000 Loss 0.5715 Accuracy 0.5125\n",
      "Epoch 11 Batch 1050 Loss 0.5724 Accuracy 0.5123\n",
      "Epoch 11 Batch 1100 Loss 0.5738 Accuracy 0.5121\n",
      "Epoch 11 Batch 1150 Loss 0.5742 Accuracy 0.5121\n",
      "Epoch 11 Batch 1200 Loss 0.5748 Accuracy 0.5121\n",
      "Epoch 11 Loss 0.5771 Accuracy 0.5119\n",
      "Time taken for 1 epoch: 103.10784459114075 secs\n",
      "\n",
      "Epoch 12 Batch 0 Loss 0.4740 Accuracy 0.5266\n",
      "Epoch 12 Batch 50 Loss 0.4919 Accuracy 0.5194\n",
      "Epoch 12 Batch 100 Loss 0.4903 Accuracy 0.5199\n",
      "Epoch 12 Batch 150 Loss 0.4920 Accuracy 0.5198\n",
      "Epoch 12 Batch 200 Loss 0.4982 Accuracy 0.5190\n",
      "Epoch 12 Batch 250 Loss 0.5020 Accuracy 0.5179\n",
      "Epoch 12 Batch 300 Loss 0.5093 Accuracy 0.5174\n",
      "Epoch 12 Batch 350 Loss 0.5126 Accuracy 0.5174\n",
      "Epoch 12 Batch 400 Loss 0.5137 Accuracy 0.5174\n",
      "Epoch 12 Batch 450 Loss 0.5165 Accuracy 0.5173\n",
      "Epoch 12 Batch 500 Loss 0.5223 Accuracy 0.5170\n",
      "Epoch 12 Batch 550 Loss 0.5270 Accuracy 0.5166\n",
      "Epoch 12 Batch 600 Loss 0.5290 Accuracy 0.5165\n",
      "Epoch 12 Batch 650 Loss 0.5296 Accuracy 0.5166\n",
      "Epoch 12 Batch 700 Loss 0.5317 Accuracy 0.5165\n",
      "Epoch 12 Batch 750 Loss 0.5333 Accuracy 0.5162\n",
      "Epoch 12 Batch 800 Loss 0.5367 Accuracy 0.5160\n",
      "Epoch 12 Batch 850 Loss 0.5386 Accuracy 0.5159\n",
      "Epoch 12 Batch 900 Loss 0.5399 Accuracy 0.5158\n",
      "Epoch 12 Batch 950 Loss 0.5422 Accuracy 0.5156\n",
      "Epoch 12 Batch 1000 Loss 0.5441 Accuracy 0.5154\n",
      "Epoch 12 Batch 1050 Loss 0.5459 Accuracy 0.5153\n",
      "Epoch 12 Batch 1100 Loss 0.5475 Accuracy 0.5153\n",
      "Epoch 12 Batch 1150 Loss 0.5487 Accuracy 0.5152\n",
      "Epoch 12 Batch 1200 Loss 0.5504 Accuracy 0.5150\n",
      "Epoch 12 Loss 0.5515 Accuracy 0.5150\n",
      "Time taken for 1 epoch: 103.0148994922638 secs\n",
      "\n",
      "Epoch 13 Batch 0 Loss 0.3959 Accuracy 0.5437\n",
      "Epoch 13 Batch 50 Loss 0.4603 Accuracy 0.5252\n",
      "Epoch 13 Batch 100 Loss 0.4706 Accuracy 0.5231\n",
      "Epoch 13 Batch 150 Loss 0.4748 Accuracy 0.5230\n",
      "Epoch 13 Batch 200 Loss 0.4833 Accuracy 0.5218\n",
      "Epoch 13 Batch 250 Loss 0.4859 Accuracy 0.5217\n",
      "Epoch 13 Batch 300 Loss 0.4921 Accuracy 0.5205\n",
      "Epoch 13 Batch 350 Loss 0.4925 Accuracy 0.5205\n",
      "Epoch 13 Batch 400 Loss 0.4951 Accuracy 0.5204\n",
      "Epoch 13 Batch 450 Loss 0.4973 Accuracy 0.5201\n",
      "Epoch 13 Batch 500 Loss 0.5016 Accuracy 0.5198\n",
      "Epoch 13 Batch 550 Loss 0.5038 Accuracy 0.5197\n",
      "Epoch 13 Batch 600 Loss 0.5064 Accuracy 0.5196\n",
      "Epoch 13 Batch 650 Loss 0.5100 Accuracy 0.5192\n",
      "Epoch 13 Batch 700 Loss 0.5110 Accuracy 0.5191\n",
      "Epoch 13 Batch 750 Loss 0.5136 Accuracy 0.5188\n",
      "Epoch 13 Batch 800 Loss 0.5154 Accuracy 0.5186\n",
      "Epoch 13 Batch 850 Loss 0.5161 Accuracy 0.5186\n",
      "Epoch 13 Batch 900 Loss 0.5188 Accuracy 0.5184\n",
      "Epoch 13 Batch 950 Loss 0.5205 Accuracy 0.5184\n",
      "Epoch 13 Batch 1000 Loss 0.5222 Accuracy 0.5183\n",
      "Epoch 13 Batch 1050 Loss 0.5234 Accuracy 0.5182\n",
      "Epoch 13 Batch 1100 Loss 0.5259 Accuracy 0.5180\n",
      "Epoch 13 Batch 1150 Loss 0.5275 Accuracy 0.5178\n",
      "Epoch 13 Batch 1200 Loss 0.5283 Accuracy 0.5178\n",
      "Epoch 13 Loss 0.5295 Accuracy 0.5178\n",
      "Time taken for 1 epoch: 103.19844937324524 secs\n",
      "\n",
      "Epoch 14 Batch 0 Loss 0.4860 Accuracy 0.5234\n",
      "Epoch 14 Batch 50 Loss 0.4581 Accuracy 0.5217\n",
      "Epoch 14 Batch 100 Loss 0.4533 Accuracy 0.5237\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 Batch 150 Loss 0.4582 Accuracy 0.5237\n",
      "Epoch 14 Batch 200 Loss 0.4646 Accuracy 0.5229\n",
      "Epoch 14 Batch 250 Loss 0.4652 Accuracy 0.5232\n",
      "Epoch 14 Batch 300 Loss 0.4686 Accuracy 0.5231\n",
      "Epoch 14 Batch 350 Loss 0.4708 Accuracy 0.5230\n",
      "Epoch 14 Batch 400 Loss 0.4750 Accuracy 0.5227\n",
      "Epoch 14 Batch 450 Loss 0.4782 Accuracy 0.5227\n",
      "Epoch 14 Batch 500 Loss 0.4838 Accuracy 0.5224\n",
      "Epoch 14 Batch 550 Loss 0.4863 Accuracy 0.5222\n",
      "Epoch 14 Batch 600 Loss 0.4874 Accuracy 0.5220\n",
      "Epoch 14 Batch 650 Loss 0.4906 Accuracy 0.5217\n",
      "Epoch 14 Batch 700 Loss 0.4920 Accuracy 0.5217\n",
      "Epoch 14 Batch 750 Loss 0.4935 Accuracy 0.5214\n",
      "Epoch 14 Batch 800 Loss 0.4968 Accuracy 0.5212\n",
      "Epoch 14 Batch 850 Loss 0.5000 Accuracy 0.5209\n",
      "Epoch 14 Batch 900 Loss 0.5027 Accuracy 0.5206\n",
      "Epoch 14 Batch 950 Loss 0.5036 Accuracy 0.5206\n",
      "Epoch 14 Batch 1000 Loss 0.5053 Accuracy 0.5204\n",
      "Epoch 14 Batch 1050 Loss 0.5068 Accuracy 0.5203\n",
      "Epoch 14 Batch 1100 Loss 0.5083 Accuracy 0.5202\n",
      "Epoch 14 Batch 1150 Loss 0.5096 Accuracy 0.5201\n",
      "Epoch 14 Batch 1200 Loss 0.5112 Accuracy 0.5200\n",
      "Epoch 14 Loss 0.5132 Accuracy 0.5198\n",
      "Time taken for 1 epoch: 103.11284232139587 secs\n",
      "\n",
      "Epoch 15 Batch 0 Loss 0.4009 Accuracy 0.5375\n",
      "Epoch 15 Batch 50 Loss 0.4635 Accuracy 0.5229\n",
      "Epoch 15 Batch 100 Loss 0.4550 Accuracy 0.5234\n",
      "Epoch 15 Batch 150 Loss 0.4575 Accuracy 0.5238\n",
      "Epoch 15 Batch 200 Loss 0.4608 Accuracy 0.5237\n",
      "Epoch 15 Batch 250 Loss 0.4602 Accuracy 0.5238\n",
      "Epoch 15 Batch 300 Loss 0.4630 Accuracy 0.5238\n",
      "Epoch 15 Batch 350 Loss 0.4626 Accuracy 0.5241\n",
      "Epoch 15 Batch 400 Loss 0.4663 Accuracy 0.5237\n",
      "Epoch 15 Batch 450 Loss 0.4681 Accuracy 0.5237\n",
      "Epoch 15 Batch 500 Loss 0.4709 Accuracy 0.5233\n",
      "Epoch 15 Batch 550 Loss 0.4730 Accuracy 0.5232\n",
      "Epoch 15 Batch 600 Loss 0.4741 Accuracy 0.5230\n",
      "Epoch 15 Batch 650 Loss 0.4783 Accuracy 0.5226\n",
      "Epoch 15 Batch 700 Loss 0.4802 Accuracy 0.5227\n",
      "Epoch 15 Batch 750 Loss 0.4809 Accuracy 0.5226\n",
      "Epoch 15 Batch 800 Loss 0.4826 Accuracy 0.5225\n",
      "Epoch 15 Batch 850 Loss 0.4829 Accuracy 0.5226\n",
      "Epoch 15 Batch 900 Loss 0.4841 Accuracy 0.5224\n",
      "Epoch 15 Batch 950 Loss 0.4864 Accuracy 0.5222\n",
      "Epoch 15 Batch 1000 Loss 0.4891 Accuracy 0.5222\n",
      "Epoch 15 Batch 1050 Loss 0.4903 Accuracy 0.5220\n",
      "Epoch 15 Batch 1100 Loss 0.4922 Accuracy 0.5219\n",
      "Epoch 15 Batch 1150 Loss 0.4948 Accuracy 0.5218\n",
      "Epoch 15 Batch 1200 Loss 0.4951 Accuracy 0.5219\n",
      "Saving checkpoint for epoch 15 at ./checkpoints/train\\ckpt-3\n",
      "Epoch 15 Loss 0.4968 Accuracy 0.5218\n",
      "Time taken for 1 epoch: 103.98277544975281 secs\n",
      "\n",
      "Epoch 16 Batch 0 Loss 0.5645 Accuracy 0.5016\n",
      "Epoch 16 Batch 50 Loss 0.4428 Accuracy 0.5283\n",
      "Epoch 16 Batch 100 Loss 0.4501 Accuracy 0.5265\n",
      "Epoch 16 Batch 150 Loss 0.4497 Accuracy 0.5269\n",
      "Epoch 16 Batch 200 Loss 0.4521 Accuracy 0.5267\n",
      "Epoch 16 Batch 250 Loss 0.4534 Accuracy 0.5267\n",
      "Epoch 16 Batch 300 Loss 0.4521 Accuracy 0.5265\n",
      "Epoch 16 Batch 350 Loss 0.4537 Accuracy 0.5260\n",
      "Epoch 16 Batch 400 Loss 0.4578 Accuracy 0.5257\n",
      "Epoch 16 Batch 450 Loss 0.4603 Accuracy 0.5255\n",
      "Epoch 16 Batch 500 Loss 0.4609 Accuracy 0.5252\n",
      "Epoch 16 Batch 550 Loss 0.4633 Accuracy 0.5250\n",
      "Epoch 16 Batch 600 Loss 0.4666 Accuracy 0.5246\n",
      "Epoch 16 Batch 650 Loss 0.4694 Accuracy 0.5245\n",
      "Epoch 16 Batch 700 Loss 0.4708 Accuracy 0.5243\n",
      "Epoch 16 Batch 750 Loss 0.4711 Accuracy 0.5242\n",
      "Epoch 16 Batch 800 Loss 0.4722 Accuracy 0.5241\n",
      "Epoch 16 Batch 850 Loss 0.4734 Accuracy 0.5241\n",
      "Epoch 16 Batch 900 Loss 0.4752 Accuracy 0.5239\n",
      "Epoch 16 Batch 950 Loss 0.4748 Accuracy 0.5241\n",
      "Epoch 16 Batch 1000 Loss 0.4763 Accuracy 0.5240\n",
      "Epoch 16 Batch 1050 Loss 0.4765 Accuracy 0.5239\n",
      "Epoch 16 Batch 1100 Loss 0.4773 Accuracy 0.5239\n",
      "Epoch 16 Batch 1150 Loss 0.4791 Accuracy 0.5238\n",
      "Epoch 16 Batch 1200 Loss 0.4809 Accuracy 0.5236\n",
      "Epoch 16 Loss 0.4817 Accuracy 0.5236\n",
      "Time taken for 1 epoch: 103.16956973075867 secs\n",
      "\n",
      "Epoch 17 Batch 0 Loss 0.5604 Accuracy 0.4984\n",
      "Epoch 17 Batch 50 Loss 0.4288 Accuracy 0.5293\n",
      "Epoch 17 Batch 100 Loss 0.4321 Accuracy 0.5288\n",
      "Epoch 17 Batch 150 Loss 0.4273 Accuracy 0.5296\n",
      "Epoch 17 Batch 200 Loss 0.4300 Accuracy 0.5294\n",
      "Epoch 17 Batch 250 Loss 0.4343 Accuracy 0.5291\n",
      "Epoch 17 Batch 300 Loss 0.4385 Accuracy 0.5288\n",
      "Epoch 17 Batch 350 Loss 0.4393 Accuracy 0.5285\n",
      "Epoch 17 Batch 400 Loss 0.4413 Accuracy 0.5281\n",
      "Epoch 17 Batch 450 Loss 0.4429 Accuracy 0.5282\n",
      "Epoch 17 Batch 500 Loss 0.4454 Accuracy 0.5279\n",
      "Epoch 17 Batch 550 Loss 0.4486 Accuracy 0.5275\n",
      "Epoch 17 Batch 600 Loss 0.4500 Accuracy 0.5272\n",
      "Epoch 17 Batch 650 Loss 0.4526 Accuracy 0.5268\n",
      "Epoch 17 Batch 700 Loss 0.4546 Accuracy 0.5267\n",
      "Epoch 17 Batch 750 Loss 0.4565 Accuracy 0.5267\n",
      "Epoch 17 Batch 800 Loss 0.4582 Accuracy 0.5264\n",
      "Epoch 17 Batch 850 Loss 0.4602 Accuracy 0.5262\n",
      "Epoch 17 Batch 900 Loss 0.4611 Accuracy 0.5261\n",
      "Epoch 17 Batch 950 Loss 0.4628 Accuracy 0.5259\n",
      "Epoch 17 Batch 1000 Loss 0.4643 Accuracy 0.5257\n",
      "Epoch 17 Batch 1050 Loss 0.4661 Accuracy 0.5256\n",
      "Epoch 17 Batch 1100 Loss 0.4671 Accuracy 0.5254\n",
      "Epoch 17 Batch 1150 Loss 0.4682 Accuracy 0.5253\n",
      "Epoch 17 Batch 1200 Loss 0.4697 Accuracy 0.5252\n",
      "Epoch 17 Loss 0.4710 Accuracy 0.5251\n",
      "Time taken for 1 epoch: 103.11520147323608 secs\n",
      "\n",
      "Epoch 18 Batch 0 Loss 0.4056 Accuracy 0.5312\n",
      "Epoch 18 Batch 50 Loss 0.4212 Accuracy 0.5271\n",
      "Epoch 18 Batch 100 Loss 0.4159 Accuracy 0.5282\n",
      "Epoch 18 Batch 150 Loss 0.4173 Accuracy 0.5281\n",
      "Epoch 18 Batch 200 Loss 0.4169 Accuracy 0.5287\n",
      "Epoch 18 Batch 250 Loss 0.4194 Accuracy 0.5291\n",
      "Epoch 18 Batch 300 Loss 0.4220 Accuracy 0.5290\n",
      "Epoch 18 Batch 350 Loss 0.4248 Accuracy 0.5284\n",
      "Epoch 18 Batch 400 Loss 0.4300 Accuracy 0.5282\n",
      "Epoch 18 Batch 450 Loss 0.4343 Accuracy 0.5279\n",
      "Epoch 18 Batch 500 Loss 0.4340 Accuracy 0.5281\n",
      "Epoch 18 Batch 550 Loss 0.4355 Accuracy 0.5280\n",
      "Epoch 18 Batch 600 Loss 0.4366 Accuracy 0.5281\n",
      "Epoch 18 Batch 650 Loss 0.4389 Accuracy 0.5278\n",
      "Epoch 18 Batch 700 Loss 0.4403 Accuracy 0.5278\n",
      "Epoch 18 Batch 750 Loss 0.4420 Accuracy 0.5278\n",
      "Epoch 18 Batch 800 Loss 0.4450 Accuracy 0.5276\n",
      "Epoch 18 Batch 850 Loss 0.4481 Accuracy 0.5275\n",
      "Epoch 18 Batch 900 Loss 0.4504 Accuracy 0.5272\n",
      "Epoch 18 Batch 950 Loss 0.4526 Accuracy 0.5271\n",
      "Epoch 18 Batch 1000 Loss 0.4545 Accuracy 0.5268\n",
      "Epoch 18 Batch 1050 Loss 0.4564 Accuracy 0.5266\n",
      "Epoch 18 Batch 1100 Loss 0.4569 Accuracy 0.5266\n",
      "Epoch 18 Batch 1150 Loss 0.4579 Accuracy 0.5267\n",
      "Epoch 18 Batch 1200 Loss 0.4584 Accuracy 0.5266\n",
      "Epoch 18 Loss 0.4591 Accuracy 0.5264\n",
      "Time taken for 1 epoch: 103.15297198295593 secs\n",
      "\n",
      "Epoch 19 Batch 0 Loss 0.5361 Accuracy 0.5375\n",
      "Epoch 19 Batch 50 Loss 0.4010 Accuracy 0.5324\n",
      "Epoch 19 Batch 100 Loss 0.4038 Accuracy 0.5308\n",
      "Epoch 19 Batch 150 Loss 0.4042 Accuracy 0.5308\n",
      "Epoch 19 Batch 200 Loss 0.4100 Accuracy 0.5306\n",
      "Epoch 19 Batch 250 Loss 0.4122 Accuracy 0.5308\n",
      "Epoch 19 Batch 300 Loss 0.4175 Accuracy 0.5302\n",
      "Epoch 19 Batch 350 Loss 0.4197 Accuracy 0.5302\n",
      "Epoch 19 Batch 400 Loss 0.4210 Accuracy 0.5304\n",
      "Epoch 19 Batch 450 Loss 0.4240 Accuracy 0.5296\n",
      "Epoch 19 Batch 500 Loss 0.4266 Accuracy 0.5295\n",
      "Epoch 19 Batch 550 Loss 0.4283 Accuracy 0.5294\n",
      "Epoch 19 Batch 600 Loss 0.4309 Accuracy 0.5291\n",
      "Epoch 19 Batch 650 Loss 0.4334 Accuracy 0.5289\n",
      "Epoch 19 Batch 700 Loss 0.4332 Accuracy 0.5289\n",
      "Epoch 19 Batch 750 Loss 0.4336 Accuracy 0.5291\n",
      "Epoch 19 Batch 800 Loss 0.4351 Accuracy 0.5289\n",
      "Epoch 19 Batch 850 Loss 0.4377 Accuracy 0.5286\n",
      "Epoch 19 Batch 900 Loss 0.4388 Accuracy 0.5286\n",
      "Epoch 19 Batch 950 Loss 0.4396 Accuracy 0.5285\n",
      "Epoch 19 Batch 1000 Loss 0.4415 Accuracy 0.5284\n",
      "Epoch 19 Batch 1050 Loss 0.4431 Accuracy 0.5284\n",
      "Epoch 19 Batch 1100 Loss 0.4445 Accuracy 0.5284\n",
      "Epoch 19 Batch 1150 Loss 0.4453 Accuracy 0.5283\n",
      "Epoch 19 Batch 1200 Loss 0.4467 Accuracy 0.5284\n",
      "Epoch 19 Loss 0.4481 Accuracy 0.5282\n",
      "Time taken for 1 epoch: 103.16826343536377 secs\n",
      "\n",
      "Epoch 20 Batch 0 Loss 0.3659 Accuracy 0.5203\n",
      "Epoch 20 Batch 50 Loss 0.3876 Accuracy 0.5296\n",
      "Epoch 20 Batch 100 Loss 0.3856 Accuracy 0.5315\n",
      "Epoch 20 Batch 150 Loss 0.3938 Accuracy 0.5312\n",
      "Epoch 20 Batch 200 Loss 0.3932 Accuracy 0.5326\n",
      "Epoch 20 Batch 250 Loss 0.3953 Accuracy 0.5327\n",
      "Epoch 20 Batch 300 Loss 0.3961 Accuracy 0.5327\n",
      "Epoch 20 Batch 350 Loss 0.4001 Accuracy 0.5319\n",
      "Epoch 20 Batch 400 Loss 0.4039 Accuracy 0.5317\n",
      "Epoch 20 Batch 450 Loss 0.4089 Accuracy 0.5312\n",
      "Epoch 20 Batch 500 Loss 0.4111 Accuracy 0.5311\n",
      "Epoch 20 Batch 550 Loss 0.4138 Accuracy 0.5312\n",
      "Epoch 20 Batch 600 Loss 0.4167 Accuracy 0.5309\n",
      "Epoch 20 Batch 650 Loss 0.4200 Accuracy 0.5307\n",
      "Epoch 20 Batch 700 Loss 0.4227 Accuracy 0.5307\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 Batch 750 Loss 0.4235 Accuracy 0.5308\n",
      "Epoch 20 Batch 800 Loss 0.4250 Accuracy 0.5305\n",
      "Epoch 20 Batch 850 Loss 0.4279 Accuracy 0.5303\n",
      "Epoch 20 Batch 900 Loss 0.4284 Accuracy 0.5303\n",
      "Epoch 20 Batch 950 Loss 0.4300 Accuracy 0.5302\n",
      "Epoch 20 Batch 1000 Loss 0.4311 Accuracy 0.5300\n",
      "Epoch 20 Batch 1050 Loss 0.4336 Accuracy 0.5298\n",
      "Epoch 20 Batch 1100 Loss 0.4355 Accuracy 0.5298\n",
      "Epoch 20 Batch 1150 Loss 0.4363 Accuracy 0.5297\n",
      "Epoch 20 Batch 1200 Loss 0.4381 Accuracy 0.5295\n",
      "Saving checkpoint for epoch 20 at ./checkpoints/train\\ckpt-4\n",
      "Epoch 20 Loss 0.4391 Accuracy 0.5294\n",
      "Time taken for 1 epoch: 103.69314312934875 secs\n",
      "\n",
      "Epoch 21 Batch 0 Loss 0.4017 Accuracy 0.5328\n",
      "Epoch 21 Batch 50 Loss 0.4022 Accuracy 0.5341\n",
      "Epoch 21 Batch 100 Loss 0.3921 Accuracy 0.5338\n",
      "Epoch 21 Batch 150 Loss 0.3881 Accuracy 0.5343\n",
      "Epoch 21 Batch 200 Loss 0.3912 Accuracy 0.5338\n",
      "Epoch 21 Batch 250 Loss 0.3951 Accuracy 0.5338\n",
      "Epoch 21 Batch 300 Loss 0.3984 Accuracy 0.5335\n",
      "Epoch 21 Batch 350 Loss 0.4032 Accuracy 0.5326\n",
      "Epoch 21 Batch 400 Loss 0.4051 Accuracy 0.5324\n",
      "Epoch 21 Batch 450 Loss 0.4079 Accuracy 0.5321\n",
      "Epoch 21 Batch 500 Loss 0.4093 Accuracy 0.5323\n",
      "Epoch 21 Batch 550 Loss 0.4099 Accuracy 0.5321\n",
      "Epoch 21 Batch 600 Loss 0.4123 Accuracy 0.5318\n",
      "Epoch 21 Batch 650 Loss 0.4147 Accuracy 0.5314\n",
      "Epoch 21 Batch 700 Loss 0.4175 Accuracy 0.5311\n",
      "Epoch 21 Batch 750 Loss 0.4179 Accuracy 0.5312\n",
      "Epoch 21 Batch 800 Loss 0.4189 Accuracy 0.5311\n",
      "Epoch 21 Batch 850 Loss 0.4209 Accuracy 0.5309\n",
      "Epoch 21 Batch 900 Loss 0.4216 Accuracy 0.5309\n",
      "Epoch 21 Batch 950 Loss 0.4225 Accuracy 0.5308\n",
      "Epoch 21 Batch 1000 Loss 0.4242 Accuracy 0.5308\n",
      "Epoch 21 Batch 1050 Loss 0.4260 Accuracy 0.5305\n",
      "Epoch 21 Batch 1100 Loss 0.4268 Accuracy 0.5303\n",
      "Epoch 21 Batch 1150 Loss 0.4282 Accuracy 0.5302\n",
      "Epoch 21 Batch 1200 Loss 0.4302 Accuracy 0.5302\n",
      "Epoch 21 Loss 0.4313 Accuracy 0.5301\n",
      "Time taken for 1 epoch: 103.05475640296936 secs\n",
      "\n",
      "Epoch 22 Batch 0 Loss 0.3760 Accuracy 0.5281\n",
      "Epoch 22 Batch 50 Loss 0.3652 Accuracy 0.5392\n",
      "Epoch 22 Batch 100 Loss 0.3691 Accuracy 0.5374\n",
      "Epoch 22 Batch 150 Loss 0.3778 Accuracy 0.5362\n",
      "Epoch 22 Batch 200 Loss 0.3797 Accuracy 0.5356\n",
      "Epoch 22 Batch 250 Loss 0.3842 Accuracy 0.5351\n",
      "Epoch 22 Batch 300 Loss 0.3890 Accuracy 0.5347\n",
      "Epoch 22 Batch 350 Loss 0.3914 Accuracy 0.5348\n",
      "Epoch 22 Batch 400 Loss 0.3962 Accuracy 0.5340\n",
      "Epoch 22 Batch 450 Loss 0.3977 Accuracy 0.5338\n",
      "Epoch 22 Batch 500 Loss 0.4005 Accuracy 0.5336\n",
      "Epoch 22 Batch 550 Loss 0.4013 Accuracy 0.5334\n",
      "Epoch 22 Batch 600 Loss 0.4032 Accuracy 0.5332\n",
      "Epoch 22 Batch 650 Loss 0.4051 Accuracy 0.5331\n",
      "Epoch 22 Batch 700 Loss 0.4054 Accuracy 0.5332\n",
      "Epoch 22 Batch 750 Loss 0.4083 Accuracy 0.5329\n",
      "Epoch 22 Batch 800 Loss 0.4094 Accuracy 0.5328\n",
      "Epoch 22 Batch 850 Loss 0.4106 Accuracy 0.5326\n",
      "Epoch 22 Batch 900 Loss 0.4111 Accuracy 0.5326\n",
      "Epoch 22 Batch 950 Loss 0.4136 Accuracy 0.5325\n",
      "Epoch 22 Batch 1000 Loss 0.4155 Accuracy 0.5323\n",
      "Epoch 22 Batch 1050 Loss 0.4177 Accuracy 0.5321\n",
      "Epoch 22 Batch 1100 Loss 0.4191 Accuracy 0.5318\n",
      "Epoch 22 Batch 1150 Loss 0.4204 Accuracy 0.5317\n",
      "Epoch 22 Batch 1200 Loss 0.4219 Accuracy 0.5315\n",
      "Epoch 22 Loss 0.4229 Accuracy 0.5314\n",
      "Time taken for 1 epoch: 103.0480694770813 secs\n",
      "\n",
      "Epoch 23 Batch 0 Loss 0.4535 Accuracy 0.5172\n",
      "Epoch 23 Batch 50 Loss 0.3598 Accuracy 0.5376\n",
      "Epoch 23 Batch 100 Loss 0.3628 Accuracy 0.5364\n",
      "Epoch 23 Batch 150 Loss 0.3706 Accuracy 0.5360\n",
      "Epoch 23 Batch 200 Loss 0.3711 Accuracy 0.5351\n",
      "Epoch 23 Batch 250 Loss 0.3780 Accuracy 0.5349\n",
      "Epoch 23 Batch 300 Loss 0.3820 Accuracy 0.5349\n",
      "Epoch 23 Batch 350 Loss 0.3856 Accuracy 0.5347\n",
      "Epoch 23 Batch 400 Loss 0.3893 Accuracy 0.5344\n",
      "Epoch 23 Batch 450 Loss 0.3907 Accuracy 0.5342\n",
      "Epoch 23 Batch 500 Loss 0.3932 Accuracy 0.5342\n",
      "Epoch 23 Batch 550 Loss 0.3931 Accuracy 0.5342\n",
      "Epoch 23 Batch 600 Loss 0.3958 Accuracy 0.5342\n",
      "Epoch 23 Batch 650 Loss 0.3963 Accuracy 0.5341\n",
      "Epoch 23 Batch 700 Loss 0.3978 Accuracy 0.5340\n",
      "Epoch 23 Batch 750 Loss 0.3997 Accuracy 0.5339\n",
      "Epoch 23 Batch 800 Loss 0.4017 Accuracy 0.5339\n",
      "Epoch 23 Batch 850 Loss 0.4042 Accuracy 0.5336\n",
      "Epoch 23 Batch 900 Loss 0.4046 Accuracy 0.5334\n",
      "Epoch 23 Batch 950 Loss 0.4066 Accuracy 0.5330\n",
      "Epoch 23 Batch 1000 Loss 0.4086 Accuracy 0.5329\n",
      "Epoch 23 Batch 1050 Loss 0.4100 Accuracy 0.5328\n",
      "Epoch 23 Batch 1100 Loss 0.4115 Accuracy 0.5327\n",
      "Epoch 23 Batch 1150 Loss 0.4130 Accuracy 0.5325\n",
      "Epoch 23 Batch 1200 Loss 0.4145 Accuracy 0.5324\n",
      "Epoch 23 Loss 0.4161 Accuracy 0.5323\n",
      "Time taken for 1 epoch: 103.04693508148193 secs\n",
      "\n",
      "Epoch 24 Batch 0 Loss 0.2886 Accuracy 0.5391\n",
      "Epoch 24 Batch 50 Loss 0.3614 Accuracy 0.5381\n",
      "Epoch 24 Batch 100 Loss 0.3660 Accuracy 0.5387\n",
      "Epoch 24 Batch 150 Loss 0.3648 Accuracy 0.5364\n",
      "Epoch 24 Batch 200 Loss 0.3667 Accuracy 0.5365\n",
      "Epoch 24 Batch 250 Loss 0.3675 Accuracy 0.5366\n",
      "Epoch 24 Batch 300 Loss 0.3704 Accuracy 0.5366\n",
      "Epoch 24 Batch 350 Loss 0.3765 Accuracy 0.5359\n",
      "Epoch 24 Batch 400 Loss 0.3791 Accuracy 0.5355\n",
      "Epoch 24 Batch 450 Loss 0.3816 Accuracy 0.5354\n",
      "Epoch 24 Batch 500 Loss 0.3845 Accuracy 0.5351\n",
      "Epoch 24 Batch 550 Loss 0.3851 Accuracy 0.5349\n",
      "Epoch 24 Batch 600 Loss 0.3884 Accuracy 0.5349\n",
      "Epoch 24 Batch 650 Loss 0.3905 Accuracy 0.5347\n",
      "Epoch 24 Batch 700 Loss 0.3923 Accuracy 0.5347\n",
      "Epoch 24 Batch 750 Loss 0.3930 Accuracy 0.5346\n",
      "Epoch 24 Batch 800 Loss 0.3953 Accuracy 0.5344\n",
      "Epoch 24 Batch 850 Loss 0.3977 Accuracy 0.5342\n",
      "Epoch 24 Batch 900 Loss 0.4001 Accuracy 0.5337\n",
      "Epoch 24 Batch 950 Loss 0.4019 Accuracy 0.5336\n",
      "Epoch 24 Batch 1000 Loss 0.4046 Accuracy 0.5333\n",
      "Epoch 24 Batch 1050 Loss 0.4058 Accuracy 0.5333\n",
      "Epoch 24 Batch 1100 Loss 0.4055 Accuracy 0.5333\n",
      "Epoch 24 Batch 1150 Loss 0.4071 Accuracy 0.5332\n",
      "Epoch 24 Batch 1200 Loss 0.4089 Accuracy 0.5330\n",
      "Epoch 24 Loss 0.4099 Accuracy 0.5329\n",
      "Time taken for 1 epoch: 103.06454300880432 secs\n",
      "\n",
      "Epoch 25 Batch 0 Loss 0.3190 Accuracy 0.5406\n",
      "Epoch 25 Batch 50 Loss 0.3656 Accuracy 0.5369\n",
      "Epoch 25 Batch 100 Loss 0.3638 Accuracy 0.5374\n",
      "Epoch 25 Batch 150 Loss 0.3662 Accuracy 0.5367\n",
      "Epoch 25 Batch 200 Loss 0.3680 Accuracy 0.5367\n",
      "Epoch 25 Batch 250 Loss 0.3674 Accuracy 0.5367\n",
      "Epoch 25 Batch 300 Loss 0.3706 Accuracy 0.5358\n",
      "Epoch 25 Batch 350 Loss 0.3754 Accuracy 0.5355\n",
      "Epoch 25 Batch 400 Loss 0.3785 Accuracy 0.5357\n",
      "Epoch 25 Batch 450 Loss 0.3819 Accuracy 0.5355\n",
      "Epoch 25 Batch 500 Loss 0.3825 Accuracy 0.5352\n",
      "Epoch 25 Batch 550 Loss 0.3830 Accuracy 0.5351\n",
      "Epoch 25 Batch 600 Loss 0.3873 Accuracy 0.5346\n",
      "Epoch 25 Batch 650 Loss 0.3881 Accuracy 0.5348\n",
      "Epoch 25 Batch 700 Loss 0.3899 Accuracy 0.5346\n",
      "Epoch 25 Batch 750 Loss 0.3920 Accuracy 0.5341\n",
      "Epoch 25 Batch 800 Loss 0.3945 Accuracy 0.5340\n",
      "Epoch 25 Batch 850 Loss 0.3953 Accuracy 0.5340\n",
      "Epoch 25 Batch 900 Loss 0.3957 Accuracy 0.5339\n",
      "Epoch 25 Batch 950 Loss 0.3968 Accuracy 0.5338\n",
      "Epoch 25 Batch 1000 Loss 0.3982 Accuracy 0.5337\n",
      "Epoch 25 Batch 1050 Loss 0.3989 Accuracy 0.5338\n",
      "Epoch 25 Batch 1100 Loss 0.4000 Accuracy 0.5337\n",
      "Epoch 25 Batch 1150 Loss 0.4020 Accuracy 0.5336\n",
      "Epoch 25 Batch 1200 Loss 0.4031 Accuracy 0.5336\n",
      "Saving checkpoint for epoch 25 at ./checkpoints/train\\ckpt-5\n",
      "Epoch 25 Loss 0.4046 Accuracy 0.5335\n",
      "Time taken for 1 epoch: 103.72582077980042 secs\n",
      "\n",
      "Epoch 26 Batch 0 Loss 0.3169 Accuracy 0.5344\n",
      "Epoch 26 Batch 50 Loss 0.3408 Accuracy 0.5392\n",
      "Epoch 26 Batch 100 Loss 0.3559 Accuracy 0.5372\n",
      "Epoch 26 Batch 150 Loss 0.3576 Accuracy 0.5374\n",
      "Epoch 26 Batch 200 Loss 0.3600 Accuracy 0.5378\n",
      "Epoch 26 Batch 250 Loss 0.3622 Accuracy 0.5376\n",
      "Epoch 26 Batch 300 Loss 0.3638 Accuracy 0.5375\n",
      "Epoch 26 Batch 350 Loss 0.3659 Accuracy 0.5375\n",
      "Epoch 26 Batch 400 Loss 0.3681 Accuracy 0.5370\n",
      "Epoch 26 Batch 450 Loss 0.3708 Accuracy 0.5370\n",
      "Epoch 26 Batch 500 Loss 0.3729 Accuracy 0.5367\n",
      "Epoch 26 Batch 550 Loss 0.3760 Accuracy 0.5363\n",
      "Epoch 26 Batch 600 Loss 0.3790 Accuracy 0.5361\n",
      "Epoch 26 Batch 650 Loss 0.3809 Accuracy 0.5357\n",
      "Epoch 26 Batch 700 Loss 0.3838 Accuracy 0.5354\n",
      "Epoch 26 Batch 750 Loss 0.3852 Accuracy 0.5354\n",
      "Epoch 26 Batch 800 Loss 0.3886 Accuracy 0.5352\n",
      "Epoch 26 Batch 850 Loss 0.3891 Accuracy 0.5351\n",
      "Epoch 26 Batch 900 Loss 0.3897 Accuracy 0.5350\n",
      "Epoch 26 Batch 950 Loss 0.3901 Accuracy 0.5350\n",
      "Epoch 26 Batch 1000 Loss 0.3907 Accuracy 0.5349\n",
      "Epoch 26 Batch 1050 Loss 0.3912 Accuracy 0.5349\n",
      "Epoch 26 Batch 1100 Loss 0.3941 Accuracy 0.5346\n",
      "Epoch 26 Batch 1150 Loss 0.3955 Accuracy 0.5345\n",
      "Epoch 26 Batch 1200 Loss 0.3963 Accuracy 0.5346\n",
      "Epoch 26 Loss 0.3977 Accuracy 0.5344\n",
      "Time taken for 1 epoch: 103.1593029499054 secs\n",
      "\n",
      "Epoch 27 Batch 0 Loss 0.3367 Accuracy 0.5422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 Batch 50 Loss 0.3377 Accuracy 0.5415\n",
      "Epoch 27 Batch 100 Loss 0.3447 Accuracy 0.5401\n",
      "Epoch 27 Batch 150 Loss 0.3495 Accuracy 0.5394\n",
      "Epoch 27 Batch 200 Loss 0.3491 Accuracy 0.5398\n",
      "Epoch 27 Batch 250 Loss 0.3513 Accuracy 0.5396\n",
      "Epoch 27 Batch 300 Loss 0.3553 Accuracy 0.5388\n",
      "Epoch 27 Batch 350 Loss 0.3568 Accuracy 0.5385\n",
      "Epoch 27 Batch 400 Loss 0.3600 Accuracy 0.5381\n",
      "Epoch 27 Batch 450 Loss 0.3641 Accuracy 0.5380\n",
      "Epoch 27 Batch 500 Loss 0.3657 Accuracy 0.5379\n",
      "Epoch 27 Batch 550 Loss 0.3679 Accuracy 0.5375\n",
      "Epoch 27 Batch 600 Loss 0.3706 Accuracy 0.5372\n",
      "Epoch 27 Batch 650 Loss 0.3726 Accuracy 0.5369\n",
      "Epoch 27 Batch 700 Loss 0.3744 Accuracy 0.5368\n",
      "Epoch 27 Batch 750 Loss 0.3769 Accuracy 0.5366\n",
      "Epoch 27 Batch 800 Loss 0.3794 Accuracy 0.5362\n",
      "Epoch 27 Batch 850 Loss 0.3816 Accuracy 0.5362\n",
      "Epoch 27 Batch 900 Loss 0.3817 Accuracy 0.5362\n",
      "Epoch 27 Batch 950 Loss 0.3835 Accuracy 0.5361\n",
      "Epoch 27 Batch 1000 Loss 0.3854 Accuracy 0.5359\n",
      "Epoch 27 Batch 1050 Loss 0.3868 Accuracy 0.5357\n",
      "Epoch 27 Batch 1100 Loss 0.3885 Accuracy 0.5356\n",
      "Epoch 27 Batch 1150 Loss 0.3900 Accuracy 0.5355\n",
      "Epoch 27 Batch 1200 Loss 0.3914 Accuracy 0.5353\n",
      "Epoch 27 Loss 0.3931 Accuracy 0.5352\n",
      "Time taken for 1 epoch: 103.17370843887329 secs\n",
      "\n",
      "Epoch 28 Batch 0 Loss 0.1957 Accuracy 0.5578\n",
      "Epoch 28 Batch 50 Loss 0.3293 Accuracy 0.5394\n",
      "Epoch 28 Batch 100 Loss 0.3317 Accuracy 0.5400\n",
      "Epoch 28 Batch 150 Loss 0.3427 Accuracy 0.5393\n",
      "Epoch 28 Batch 200 Loss 0.3442 Accuracy 0.5392\n",
      "Epoch 28 Batch 250 Loss 0.3506 Accuracy 0.5390\n",
      "Epoch 28 Batch 300 Loss 0.3530 Accuracy 0.5389\n",
      "Epoch 28 Batch 350 Loss 0.3528 Accuracy 0.5383\n",
      "Epoch 28 Batch 400 Loss 0.3536 Accuracy 0.5380\n",
      "Epoch 28 Batch 450 Loss 0.3574 Accuracy 0.5379\n",
      "Epoch 28 Batch 500 Loss 0.3600 Accuracy 0.5377\n",
      "Epoch 28 Batch 550 Loss 0.3604 Accuracy 0.5377\n",
      "Epoch 28 Batch 600 Loss 0.3632 Accuracy 0.5374\n",
      "Epoch 28 Batch 650 Loss 0.3664 Accuracy 0.5371\n",
      "Epoch 28 Batch 700 Loss 0.3678 Accuracy 0.5370\n",
      "Epoch 28 Batch 750 Loss 0.3702 Accuracy 0.5368\n",
      "Epoch 28 Batch 800 Loss 0.3719 Accuracy 0.5369\n",
      "Epoch 28 Batch 850 Loss 0.3741 Accuracy 0.5367\n",
      "Epoch 28 Batch 900 Loss 0.3755 Accuracy 0.5365\n",
      "Epoch 28 Batch 950 Loss 0.3773 Accuracy 0.5364\n",
      "Epoch 28 Batch 1000 Loss 0.3786 Accuracy 0.5363\n",
      "Epoch 28 Batch 1050 Loss 0.3796 Accuracy 0.5364\n",
      "Epoch 28 Batch 1100 Loss 0.3816 Accuracy 0.5363\n",
      "Epoch 28 Batch 1150 Loss 0.3828 Accuracy 0.5362\n",
      "Epoch 28 Batch 1200 Loss 0.3840 Accuracy 0.5361\n",
      "Epoch 28 Loss 0.3857 Accuracy 0.5359\n",
      "Time taken for 1 epoch: 103.01829195022583 secs\n",
      "\n",
      "Epoch 29 Batch 0 Loss 0.2086 Accuracy 0.5578\n",
      "Epoch 29 Batch 50 Loss 0.3291 Accuracy 0.5437\n",
      "Epoch 29 Batch 100 Loss 0.3346 Accuracy 0.5418\n",
      "Epoch 29 Batch 150 Loss 0.3358 Accuracy 0.5411\n",
      "Epoch 29 Batch 200 Loss 0.3339 Accuracy 0.5417\n",
      "Epoch 29 Batch 250 Loss 0.3398 Accuracy 0.5411\n",
      "Epoch 29 Batch 300 Loss 0.3438 Accuracy 0.5409\n",
      "Epoch 29 Batch 350 Loss 0.3477 Accuracy 0.5403\n",
      "Epoch 29 Batch 400 Loss 0.3490 Accuracy 0.5402\n",
      "Epoch 29 Batch 450 Loss 0.3509 Accuracy 0.5399\n",
      "Epoch 29 Batch 500 Loss 0.3521 Accuracy 0.5397\n",
      "Epoch 29 Batch 550 Loss 0.3567 Accuracy 0.5392\n",
      "Epoch 29 Batch 600 Loss 0.3593 Accuracy 0.5389\n",
      "Epoch 29 Batch 650 Loss 0.3621 Accuracy 0.5386\n",
      "Epoch 29 Batch 700 Loss 0.3642 Accuracy 0.5382\n",
      "Epoch 29 Batch 750 Loss 0.3667 Accuracy 0.5378\n",
      "Epoch 29 Batch 800 Loss 0.3677 Accuracy 0.5376\n",
      "Epoch 29 Batch 850 Loss 0.3699 Accuracy 0.5375\n",
      "Epoch 29 Batch 900 Loss 0.3708 Accuracy 0.5375\n",
      "Epoch 29 Batch 950 Loss 0.3720 Accuracy 0.5373\n",
      "Epoch 29 Batch 1000 Loss 0.3732 Accuracy 0.5372\n",
      "Epoch 29 Batch 1050 Loss 0.3760 Accuracy 0.5370\n",
      "Epoch 29 Batch 1100 Loss 0.3771 Accuracy 0.5367\n",
      "Epoch 29 Batch 1150 Loss 0.3790 Accuracy 0.5367\n",
      "Epoch 29 Batch 1200 Loss 0.3808 Accuracy 0.5366\n",
      "Epoch 29 Loss 0.3819 Accuracy 0.5365\n",
      "Time taken for 1 epoch: 103.15965127944946 secs\n",
      "\n",
      "Epoch 30 Batch 0 Loss 0.2760 Accuracy 0.5422\n",
      "Epoch 30 Batch 50 Loss 0.3092 Accuracy 0.5433\n",
      "Epoch 30 Batch 100 Loss 0.3123 Accuracy 0.5438\n",
      "Epoch 30 Batch 150 Loss 0.3244 Accuracy 0.5422\n",
      "Epoch 30 Batch 200 Loss 0.3353 Accuracy 0.5410\n",
      "Epoch 30 Batch 250 Loss 0.3354 Accuracy 0.5411\n",
      "Epoch 30 Batch 300 Loss 0.3403 Accuracy 0.5410\n",
      "Epoch 30 Batch 350 Loss 0.3433 Accuracy 0.5404\n",
      "Epoch 30 Batch 400 Loss 0.3449 Accuracy 0.5401\n",
      "Epoch 30 Batch 450 Loss 0.3464 Accuracy 0.5399\n",
      "Epoch 30 Batch 500 Loss 0.3481 Accuracy 0.5399\n",
      "Epoch 30 Batch 550 Loss 0.3512 Accuracy 0.5394\n",
      "Epoch 30 Batch 600 Loss 0.3548 Accuracy 0.5392\n",
      "Epoch 30 Batch 650 Loss 0.3578 Accuracy 0.5387\n",
      "Epoch 30 Batch 700 Loss 0.3593 Accuracy 0.5384\n",
      "Epoch 30 Batch 750 Loss 0.3615 Accuracy 0.5383\n",
      "Epoch 30 Batch 800 Loss 0.3641 Accuracy 0.5380\n",
      "Epoch 30 Batch 850 Loss 0.3663 Accuracy 0.5376\n",
      "Epoch 30 Batch 900 Loss 0.3678 Accuracy 0.5374\n",
      "Epoch 30 Batch 950 Loss 0.3695 Accuracy 0.5372\n",
      "Epoch 30 Batch 1000 Loss 0.3717 Accuracy 0.5370\n",
      "Epoch 30 Batch 1050 Loss 0.3732 Accuracy 0.5369\n",
      "Epoch 30 Batch 1100 Loss 0.3751 Accuracy 0.5369\n",
      "Epoch 30 Batch 1150 Loss 0.3770 Accuracy 0.5368\n",
      "Epoch 30 Batch 1200 Loss 0.3773 Accuracy 0.5370\n",
      "Saving checkpoint for epoch 30 at ./checkpoints/train\\ckpt-6\n",
      "Epoch 30 Loss 0.3786 Accuracy 0.5370\n",
      "Time taken for 1 epoch: 103.58837103843689 secs\n",
      "\n",
      "Epoch 31 Batch 0 Loss 0.2813 Accuracy 0.5547\n",
      "Epoch 31 Batch 50 Loss 0.3175 Accuracy 0.5428\n",
      "Epoch 31 Batch 100 Loss 0.3190 Accuracy 0.5410\n",
      "Epoch 31 Batch 150 Loss 0.3252 Accuracy 0.5411\n",
      "Epoch 31 Batch 200 Loss 0.3288 Accuracy 0.5411\n",
      "Epoch 31 Batch 250 Loss 0.3315 Accuracy 0.5404\n",
      "Epoch 31 Batch 300 Loss 0.3355 Accuracy 0.5398\n",
      "Epoch 31 Batch 350 Loss 0.3361 Accuracy 0.5398\n",
      "Epoch 31 Batch 400 Loss 0.3421 Accuracy 0.5391\n",
      "Epoch 31 Batch 450 Loss 0.3424 Accuracy 0.5394\n",
      "Epoch 31 Batch 500 Loss 0.3454 Accuracy 0.5396\n",
      "Epoch 31 Batch 550 Loss 0.3479 Accuracy 0.5394\n",
      "Epoch 31 Batch 600 Loss 0.3500 Accuracy 0.5393\n",
      "Epoch 31 Batch 650 Loss 0.3508 Accuracy 0.5393\n",
      "Epoch 31 Batch 700 Loss 0.3545 Accuracy 0.5390\n",
      "Epoch 31 Batch 750 Loss 0.3566 Accuracy 0.5387\n",
      "Epoch 31 Batch 800 Loss 0.3583 Accuracy 0.5385\n",
      "Epoch 31 Batch 850 Loss 0.3595 Accuracy 0.5385\n",
      "Epoch 31 Batch 900 Loss 0.3609 Accuracy 0.5384\n",
      "Epoch 31 Batch 950 Loss 0.3630 Accuracy 0.5384\n",
      "Epoch 31 Batch 1000 Loss 0.3642 Accuracy 0.5383\n",
      "Epoch 31 Batch 1050 Loss 0.3658 Accuracy 0.5382\n",
      "Epoch 31 Batch 1100 Loss 0.3677 Accuracy 0.5380\n",
      "Epoch 31 Batch 1150 Loss 0.3691 Accuracy 0.5380\n",
      "Epoch 31 Batch 1200 Loss 0.3713 Accuracy 0.5378\n",
      "Epoch 31 Loss 0.3723 Accuracy 0.5378\n",
      "Time taken for 1 epoch: 103.14063668251038 secs\n",
      "\n",
      "Epoch 32 Batch 0 Loss 0.2854 Accuracy 0.5437\n",
      "Epoch 32 Batch 50 Loss 0.3301 Accuracy 0.5381\n",
      "Epoch 32 Batch 100 Loss 0.3265 Accuracy 0.5416\n",
      "Epoch 32 Batch 150 Loss 0.3274 Accuracy 0.5418\n",
      "Epoch 32 Batch 200 Loss 0.3285 Accuracy 0.5417\n",
      "Epoch 32 Batch 250 Loss 0.3328 Accuracy 0.5420\n",
      "Epoch 32 Batch 300 Loss 0.3340 Accuracy 0.5417\n",
      "Epoch 32 Batch 350 Loss 0.3366 Accuracy 0.5419\n",
      "Epoch 32 Batch 400 Loss 0.3403 Accuracy 0.5414\n",
      "Epoch 32 Batch 450 Loss 0.3412 Accuracy 0.5414\n",
      "Epoch 32 Batch 500 Loss 0.3428 Accuracy 0.5409\n",
      "Epoch 32 Batch 550 Loss 0.3452 Accuracy 0.5406\n",
      "Epoch 32 Batch 600 Loss 0.3476 Accuracy 0.5404\n",
      "Epoch 32 Batch 650 Loss 0.3511 Accuracy 0.5400\n",
      "Epoch 32 Batch 700 Loss 0.3519 Accuracy 0.5400\n",
      "Epoch 32 Batch 750 Loss 0.3547 Accuracy 0.5398\n",
      "Epoch 32 Batch 800 Loss 0.3562 Accuracy 0.5398\n",
      "Epoch 32 Batch 850 Loss 0.3575 Accuracy 0.5396\n",
      "Epoch 32 Batch 900 Loss 0.3595 Accuracy 0.5393\n",
      "Epoch 32 Batch 950 Loss 0.3617 Accuracy 0.5390\n",
      "Epoch 32 Batch 1000 Loss 0.3642 Accuracy 0.5388\n",
      "Epoch 32 Batch 1050 Loss 0.3662 Accuracy 0.5386\n",
      "Epoch 32 Batch 1100 Loss 0.3675 Accuracy 0.5385\n",
      "Epoch 32 Batch 1150 Loss 0.3687 Accuracy 0.5385\n",
      "Epoch 32 Batch 1200 Loss 0.3698 Accuracy 0.5384\n",
      "Epoch 32 Loss 0.3710 Accuracy 0.5383\n",
      "Time taken for 1 epoch: 103.0835771560669 secs\n",
      "\n",
      "Epoch 33 Batch 0 Loss 0.3661 Accuracy 0.5641\n",
      "Epoch 33 Batch 50 Loss 0.3054 Accuracy 0.5433\n",
      "Epoch 33 Batch 100 Loss 0.3202 Accuracy 0.5418\n",
      "Epoch 33 Batch 150 Loss 0.3262 Accuracy 0.5417\n",
      "Epoch 33 Batch 200 Loss 0.3274 Accuracy 0.5408\n",
      "Epoch 33 Batch 250 Loss 0.3331 Accuracy 0.5405\n",
      "Epoch 33 Batch 300 Loss 0.3370 Accuracy 0.5400\n",
      "Epoch 33 Batch 350 Loss 0.3425 Accuracy 0.5395\n",
      "Epoch 33 Batch 400 Loss 0.3451 Accuracy 0.5394\n",
      "Epoch 33 Batch 450 Loss 0.3467 Accuracy 0.5395\n",
      "Epoch 33 Batch 500 Loss 0.3462 Accuracy 0.5396\n",
      "Epoch 33 Batch 550 Loss 0.3477 Accuracy 0.5395\n",
      "Epoch 33 Batch 600 Loss 0.3502 Accuracy 0.5394\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33 Batch 650 Loss 0.3505 Accuracy 0.5394\n",
      "Epoch 33 Batch 700 Loss 0.3509 Accuracy 0.5395\n",
      "Epoch 33 Batch 750 Loss 0.3519 Accuracy 0.5397\n",
      "Epoch 33 Batch 800 Loss 0.3535 Accuracy 0.5396\n",
      "Epoch 33 Batch 850 Loss 0.3546 Accuracy 0.5396\n",
      "Epoch 33 Batch 900 Loss 0.3566 Accuracy 0.5393\n",
      "Epoch 33 Batch 950 Loss 0.3582 Accuracy 0.5392\n",
      "Epoch 33 Batch 1000 Loss 0.3591 Accuracy 0.5391\n",
      "Epoch 33 Batch 1050 Loss 0.3580 Accuracy 0.5392\n",
      "Epoch 33 Batch 1100 Loss 0.3596 Accuracy 0.5391\n",
      "Epoch 33 Batch 1150 Loss 0.3606 Accuracy 0.5391\n",
      "Epoch 33 Batch 1200 Loss 0.3621 Accuracy 0.5389\n",
      "Epoch 33 Loss 0.3639 Accuracy 0.5386\n",
      "Time taken for 1 epoch: 103.15014004707336 secs\n",
      "\n",
      "Epoch 34 Batch 0 Loss 0.4632 Accuracy 0.5266\n",
      "Epoch 34 Batch 50 Loss 0.3215 Accuracy 0.5419\n",
      "Epoch 34 Batch 100 Loss 0.3187 Accuracy 0.5423\n",
      "Epoch 34 Batch 150 Loss 0.3285 Accuracy 0.5413\n",
      "Epoch 34 Batch 200 Loss 0.3270 Accuracy 0.5415\n",
      "Epoch 34 Batch 250 Loss 0.3227 Accuracy 0.5422\n",
      "Epoch 34 Batch 300 Loss 0.3253 Accuracy 0.5424\n",
      "Epoch 34 Batch 350 Loss 0.3266 Accuracy 0.5422\n",
      "Epoch 34 Batch 400 Loss 0.3310 Accuracy 0.5417\n",
      "Epoch 34 Batch 450 Loss 0.3361 Accuracy 0.5413\n",
      "Epoch 34 Batch 500 Loss 0.3364 Accuracy 0.5408\n",
      "Epoch 34 Batch 550 Loss 0.3394 Accuracy 0.5407\n",
      "Epoch 34 Batch 600 Loss 0.3413 Accuracy 0.5405\n",
      "Epoch 34 Batch 650 Loss 0.3427 Accuracy 0.5405\n",
      "Epoch 34 Batch 700 Loss 0.3454 Accuracy 0.5402\n",
      "Epoch 34 Batch 750 Loss 0.3464 Accuracy 0.5404\n",
      "Epoch 34 Batch 800 Loss 0.3478 Accuracy 0.5403\n",
      "Epoch 34 Batch 850 Loss 0.3492 Accuracy 0.5402\n",
      "Epoch 34 Batch 900 Loss 0.3497 Accuracy 0.5403\n",
      "Epoch 34 Batch 950 Loss 0.3511 Accuracy 0.5401\n",
      "Epoch 34 Batch 1000 Loss 0.3523 Accuracy 0.5399\n",
      "Epoch 34 Batch 1050 Loss 0.3547 Accuracy 0.5398\n",
      "Epoch 34 Batch 1100 Loss 0.3573 Accuracy 0.5396\n",
      "Epoch 34 Batch 1150 Loss 0.3591 Accuracy 0.5395\n",
      "Epoch 34 Batch 1200 Loss 0.3607 Accuracy 0.5395\n",
      "Epoch 34 Loss 0.3623 Accuracy 0.5393\n",
      "Time taken for 1 epoch: 103.08297181129456 secs\n",
      "\n",
      "Epoch 35 Batch 0 Loss 0.2857 Accuracy 0.5406\n",
      "Epoch 35 Batch 50 Loss 0.3134 Accuracy 0.5455\n",
      "Epoch 35 Batch 100 Loss 0.3203 Accuracy 0.5420\n",
      "Epoch 35 Batch 150 Loss 0.3200 Accuracy 0.5429\n",
      "Epoch 35 Batch 200 Loss 0.3240 Accuracy 0.5424\n",
      "Epoch 35 Batch 250 Loss 0.3297 Accuracy 0.5416\n",
      "Epoch 35 Batch 300 Loss 0.3337 Accuracy 0.5412\n",
      "Epoch 35 Batch 350 Loss 0.3351 Accuracy 0.5410\n",
      "Epoch 35 Batch 400 Loss 0.3359 Accuracy 0.5416\n",
      "Epoch 35 Batch 450 Loss 0.3366 Accuracy 0.5415\n",
      "Epoch 35 Batch 500 Loss 0.3389 Accuracy 0.5414\n",
      "Epoch 35 Batch 550 Loss 0.3402 Accuracy 0.5409\n",
      "Epoch 35 Batch 600 Loss 0.3418 Accuracy 0.5411\n",
      "Epoch 35 Batch 650 Loss 0.3429 Accuracy 0.5411\n",
      "Epoch 35 Batch 700 Loss 0.3452 Accuracy 0.5407\n",
      "Epoch 35 Batch 750 Loss 0.3450 Accuracy 0.5407\n",
      "Epoch 35 Batch 800 Loss 0.3455 Accuracy 0.5407\n",
      "Epoch 35 Batch 850 Loss 0.3464 Accuracy 0.5406\n",
      "Epoch 35 Batch 900 Loss 0.3484 Accuracy 0.5406\n",
      "Epoch 35 Batch 950 Loss 0.3497 Accuracy 0.5403\n",
      "Epoch 35 Batch 1000 Loss 0.3511 Accuracy 0.5403\n",
      "Epoch 35 Batch 1050 Loss 0.3526 Accuracy 0.5402\n",
      "Epoch 35 Batch 1100 Loss 0.3544 Accuracy 0.5400\n",
      "Epoch 35 Batch 1150 Loss 0.3557 Accuracy 0.5399\n",
      "Epoch 35 Batch 1200 Loss 0.3574 Accuracy 0.5398\n",
      "Saving checkpoint for epoch 35 at ./checkpoints/train\\ckpt-7\n",
      "Epoch 35 Loss 0.3589 Accuracy 0.5397\n",
      "Time taken for 1 epoch: 103.71916842460632 secs\n",
      "\n",
      "Epoch 36 Batch 0 Loss 0.3079 Accuracy 0.5375\n",
      "Epoch 36 Batch 50 Loss 0.3196 Accuracy 0.5441\n",
      "Epoch 36 Batch 100 Loss 0.3178 Accuracy 0.5442\n",
      "Epoch 36 Batch 150 Loss 0.3203 Accuracy 0.5449\n",
      "Epoch 36 Batch 200 Loss 0.3209 Accuracy 0.5444\n",
      "Epoch 36 Batch 250 Loss 0.3220 Accuracy 0.5444\n",
      "Epoch 36 Batch 300 Loss 0.3212 Accuracy 0.5442\n",
      "Epoch 36 Batch 350 Loss 0.3252 Accuracy 0.5433\n",
      "Epoch 36 Batch 400 Loss 0.3246 Accuracy 0.5432\n",
      "Epoch 36 Batch 450 Loss 0.3265 Accuracy 0.5431\n",
      "Epoch 36 Batch 500 Loss 0.3291 Accuracy 0.5426\n",
      "Epoch 36 Batch 550 Loss 0.3322 Accuracy 0.5421\n",
      "Epoch 36 Batch 600 Loss 0.3349 Accuracy 0.5416\n",
      "Epoch 36 Batch 650 Loss 0.3384 Accuracy 0.5415\n",
      "Epoch 36 Batch 700 Loss 0.3394 Accuracy 0.5415\n",
      "Epoch 36 Batch 750 Loss 0.3415 Accuracy 0.5414\n",
      "Epoch 36 Batch 800 Loss 0.3433 Accuracy 0.5413\n",
      "Epoch 36 Batch 850 Loss 0.3447 Accuracy 0.5410\n",
      "Epoch 36 Batch 900 Loss 0.3477 Accuracy 0.5409\n",
      "Epoch 36 Batch 950 Loss 0.3489 Accuracy 0.5406\n",
      "Epoch 36 Batch 1000 Loss 0.3495 Accuracy 0.5406\n",
      "Epoch 36 Batch 1050 Loss 0.3507 Accuracy 0.5405\n",
      "Epoch 36 Batch 1100 Loss 0.3522 Accuracy 0.5403\n",
      "Epoch 36 Batch 1150 Loss 0.3539 Accuracy 0.5402\n",
      "Epoch 36 Batch 1200 Loss 0.3553 Accuracy 0.5401\n",
      "Epoch 36 Loss 0.3562 Accuracy 0.5402\n",
      "Time taken for 1 epoch: 103.16528463363647 secs\n",
      "\n",
      "Epoch 37 Batch 0 Loss 0.2554 Accuracy 0.5516\n",
      "Epoch 37 Batch 50 Loss 0.2938 Accuracy 0.5434\n",
      "Epoch 37 Batch 100 Loss 0.2978 Accuracy 0.5448\n",
      "Epoch 37 Batch 150 Loss 0.3038 Accuracy 0.5444\n",
      "Epoch 37 Batch 200 Loss 0.3093 Accuracy 0.5436\n",
      "Epoch 37 Batch 250 Loss 0.3135 Accuracy 0.5433\n",
      "Epoch 37 Batch 300 Loss 0.3144 Accuracy 0.5430\n",
      "Epoch 37 Batch 350 Loss 0.3173 Accuracy 0.5426\n",
      "Epoch 37 Batch 400 Loss 0.3198 Accuracy 0.5423\n",
      "Epoch 37 Batch 450 Loss 0.3208 Accuracy 0.5427\n",
      "Epoch 37 Batch 500 Loss 0.3225 Accuracy 0.5426\n",
      "Epoch 37 Batch 550 Loss 0.3264 Accuracy 0.5423\n",
      "Epoch 37 Batch 600 Loss 0.3291 Accuracy 0.5419\n",
      "Epoch 37 Batch 650 Loss 0.3314 Accuracy 0.5416\n",
      "Epoch 37 Batch 700 Loss 0.3346 Accuracy 0.5413\n",
      "Epoch 37 Batch 750 Loss 0.3359 Accuracy 0.5414\n",
      "Epoch 37 Batch 800 Loss 0.3391 Accuracy 0.5413\n",
      "Epoch 37 Batch 850 Loss 0.3421 Accuracy 0.5411\n",
      "Epoch 37 Batch 900 Loss 0.3433 Accuracy 0.5411\n",
      "Epoch 37 Batch 950 Loss 0.3442 Accuracy 0.5409\n",
      "Epoch 37 Batch 1000 Loss 0.3459 Accuracy 0.5408\n",
      "Epoch 37 Batch 1050 Loss 0.3471 Accuracy 0.5406\n",
      "Epoch 37 Batch 1100 Loss 0.3491 Accuracy 0.5405\n",
      "Epoch 37 Batch 1150 Loss 0.3513 Accuracy 0.5404\n",
      "Epoch 37 Batch 1200 Loss 0.3532 Accuracy 0.5404\n",
      "Epoch 37 Loss 0.3542 Accuracy 0.5403\n",
      "Time taken for 1 epoch: 103.13258051872253 secs\n",
      "\n",
      "Epoch 38 Batch 0 Loss 0.2163 Accuracy 0.5609\n",
      "Epoch 38 Batch 50 Loss 0.3087 Accuracy 0.5414\n",
      "Epoch 38 Batch 100 Loss 0.3049 Accuracy 0.5429\n",
      "Epoch 38 Batch 150 Loss 0.3088 Accuracy 0.5435\n",
      "Epoch 38 Batch 200 Loss 0.3114 Accuracy 0.5438\n",
      "Epoch 38 Batch 250 Loss 0.3162 Accuracy 0.5429\n",
      "Epoch 38 Batch 300 Loss 0.3157 Accuracy 0.5430\n",
      "Epoch 38 Batch 350 Loss 0.3187 Accuracy 0.5431\n",
      "Epoch 38 Batch 400 Loss 0.3207 Accuracy 0.5434\n",
      "Epoch 38 Batch 450 Loss 0.3248 Accuracy 0.5430\n",
      "Epoch 38 Batch 500 Loss 0.3253 Accuracy 0.5430\n",
      "Epoch 38 Batch 550 Loss 0.3287 Accuracy 0.5425\n",
      "Epoch 38 Batch 600 Loss 0.3300 Accuracy 0.5423\n",
      "Epoch 38 Batch 650 Loss 0.3327 Accuracy 0.5423\n",
      "Epoch 38 Batch 700 Loss 0.3347 Accuracy 0.5420\n",
      "Epoch 38 Batch 750 Loss 0.3374 Accuracy 0.5419\n",
      "Epoch 38 Batch 800 Loss 0.3387 Accuracy 0.5418\n",
      "Epoch 38 Batch 850 Loss 0.3393 Accuracy 0.5417\n",
      "Epoch 38 Batch 900 Loss 0.3411 Accuracy 0.5417\n",
      "Epoch 38 Batch 950 Loss 0.3422 Accuracy 0.5415\n",
      "Epoch 38 Batch 1000 Loss 0.3438 Accuracy 0.5414\n",
      "Epoch 38 Batch 1050 Loss 0.3452 Accuracy 0.5413\n",
      "Epoch 38 Batch 1100 Loss 0.3466 Accuracy 0.5413\n",
      "Epoch 38 Batch 1150 Loss 0.3484 Accuracy 0.5410\n",
      "Epoch 38 Batch 1200 Loss 0.3505 Accuracy 0.5408\n",
      "Epoch 38 Loss 0.3515 Accuracy 0.5408\n",
      "Time taken for 1 epoch: 103.1380672454834 secs\n",
      "\n",
      "Epoch 39 Batch 0 Loss 0.3842 Accuracy 0.5453\n",
      "Epoch 39 Batch 50 Loss 0.2929 Accuracy 0.5457\n",
      "Epoch 39 Batch 100 Loss 0.2958 Accuracy 0.5447\n",
      "Epoch 39 Batch 150 Loss 0.3038 Accuracy 0.5444\n",
      "Epoch 39 Batch 200 Loss 0.3106 Accuracy 0.5436\n",
      "Epoch 39 Batch 250 Loss 0.3102 Accuracy 0.5436\n",
      "Epoch 39 Batch 300 Loss 0.3143 Accuracy 0.5434\n",
      "Epoch 39 Batch 350 Loss 0.3185 Accuracy 0.5432\n",
      "Epoch 39 Batch 400 Loss 0.3200 Accuracy 0.5432\n",
      "Epoch 39 Batch 450 Loss 0.3234 Accuracy 0.5426\n",
      "Epoch 39 Batch 500 Loss 0.3247 Accuracy 0.5430\n",
      "Epoch 39 Batch 550 Loss 0.3256 Accuracy 0.5428\n",
      "Epoch 39 Batch 600 Loss 0.3286 Accuracy 0.5427\n",
      "Epoch 39 Batch 650 Loss 0.3314 Accuracy 0.5425\n",
      "Epoch 39 Batch 700 Loss 0.3314 Accuracy 0.5425\n",
      "Epoch 39 Batch 750 Loss 0.3337 Accuracy 0.5424\n",
      "Epoch 39 Batch 800 Loss 0.3347 Accuracy 0.5423\n",
      "Epoch 39 Batch 850 Loss 0.3366 Accuracy 0.5422\n",
      "Epoch 39 Batch 900 Loss 0.3389 Accuracy 0.5420\n",
      "Epoch 39 Batch 950 Loss 0.3404 Accuracy 0.5417\n",
      "Epoch 39 Batch 1000 Loss 0.3410 Accuracy 0.5417\n",
      "Epoch 39 Batch 1050 Loss 0.3419 Accuracy 0.5416\n",
      "Epoch 39 Batch 1100 Loss 0.3430 Accuracy 0.5415\n",
      "Epoch 39 Batch 1150 Loss 0.3442 Accuracy 0.5415\n",
      "Epoch 39 Batch 1200 Loss 0.3467 Accuracy 0.5413\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39 Loss 0.3482 Accuracy 0.5411\n",
      "Time taken for 1 epoch: 103.07581353187561 secs\n",
      "\n",
      "Epoch 40 Batch 0 Loss 0.3366 Accuracy 0.5406\n",
      "Epoch 40 Batch 50 Loss 0.2926 Accuracy 0.5450\n",
      "Epoch 40 Batch 100 Loss 0.3031 Accuracy 0.5449\n",
      "Epoch 40 Batch 150 Loss 0.3046 Accuracy 0.5441\n",
      "Epoch 40 Batch 200 Loss 0.3018 Accuracy 0.5453\n",
      "Epoch 40 Batch 250 Loss 0.3057 Accuracy 0.5449\n",
      "Epoch 40 Batch 300 Loss 0.3088 Accuracy 0.5443\n",
      "Epoch 40 Batch 350 Loss 0.3137 Accuracy 0.5435\n",
      "Epoch 40 Batch 400 Loss 0.3168 Accuracy 0.5435\n",
      "Epoch 40 Batch 450 Loss 0.3171 Accuracy 0.5432\n",
      "Epoch 40 Batch 500 Loss 0.3188 Accuracy 0.5430\n",
      "Epoch 40 Batch 550 Loss 0.3203 Accuracy 0.5429\n",
      "Epoch 40 Batch 600 Loss 0.3230 Accuracy 0.5430\n",
      "Epoch 40 Batch 650 Loss 0.3245 Accuracy 0.5429\n",
      "Epoch 40 Batch 700 Loss 0.3251 Accuracy 0.5431\n",
      "Epoch 40 Batch 750 Loss 0.3266 Accuracy 0.5429\n",
      "Epoch 40 Batch 800 Loss 0.3284 Accuracy 0.5428\n",
      "Epoch 40 Batch 850 Loss 0.3305 Accuracy 0.5428\n",
      "Epoch 40 Batch 900 Loss 0.3323 Accuracy 0.5427\n",
      "Epoch 40 Batch 950 Loss 0.3339 Accuracy 0.5425\n",
      "Epoch 40 Batch 1000 Loss 0.3352 Accuracy 0.5426\n",
      "Epoch 40 Batch 1050 Loss 0.3367 Accuracy 0.5424\n",
      "Epoch 40 Batch 1100 Loss 0.3396 Accuracy 0.5421\n",
      "Epoch 40 Batch 1150 Loss 0.3416 Accuracy 0.5419\n",
      "Epoch 40 Batch 1200 Loss 0.3430 Accuracy 0.5419\n",
      "Saving checkpoint for epoch 40 at ./checkpoints/train\\ckpt-8\n",
      "Epoch 40 Loss 0.3445 Accuracy 0.5417\n",
      "Time taken for 1 epoch: 103.79936361312866 secs\n",
      "\n",
      "Epoch 41 Batch 0 Loss 0.3266 Accuracy 0.5500\n",
      "Epoch 41 Batch 50 Loss 0.2897 Accuracy 0.5470\n",
      "Epoch 41 Batch 100 Loss 0.2929 Accuracy 0.5462\n",
      "Epoch 41 Batch 150 Loss 0.2908 Accuracy 0.5459\n",
      "Epoch 41 Batch 200 Loss 0.2935 Accuracy 0.5448\n",
      "Epoch 41 Batch 250 Loss 0.2966 Accuracy 0.5444\n",
      "Epoch 41 Batch 300 Loss 0.3004 Accuracy 0.5447\n",
      "Epoch 41 Batch 350 Loss 0.3054 Accuracy 0.5440\n",
      "Epoch 41 Batch 400 Loss 0.3081 Accuracy 0.5439\n",
      "Epoch 41 Batch 450 Loss 0.3094 Accuracy 0.5438\n",
      "Epoch 41 Batch 500 Loss 0.3133 Accuracy 0.5435\n",
      "Epoch 41 Batch 550 Loss 0.3149 Accuracy 0.5433\n",
      "Epoch 41 Batch 600 Loss 0.3178 Accuracy 0.5430\n",
      "Epoch 41 Batch 650 Loss 0.3209 Accuracy 0.5429\n",
      "Epoch 41 Batch 700 Loss 0.3236 Accuracy 0.5428\n",
      "Epoch 41 Batch 750 Loss 0.3254 Accuracy 0.5427\n",
      "Epoch 41 Batch 800 Loss 0.3261 Accuracy 0.5427\n",
      "Epoch 41 Batch 850 Loss 0.3290 Accuracy 0.5426\n",
      "Epoch 41 Batch 900 Loss 0.3305 Accuracy 0.5425\n",
      "Epoch 41 Batch 950 Loss 0.3328 Accuracy 0.5423\n",
      "Epoch 41 Batch 1000 Loss 0.3342 Accuracy 0.5422\n",
      "Epoch 41 Batch 1050 Loss 0.3362 Accuracy 0.5422\n",
      "Epoch 41 Batch 1100 Loss 0.3380 Accuracy 0.5420\n",
      "Epoch 41 Batch 1150 Loss 0.3396 Accuracy 0.5418\n",
      "Epoch 41 Batch 1200 Loss 0.3409 Accuracy 0.5418\n",
      "Epoch 41 Loss 0.3421 Accuracy 0.5417\n",
      "Time taken for 1 epoch: 103.28448677062988 secs\n",
      "\n",
      "Epoch 42 Batch 0 Loss 0.3753 Accuracy 0.5547\n",
      "Epoch 42 Batch 50 Loss 0.2848 Accuracy 0.5472\n",
      "Epoch 42 Batch 100 Loss 0.2856 Accuracy 0.5454\n",
      "Epoch 42 Batch 150 Loss 0.2881 Accuracy 0.5446\n",
      "Epoch 42 Batch 200 Loss 0.2884 Accuracy 0.5453\n",
      "Epoch 42 Batch 250 Loss 0.2910 Accuracy 0.5454\n",
      "Epoch 42 Batch 300 Loss 0.2948 Accuracy 0.5449\n",
      "Epoch 42 Batch 350 Loss 0.2994 Accuracy 0.5449\n",
      "Epoch 42 Batch 400 Loss 0.3015 Accuracy 0.5444\n",
      "Epoch 42 Batch 450 Loss 0.3041 Accuracy 0.5444\n",
      "Epoch 42 Batch 500 Loss 0.3075 Accuracy 0.5442\n",
      "Epoch 42 Batch 550 Loss 0.3108 Accuracy 0.5440\n",
      "Epoch 42 Batch 600 Loss 0.3133 Accuracy 0.5439\n",
      "Epoch 42 Batch 650 Loss 0.3151 Accuracy 0.5439\n",
      "Epoch 42 Batch 700 Loss 0.3194 Accuracy 0.5434\n",
      "Epoch 42 Batch 750 Loss 0.3205 Accuracy 0.5435\n",
      "Epoch 42 Batch 800 Loss 0.3219 Accuracy 0.5435\n",
      "Epoch 42 Batch 850 Loss 0.3232 Accuracy 0.5435\n",
      "Epoch 42 Batch 900 Loss 0.3247 Accuracy 0.5435\n",
      "Epoch 42 Batch 950 Loss 0.3269 Accuracy 0.5433\n",
      "Epoch 42 Batch 1000 Loss 0.3293 Accuracy 0.5431\n",
      "Epoch 42 Batch 1050 Loss 0.3315 Accuracy 0.5430\n",
      "Epoch 42 Batch 1100 Loss 0.3324 Accuracy 0.5429\n",
      "Epoch 42 Batch 1150 Loss 0.3339 Accuracy 0.5427\n",
      "Epoch 42 Batch 1200 Loss 0.3353 Accuracy 0.5426\n",
      "Epoch 42 Loss 0.3368 Accuracy 0.5426\n",
      "Time taken for 1 epoch: 103.32305431365967 secs\n",
      "\n",
      "Epoch 43 Batch 0 Loss 0.4003 Accuracy 0.5297\n",
      "Epoch 43 Batch 50 Loss 0.2816 Accuracy 0.5491\n",
      "Epoch 43 Batch 100 Loss 0.2947 Accuracy 0.5483\n",
      "Epoch 43 Batch 150 Loss 0.2978 Accuracy 0.5476\n",
      "Epoch 43 Batch 200 Loss 0.3028 Accuracy 0.5460\n",
      "Epoch 43 Batch 250 Loss 0.3033 Accuracy 0.5457\n",
      "Epoch 43 Batch 300 Loss 0.3015 Accuracy 0.5460\n",
      "Epoch 43 Batch 350 Loss 0.3028 Accuracy 0.5458\n",
      "Epoch 43 Batch 400 Loss 0.3060 Accuracy 0.5452\n",
      "Epoch 43 Batch 450 Loss 0.3063 Accuracy 0.5451\n",
      "Epoch 43 Batch 500 Loss 0.3094 Accuracy 0.5449\n",
      "Epoch 43 Batch 550 Loss 0.3126 Accuracy 0.5447\n",
      "Epoch 43 Batch 600 Loss 0.3142 Accuracy 0.5445\n",
      "Epoch 43 Batch 650 Loss 0.3172 Accuracy 0.5443\n",
      "Epoch 43 Batch 700 Loss 0.3197 Accuracy 0.5442\n",
      "Epoch 43 Batch 750 Loss 0.3213 Accuracy 0.5440\n",
      "Epoch 43 Batch 800 Loss 0.3218 Accuracy 0.5441\n",
      "Epoch 43 Batch 850 Loss 0.3249 Accuracy 0.5437\n",
      "Epoch 43 Batch 900 Loss 0.3260 Accuracy 0.5436\n",
      "Epoch 43 Batch 950 Loss 0.3277 Accuracy 0.5435\n",
      "Epoch 43 Batch 1000 Loss 0.3289 Accuracy 0.5435\n",
      "Epoch 43 Batch 1050 Loss 0.3298 Accuracy 0.5433\n",
      "Epoch 43 Batch 1100 Loss 0.3316 Accuracy 0.5430\n",
      "Epoch 43 Batch 1150 Loss 0.3326 Accuracy 0.5430\n",
      "Epoch 43 Batch 1200 Loss 0.3336 Accuracy 0.5430\n",
      "Epoch 43 Loss 0.3352 Accuracy 0.5429\n",
      "Time taken for 1 epoch: 103.30194902420044 secs\n",
      "\n",
      "Epoch 44 Batch 0 Loss 0.2395 Accuracy 0.5672\n",
      "Epoch 44 Batch 50 Loss 0.2943 Accuracy 0.5460\n",
      "Epoch 44 Batch 100 Loss 0.2977 Accuracy 0.5470\n",
      "Epoch 44 Batch 150 Loss 0.2998 Accuracy 0.5453\n",
      "Epoch 44 Batch 200 Loss 0.2980 Accuracy 0.5455\n",
      "Epoch 44 Batch 250 Loss 0.2995 Accuracy 0.5450\n",
      "Epoch 44 Batch 300 Loss 0.2989 Accuracy 0.5449\n",
      "Epoch 44 Batch 350 Loss 0.3035 Accuracy 0.5443\n",
      "Epoch 44 Batch 400 Loss 0.3064 Accuracy 0.5444\n",
      "Epoch 44 Batch 450 Loss 0.3070 Accuracy 0.5443\n",
      "Epoch 44 Batch 500 Loss 0.3084 Accuracy 0.5441\n",
      "Epoch 44 Batch 550 Loss 0.3092 Accuracy 0.5440\n",
      "Epoch 44 Batch 600 Loss 0.3110 Accuracy 0.5442\n",
      "Epoch 44 Batch 650 Loss 0.3126 Accuracy 0.5443\n",
      "Epoch 44 Batch 700 Loss 0.3150 Accuracy 0.5443\n",
      "Epoch 44 Batch 750 Loss 0.3172 Accuracy 0.5442\n",
      "Epoch 44 Batch 800 Loss 0.3192 Accuracy 0.5441\n",
      "Epoch 44 Batch 850 Loss 0.3211 Accuracy 0.5440\n",
      "Epoch 44 Batch 900 Loss 0.3230 Accuracy 0.5439\n",
      "Epoch 44 Batch 950 Loss 0.3249 Accuracy 0.5438\n",
      "Epoch 44 Batch 1000 Loss 0.3265 Accuracy 0.5436\n",
      "Epoch 44 Batch 1050 Loss 0.3291 Accuracy 0.5434\n",
      "Epoch 44 Batch 1100 Loss 0.3316 Accuracy 0.5432\n",
      "Epoch 44 Batch 1150 Loss 0.3332 Accuracy 0.5431\n",
      "Epoch 44 Batch 1200 Loss 0.3341 Accuracy 0.5431\n",
      "Epoch 44 Loss 0.3361 Accuracy 0.5429\n",
      "Time taken for 1 epoch: 103.3493115901947 secs\n",
      "\n",
      "Epoch 45 Batch 0 Loss 0.2794 Accuracy 0.5500\n",
      "Epoch 45 Batch 50 Loss 0.2804 Accuracy 0.5462\n",
      "Epoch 45 Batch 100 Loss 0.2846 Accuracy 0.5467\n",
      "Epoch 45 Batch 150 Loss 0.2896 Accuracy 0.5452\n",
      "Epoch 45 Batch 200 Loss 0.2911 Accuracy 0.5457\n",
      "Epoch 45 Batch 250 Loss 0.2928 Accuracy 0.5461\n",
      "Epoch 45 Batch 300 Loss 0.2957 Accuracy 0.5457\n",
      "Epoch 45 Batch 350 Loss 0.2985 Accuracy 0.5455\n",
      "Epoch 45 Batch 400 Loss 0.3014 Accuracy 0.5451\n",
      "Epoch 45 Batch 450 Loss 0.3055 Accuracy 0.5450\n",
      "Epoch 45 Batch 500 Loss 0.3072 Accuracy 0.5449\n",
      "Epoch 45 Batch 550 Loss 0.3093 Accuracy 0.5448\n",
      "Epoch 45 Batch 600 Loss 0.3117 Accuracy 0.5446\n",
      "Epoch 45 Batch 650 Loss 0.3118 Accuracy 0.5448\n",
      "Epoch 45 Batch 700 Loss 0.3132 Accuracy 0.5445\n",
      "Epoch 45 Batch 750 Loss 0.3148 Accuracy 0.5444\n",
      "Epoch 45 Batch 800 Loss 0.3166 Accuracy 0.5446\n",
      "Epoch 45 Batch 850 Loss 0.3181 Accuracy 0.5445\n",
      "Epoch 45 Batch 900 Loss 0.3198 Accuracy 0.5444\n",
      "Epoch 45 Batch 950 Loss 0.3226 Accuracy 0.5441\n",
      "Epoch 45 Batch 1000 Loss 0.3229 Accuracy 0.5441\n",
      "Epoch 45 Batch 1050 Loss 0.3250 Accuracy 0.5439\n",
      "Epoch 45 Batch 1100 Loss 0.3265 Accuracy 0.5438\n",
      "Epoch 45 Batch 1150 Loss 0.3281 Accuracy 0.5437\n",
      "Epoch 45 Batch 1200 Loss 0.3303 Accuracy 0.5435\n",
      "Saving checkpoint for epoch 45 at ./checkpoints/train\\ckpt-9\n",
      "Epoch 45 Loss 0.3320 Accuracy 0.5434\n",
      "Time taken for 1 epoch: 104.4780855178833 secs\n",
      "\n",
      "Epoch 46 Batch 0 Loss 0.4800 Accuracy 0.5234\n",
      "Epoch 46 Batch 50 Loss 0.2892 Accuracy 0.5469\n",
      "Epoch 46 Batch 100 Loss 0.2872 Accuracy 0.5475\n",
      "Epoch 46 Batch 150 Loss 0.2879 Accuracy 0.5464\n",
      "Epoch 46 Batch 200 Loss 0.2928 Accuracy 0.5460\n",
      "Epoch 46 Batch 250 Loss 0.2939 Accuracy 0.5457\n",
      "Epoch 46 Batch 300 Loss 0.2914 Accuracy 0.5460\n",
      "Epoch 46 Batch 350 Loss 0.2934 Accuracy 0.5457\n",
      "Epoch 46 Batch 400 Loss 0.2950 Accuracy 0.5456\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46 Batch 450 Loss 0.2973 Accuracy 0.5455\n",
      "Epoch 46 Batch 500 Loss 0.2993 Accuracy 0.5453\n",
      "Epoch 46 Batch 550 Loss 0.3002 Accuracy 0.5452\n",
      "Epoch 46 Batch 600 Loss 0.3027 Accuracy 0.5452\n",
      "Epoch 46 Batch 650 Loss 0.3058 Accuracy 0.5448\n",
      "Epoch 46 Batch 700 Loss 0.3099 Accuracy 0.5446\n",
      "Epoch 46 Batch 750 Loss 0.3128 Accuracy 0.5445\n",
      "Epoch 46 Batch 800 Loss 0.3146 Accuracy 0.5445\n",
      "Epoch 46 Batch 850 Loss 0.3168 Accuracy 0.5444\n",
      "Epoch 46 Batch 900 Loss 0.3195 Accuracy 0.5442\n",
      "Epoch 46 Batch 950 Loss 0.3209 Accuracy 0.5441\n",
      "Epoch 46 Batch 1000 Loss 0.3236 Accuracy 0.5438\n",
      "Epoch 46 Batch 1050 Loss 0.3253 Accuracy 0.5437\n",
      "Epoch 46 Batch 1100 Loss 0.3266 Accuracy 0.5437\n",
      "Epoch 46 Batch 1150 Loss 0.3273 Accuracy 0.5437\n",
      "Epoch 46 Batch 1200 Loss 0.3285 Accuracy 0.5436\n",
      "Epoch 46 Loss 0.3292 Accuracy 0.5435\n",
      "Time taken for 1 epoch: 103.07547187805176 secs\n",
      "\n",
      "Epoch 47 Batch 0 Loss 0.2421 Accuracy 0.5594\n",
      "Epoch 47 Batch 50 Loss 0.2740 Accuracy 0.5502\n",
      "Epoch 47 Batch 100 Loss 0.2742 Accuracy 0.5472\n",
      "Epoch 47 Batch 150 Loss 0.2839 Accuracy 0.5466\n",
      "Epoch 47 Batch 200 Loss 0.2881 Accuracy 0.5460\n",
      "Epoch 47 Batch 250 Loss 0.2881 Accuracy 0.5459\n",
      "Epoch 47 Batch 300 Loss 0.2920 Accuracy 0.5455\n",
      "Epoch 47 Batch 350 Loss 0.2947 Accuracy 0.5452\n",
      "Epoch 47 Batch 400 Loss 0.2953 Accuracy 0.5451\n",
      "Epoch 47 Batch 450 Loss 0.2972 Accuracy 0.5452\n",
      "Epoch 47 Batch 500 Loss 0.2997 Accuracy 0.5451\n",
      "Epoch 47 Batch 550 Loss 0.3027 Accuracy 0.5450\n",
      "Epoch 47 Batch 600 Loss 0.3050 Accuracy 0.5449\n",
      "Epoch 47 Batch 650 Loss 0.3069 Accuracy 0.5451\n",
      "Epoch 47 Batch 700 Loss 0.3099 Accuracy 0.5448\n",
      "Epoch 47 Batch 750 Loss 0.3114 Accuracy 0.5448\n",
      "Epoch 47 Batch 800 Loss 0.3137 Accuracy 0.5447\n",
      "Epoch 47 Batch 850 Loss 0.3140 Accuracy 0.5447\n",
      "Epoch 47 Batch 900 Loss 0.3170 Accuracy 0.5445\n",
      "Epoch 47 Batch 950 Loss 0.3187 Accuracy 0.5446\n",
      "Epoch 47 Batch 1000 Loss 0.3201 Accuracy 0.5444\n",
      "Epoch 47 Batch 1050 Loss 0.3209 Accuracy 0.5443\n",
      "Epoch 47 Batch 1100 Loss 0.3220 Accuracy 0.5440\n",
      "Epoch 47 Batch 1150 Loss 0.3236 Accuracy 0.5439\n",
      "Epoch 47 Batch 1200 Loss 0.3253 Accuracy 0.5439\n",
      "Epoch 47 Loss 0.3269 Accuracy 0.5438\n",
      "Time taken for 1 epoch: 103.07547664642334 secs\n",
      "\n",
      "Epoch 48 Batch 0 Loss 0.2630 Accuracy 0.5500\n",
      "Epoch 48 Batch 50 Loss 0.2686 Accuracy 0.5498\n",
      "Epoch 48 Batch 100 Loss 0.2816 Accuracy 0.5478\n",
      "Epoch 48 Batch 150 Loss 0.2804 Accuracy 0.5479\n",
      "Epoch 48 Batch 200 Loss 0.2836 Accuracy 0.5471\n",
      "Epoch 48 Batch 250 Loss 0.2912 Accuracy 0.5463\n",
      "Epoch 48 Batch 300 Loss 0.2937 Accuracy 0.5466\n",
      "Epoch 48 Batch 350 Loss 0.2957 Accuracy 0.5464\n",
      "Epoch 48 Batch 400 Loss 0.2981 Accuracy 0.5466\n",
      "Epoch 48 Batch 450 Loss 0.2972 Accuracy 0.5467\n",
      "Epoch 48 Batch 500 Loss 0.2986 Accuracy 0.5465\n",
      "Epoch 48 Batch 550 Loss 0.3019 Accuracy 0.5461\n",
      "Epoch 48 Batch 600 Loss 0.3045 Accuracy 0.5458\n",
      "Epoch 48 Batch 650 Loss 0.3048 Accuracy 0.5457\n",
      "Epoch 48 Batch 700 Loss 0.3068 Accuracy 0.5456\n",
      "Epoch 48 Batch 750 Loss 0.3089 Accuracy 0.5454\n",
      "Epoch 48 Batch 800 Loss 0.3097 Accuracy 0.5453\n",
      "Epoch 48 Batch 850 Loss 0.3123 Accuracy 0.5452\n",
      "Epoch 48 Batch 900 Loss 0.3148 Accuracy 0.5450\n",
      "Epoch 48 Batch 950 Loss 0.3167 Accuracy 0.5449\n",
      "Epoch 48 Batch 1000 Loss 0.3179 Accuracy 0.5447\n",
      "Epoch 48 Batch 1050 Loss 0.3191 Accuracy 0.5446\n",
      "Epoch 48 Batch 1100 Loss 0.3210 Accuracy 0.5445\n",
      "Epoch 48 Batch 1150 Loss 0.3231 Accuracy 0.5442\n",
      "Epoch 48 Batch 1200 Loss 0.3249 Accuracy 0.5442\n",
      "Epoch 48 Loss 0.3265 Accuracy 0.5440\n",
      "Time taken for 1 epoch: 103.05152583122253 secs\n",
      "\n",
      "Epoch 49 Batch 0 Loss 0.2212 Accuracy 0.5688\n",
      "Epoch 49 Batch 50 Loss 0.2720 Accuracy 0.5483\n",
      "Epoch 49 Batch 100 Loss 0.2751 Accuracy 0.5487\n",
      "Epoch 49 Batch 150 Loss 0.2796 Accuracy 0.5476\n",
      "Epoch 49 Batch 200 Loss 0.2833 Accuracy 0.5475\n",
      "Epoch 49 Batch 250 Loss 0.2868 Accuracy 0.5468\n",
      "Epoch 49 Batch 300 Loss 0.2889 Accuracy 0.5467\n",
      "Epoch 49 Batch 350 Loss 0.2902 Accuracy 0.5464\n",
      "Epoch 49 Batch 400 Loss 0.2918 Accuracy 0.5461\n",
      "Epoch 49 Batch 450 Loss 0.2956 Accuracy 0.5461\n",
      "Epoch 49 Batch 500 Loss 0.2964 Accuracy 0.5461\n",
      "Epoch 49 Batch 550 Loss 0.2976 Accuracy 0.5462\n",
      "Epoch 49 Batch 600 Loss 0.2997 Accuracy 0.5461\n",
      "Epoch 49 Batch 650 Loss 0.3021 Accuracy 0.5463\n",
      "Epoch 49 Batch 700 Loss 0.3043 Accuracy 0.5461\n",
      "Epoch 49 Batch 750 Loss 0.3061 Accuracy 0.5458\n",
      "Epoch 49 Batch 800 Loss 0.3079 Accuracy 0.5457\n",
      "Epoch 49 Batch 850 Loss 0.3096 Accuracy 0.5457\n",
      "Epoch 49 Batch 900 Loss 0.3113 Accuracy 0.5456\n",
      "Epoch 49 Batch 950 Loss 0.3119 Accuracy 0.5455\n",
      "Epoch 49 Batch 1000 Loss 0.3130 Accuracy 0.5455\n",
      "Epoch 49 Batch 1050 Loss 0.3144 Accuracy 0.5454\n",
      "Epoch 49 Batch 1100 Loss 0.3162 Accuracy 0.5452\n",
      "Epoch 49 Batch 1150 Loss 0.3183 Accuracy 0.5451\n",
      "Epoch 49 Batch 1200 Loss 0.3193 Accuracy 0.5449\n",
      "Epoch 49 Loss 0.3207 Accuracy 0.5447\n",
      "Time taken for 1 epoch: 103.96951270103455 secs\n",
      "\n",
      "Epoch 50 Batch 0 Loss 0.2457 Accuracy 0.5500\n",
      "Epoch 50 Batch 50 Loss 0.2796 Accuracy 0.5472\n",
      "Epoch 50 Batch 100 Loss 0.2746 Accuracy 0.5469\n",
      "Epoch 50 Batch 150 Loss 0.2714 Accuracy 0.5471\n",
      "Epoch 50 Batch 200 Loss 0.2733 Accuracy 0.5478\n",
      "Epoch 50 Batch 250 Loss 0.2799 Accuracy 0.5472\n",
      "Epoch 50 Batch 300 Loss 0.2834 Accuracy 0.5471\n",
      "Epoch 50 Batch 350 Loss 0.2864 Accuracy 0.5471\n",
      "Epoch 50 Batch 400 Loss 0.2900 Accuracy 0.5468\n",
      "Epoch 50 Batch 450 Loss 0.2919 Accuracy 0.5464\n",
      "Epoch 50 Batch 500 Loss 0.2949 Accuracy 0.5460\n",
      "Epoch 50 Batch 550 Loss 0.2977 Accuracy 0.5459\n",
      "Epoch 50 Batch 600 Loss 0.3006 Accuracy 0.5458\n",
      "Epoch 50 Batch 650 Loss 0.3031 Accuracy 0.5456\n",
      "Epoch 50 Batch 700 Loss 0.3041 Accuracy 0.5456\n",
      "Epoch 50 Batch 750 Loss 0.3057 Accuracy 0.5455\n",
      "Epoch 50 Batch 800 Loss 0.3076 Accuracy 0.5452\n",
      "Epoch 50 Batch 850 Loss 0.3096 Accuracy 0.5452\n",
      "Epoch 50 Batch 900 Loss 0.3111 Accuracy 0.5450\n",
      "Epoch 50 Batch 950 Loss 0.3116 Accuracy 0.5450\n",
      "Epoch 50 Batch 1000 Loss 0.3137 Accuracy 0.5448\n",
      "Epoch 50 Batch 1050 Loss 0.3144 Accuracy 0.5449\n",
      "Epoch 50 Batch 1100 Loss 0.3152 Accuracy 0.5449\n",
      "Epoch 50 Batch 1150 Loss 0.3164 Accuracy 0.5448\n",
      "Epoch 50 Batch 1200 Loss 0.3175 Accuracy 0.5449\n",
      "Saving checkpoint for epoch 50 at ./checkpoints/train\\ckpt-10\n",
      "Epoch 50 Loss 0.3183 Accuracy 0.5449\n",
      "Time taken for 1 epoch: 103.99351859092712 secs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "  start = time.time()\n",
    "  \n",
    "  train_loss.reset_states()\n",
    "  train_accuracy.reset_states()\n",
    "  \n",
    "  # inp -> portuguese, tar -> english\n",
    "  for (batch, (inp, tar)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "    train_step(inp, tar)\n",
    "    \n",
    "    if batch % 50 == 0:\n",
    "      print ('Epoch {} Batch {} Loss {:.4f} Accuracy {:.4f}'.format(\n",
    "          epoch + 1, batch, train_loss.result(), train_accuracy.result()))\n",
    "      \n",
    "  if (epoch + 1) % 5 == 0:\n",
    "    ckpt_save_path = ckpt_manager.save()\n",
    "    print ('Saving checkpoint for epoch {} at {}'.format(epoch+1,\n",
    "                                                         ckpt_save_path))\n",
    "    \n",
    "  print ('Epoch {} Loss {:.4f} Accuracy {:.4f}'.format(epoch + 1, \n",
    "                                                train_loss.result(), \n",
    "                                                train_accuracy.result()))\n",
    "\n",
    "  print ('Time taken for 1 epoch: {} secs\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QfcsSWswSdGV"
   },
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y6APsFrgImLW"
   },
   "source": [
    "Для оценки используются следующие шаги:\n",
    "\n",
    "Закодируйте входное предложение с помощью русского токенизатора ( tokenizer_pt ). Кроме того, добавьте начальный и конечный токены, чтобы ввод был эквивалентен тому, с чем обучается модель. Это вход энкодера.\n",
    "Вход декодера - это start token == tokenizer_en.vocab_size .\n",
    "Рассчитайте маски заполнения и маски прогнозирования.\n",
    "Затем decoder выводит прогнозы, глядя на encoder output и собственные выходные данные (самовнимание).\n",
    "Выберите последнее слово и вычислите его argmax.\n",
    "Конкатентируйте предсказанное слово на вход декодера при передаче его в декодер.\n",
    "В этом подходе декодер предсказывает следующее слово на основе предсказанных им предыдущих слов.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<start>': 1,\n",
       " '<end>': 2,\n",
       " '.': 3,\n",
       " 'i': 4,\n",
       " 'tom': 5,\n",
       " '?': 6,\n",
       " 'you': 7,\n",
       " 'is': 8,\n",
       " 'a': 9,\n",
       " 'it': 10,\n",
       " 'to': 11,\n",
       " 'the': 12,\n",
       " \"i'm\": 13,\n",
       " 'me': 14,\n",
       " 'do': 15,\n",
       " 'was': 16,\n",
       " 'that': 17,\n",
       " 'we': 18,\n",
       " 'this': 19,\n",
       " \"don't\": 20,\n",
       " 'my': 21,\n",
       " 'are': 22,\n",
       " 'your': 23,\n",
       " 'have': 24,\n",
       " 'did': 25,\n",
       " 'can': 26,\n",
       " 'he': 27,\n",
       " 'go': 28,\n",
       " \"you're\": 29,\n",
       " \"it's\": 30,\n",
       " 'like': 31,\n",
       " 'not': 32,\n",
       " 'be': 33,\n",
       " 'know': 34,\n",
       " 'in': 35,\n",
       " \"i'll\": 36,\n",
       " 'what': 37,\n",
       " 'here': 38,\n",
       " 'they': 39,\n",
       " ',': 40,\n",
       " 'need': 41,\n",
       " 'want': 42,\n",
       " 'on': 43,\n",
       " 'how': 44,\n",
       " \"can't\": 45,\n",
       " 'very': 46,\n",
       " 'now': 47,\n",
       " 'why': 48,\n",
       " 'for': 49,\n",
       " 'help': 50,\n",
       " 'us': 51,\n",
       " 'will': 52,\n",
       " 'at': 53,\n",
       " 'one': 54,\n",
       " '!': 55,\n",
       " 'up': 56,\n",
       " 'so': 57,\n",
       " 'has': 58,\n",
       " 'all': 59,\n",
       " \"didn't\": 60,\n",
       " 'get': 61,\n",
       " 'with': 62,\n",
       " 'who': 63,\n",
       " 'of': 64,\n",
       " \"that's\": 65,\n",
       " \"we're\": 66,\n",
       " 'got': 67,\n",
       " 'come': 68,\n",
       " 'too': 69,\n",
       " \"let's\": 70,\n",
       " 'no': 71,\n",
       " 'just': 72,\n",
       " 'there': 73,\n",
       " 'she': 74,\n",
       " 'see': 75,\n",
       " \"tom's\": 76,\n",
       " 'please': 77,\n",
       " \"won't\": 78,\n",
       " 'were': 79,\n",
       " \"isn't\": 80,\n",
       " \"i've\": 81,\n",
       " 'look': 82,\n",
       " 'think': 83,\n",
       " 'home': 84,\n",
       " 'take': 85,\n",
       " 'tell': 86,\n",
       " 'him': 87,\n",
       " 'stop': 88,\n",
       " 'let': 89,\n",
       " 'out': 90,\n",
       " 'give': 91,\n",
       " 'mary': 92,\n",
       " 'leave': 93,\n",
       " 'back': 94,\n",
       " 'good': 95,\n",
       " 'an': 96,\n",
       " 'still': 97,\n",
       " 'his': 98,\n",
       " 'never': 99,\n",
       " 'them': 100,\n",
       " 'call': 101,\n",
       " 'am': 102,\n",
       " 'love': 103,\n",
       " 'where': 104,\n",
       " 'car': 105,\n",
       " 'work': 106,\n",
       " 'had': 107,\n",
       " 'eat': 108,\n",
       " 'try': 109,\n",
       " 'must': 110,\n",
       " 'saw': 111,\n",
       " 'does': 112,\n",
       " 'stay': 113,\n",
       " 'going': 114,\n",
       " 'her': 115,\n",
       " 'again': 116,\n",
       " 'wait': 117,\n",
       " \"he's\": 118,\n",
       " 'may': 119,\n",
       " \"wasn't\": 120,\n",
       " 'really': 121,\n",
       " 'find': 122,\n",
       " \"they're\": 123,\n",
       " 'alone': 124,\n",
       " 'time': 125,\n",
       " \"we'll\": 126,\n",
       " 'should': 127,\n",
       " 'ask': 128,\n",
       " 'made': 129,\n",
       " 'happy': 130,\n",
       " 'about': 131,\n",
       " 'talk': 132,\n",
       " 'busy': 133,\n",
       " 'left': 134,\n",
       " 'right': 135,\n",
       " 'put': 136,\n",
       " 'could': 137,\n",
       " 'say': 138,\n",
       " 'win': 139,\n",
       " 'dog': 140,\n",
       " 'knew': 141,\n",
       " 'said': 142,\n",
       " 'today': 143,\n",
       " 'lost': 144,\n",
       " 'hate': 145,\n",
       " 'much': 146,\n",
       " 'down': 147,\n",
       " 'hope': 148,\n",
       " 'went': 149,\n",
       " 'well': 150,\n",
       " 'some': 151,\n",
       " 'and': 152,\n",
       " 'told': 153,\n",
       " 'lot': 154,\n",
       " 'tired': 155,\n",
       " 'wrong': 156,\n",
       " \"aren't\": 157,\n",
       " 'both': 158,\n",
       " \"what's\": 159,\n",
       " 'buy': 160,\n",
       " 'bad': 161,\n",
       " 'feel': 162,\n",
       " 'when': 163,\n",
       " 'job': 164,\n",
       " 'ready': 165,\n",
       " 'off': 166,\n",
       " 'open': 167,\n",
       " 'read': 168,\n",
       " 'make': 169,\n",
       " 'away': 170,\n",
       " 'already': 171,\n",
       " 'hungry': 172,\n",
       " 'yet': 173,\n",
       " 'keep': 174,\n",
       " 'money': 175,\n",
       " 'our': 176,\n",
       " 'old': 177,\n",
       " 'new': 178,\n",
       " \"i'd\": 179,\n",
       " 'came': 180,\n",
       " 'miss': 181,\n",
       " \"you'll\": 182,\n",
       " 'room': 183,\n",
       " 'ok': 184,\n",
       " 'book': 185,\n",
       " 'likes': 186,\n",
       " 'would': 187,\n",
       " 'everyone': 188,\n",
       " 'late': 189,\n",
       " 'sick': 190,\n",
       " \"where's\": 191,\n",
       " 'wanted': 192,\n",
       " 'better': 193,\n",
       " 'nobody': 194,\n",
       " 'sing': 195,\n",
       " 'been': 196,\n",
       " 'found': 197,\n",
       " 'more': 198,\n",
       " 'gave': 199,\n",
       " 'by': 200,\n",
       " 'tried': 201,\n",
       " 'day': 202,\n",
       " \"you've\": 203,\n",
       " 'cold': 204,\n",
       " 'mine': 205,\n",
       " 'hurt': 206,\n",
       " 'heard': 207,\n",
       " 'always': 208,\n",
       " 'glad': 209,\n",
       " 'over': 210,\n",
       " 'drink': 211,\n",
       " 'done': 212,\n",
       " 'french': 213,\n",
       " 'house': 214,\n",
       " 'boston': 215,\n",
       " 'play': 216,\n",
       " 'trust': 217,\n",
       " 'sure': 218,\n",
       " 'big': 219,\n",
       " 'man': 220,\n",
       " 'cat': 221,\n",
       " 'nothing': 222,\n",
       " 'called': 223,\n",
       " 'hear': 224,\n",
       " 'hard': 225,\n",
       " 'wants': 226,\n",
       " 'speak': 227,\n",
       " 'yours': 228,\n",
       " 'show': 229,\n",
       " 'bought': 230,\n",
       " 'door': 231,\n",
       " 'as': 232,\n",
       " 'angry': 233,\n",
       " 'seen': 234,\n",
       " 'knows': 235,\n",
       " 'bring': 236,\n",
       " 'won': 237,\n",
       " 'live': 238,\n",
       " 'afraid': 239,\n",
       " 'everybody': 240,\n",
       " \"you'd\": 241,\n",
       " 'needs': 242,\n",
       " 'only': 243,\n",
       " 'everything': 244,\n",
       " 'turn': 245,\n",
       " 'looks': 246,\n",
       " 'died': 247,\n",
       " 'drunk': 248,\n",
       " 'idea': 249,\n",
       " \"who's\": 250,\n",
       " 'lie': 251,\n",
       " 'early': 252,\n",
       " 'watch': 253,\n",
       " 'believe': 254,\n",
       " 'something': 255,\n",
       " 'sleep': 256,\n",
       " 'doing': 257,\n",
       " 'way': 258,\n",
       " 'sit': 259,\n",
       " 'liked': 260,\n",
       " 'forget': 261,\n",
       " 'felt': 262,\n",
       " 'swim': 263,\n",
       " 'started': 264,\n",
       " 'took': 265,\n",
       " 'father': 266,\n",
       " 'hurry': 267,\n",
       " 'fix': 268,\n",
       " 'fast': 269,\n",
       " 'these': 270,\n",
       " 'long': 271,\n",
       " 'tv': 272,\n",
       " 'drive': 273,\n",
       " 'die': 274,\n",
       " 'almost': 275,\n",
       " 'friend': 276,\n",
       " 'pay': 277,\n",
       " 'soon': 278,\n",
       " 'coming': 279,\n",
       " 'scared': 280,\n",
       " 'plan': 281,\n",
       " 'anyone': 282,\n",
       " 'from': 283,\n",
       " \"we've\": 284,\n",
       " 'agree': 285,\n",
       " 'bed': 286,\n",
       " 'anything': 287,\n",
       " \"doesn't\": 288,\n",
       " 'looked': 289,\n",
       " 'young': 290,\n",
       " 'loves': 291,\n",
       " 'used': 292,\n",
       " 'free': 293,\n",
       " 'broke': 294,\n",
       " 'start': 295,\n",
       " 'often': 296,\n",
       " 'fun': 297,\n",
       " 'use': 298,\n",
       " 'dead': 299,\n",
       " 'easy': 300,\n",
       " 'yourself': 301,\n",
       " 'myself': 302,\n",
       " 'name': 303,\n",
       " 'rich': 304,\n",
       " 'stupid': 305,\n",
       " 'later': 306,\n",
       " 'bit': 307,\n",
       " 'run': 308,\n",
       " 'safe': 309,\n",
       " 'friends': 310,\n",
       " 'life': 311,\n",
       " 'key': 312,\n",
       " 'coffee': 313,\n",
       " 'listen': 314,\n",
       " 'nice': 315,\n",
       " 'sad': 316,\n",
       " 'walk': 317,\n",
       " 'hair': 318,\n",
       " 'wife': 319,\n",
       " 'cry': 320,\n",
       " 'met': 321,\n",
       " 'crazy': 322,\n",
       " \"she's\": 323,\n",
       " 'meet': 324,\n",
       " 'mad': 325,\n",
       " 'change': 326,\n",
       " 'which': 327,\n",
       " 'food': 328,\n",
       " 'remember': 329,\n",
       " 'tomorrow': 330,\n",
       " 'three': 331,\n",
       " 'true': 332,\n",
       " 'empty': 333,\n",
       " 'asked': 334,\n",
       " 'needed': 335,\n",
       " 'ran': 336,\n",
       " 'outside': 337,\n",
       " 'eyes': 338,\n",
       " 'bus': 339,\n",
       " 'kill': 340,\n",
       " 'two': 341,\n",
       " 'boy': 342,\n",
       " 'ate': 343,\n",
       " 'lying': 344,\n",
       " 'little': 345,\n",
       " 'answer': 346,\n",
       " 'tea': 347,\n",
       " 'first': 348,\n",
       " 'water': 349,\n",
       " 'son': 350,\n",
       " 'enough': 351,\n",
       " 'sorry': 352,\n",
       " 'cut': 353,\n",
       " 'any': 354,\n",
       " 'school': 355,\n",
       " 'lied': 356,\n",
       " 'last': 357,\n",
       " 'gone': 358,\n",
       " 'anybody': 359,\n",
       " 'lose': 360,\n",
       " 'great': 361,\n",
       " 'phone': 362,\n",
       " 'married': 363,\n",
       " 'rest': 364,\n",
       " 'even': 365,\n",
       " 'missed': 366,\n",
       " 'maybe': 367,\n",
       " 'red': 368,\n",
       " 'box': 369,\n",
       " \"there's\": 370,\n",
       " 'forgot': 371,\n",
       " 'helped': 372,\n",
       " 'hands': 373,\n",
       " 'wish': 374,\n",
       " 'hat': 375,\n",
       " 'lunch': 376,\n",
       " 'upset': 377,\n",
       " 'bag': 378,\n",
       " 'best': 379,\n",
       " 'hand': 380,\n",
       " 'beer': 381,\n",
       " 'kids': 382,\n",
       " 'paid': 383,\n",
       " 'mean': 384,\n",
       " 'lucky': 385,\n",
       " 'crying': 386,\n",
       " 'happen': 387,\n",
       " \"it'll\": 388,\n",
       " 'leaving': 389,\n",
       " 'kept': 390,\n",
       " 'strong': 391,\n",
       " 'understand': 392,\n",
       " 'write': 393,\n",
       " 'shoes': 394,\n",
       " 'else': 395,\n",
       " 'seems': 396,\n",
       " \"couldn't\": 397,\n",
       " 'getting': 398,\n",
       " 'hot': 399,\n",
       " 'working': 400,\n",
       " 'kiss': 401,\n",
       " 'eating': 402,\n",
       " 'killed': 403,\n",
       " 'pretty': 404,\n",
       " 'doctor': 405,\n",
       " 'pen': 406,\n",
       " 'hit': 407,\n",
       " 'shut': 408,\n",
       " 'inside': 409,\n",
       " 'serious': 410,\n",
       " 'close': 411,\n",
       " 'problem': 412,\n",
       " 'mother': 413,\n",
       " 'stand': 414,\n",
       " 'wine': 415,\n",
       " 'caught': 416,\n",
       " 'fat': 417,\n",
       " 'next': 418,\n",
       " 'works': 419,\n",
       " 'loved': 420,\n",
       " 'move': 421,\n",
       " 'fish': 422,\n",
       " 'people': 423,\n",
       " 'dinner': 424,\n",
       " 'care': 425,\n",
       " 'tall': 426,\n",
       " 'study': 427,\n",
       " 'if': 428,\n",
       " 'shy': 429,\n",
       " 'whose': 430,\n",
       " 'follow': 431,\n",
       " \"how's\": 432,\n",
       " 'cats': 433,\n",
       " 'became': 434,\n",
       " \"here's\": 435,\n",
       " 'many': 436,\n",
       " 'quite': 437,\n",
       " 'fault': 438,\n",
       " 'sign': 439,\n",
       " 'asleep': 440,\n",
       " 'milk': 441,\n",
       " 'changed': 442,\n",
       " 'fired': 443,\n",
       " 'wake': 444,\n",
       " 'fine': 445,\n",
       " 'thank': 446,\n",
       " 'careful': 447,\n",
       " 'someone': 448,\n",
       " 'hates': 449,\n",
       " 'touch': 450,\n",
       " 'shot': 451,\n",
       " 'keys': 452,\n",
       " \"one's\": 453,\n",
       " 'guess': 454,\n",
       " 'kind': 455,\n",
       " 'into': 456,\n",
       " 'broken': 457,\n",
       " 'thought': 458,\n",
       " 'being': 459,\n",
       " 'hold': 460,\n",
       " 'arrived': 461,\n",
       " 'began': 462,\n",
       " 'check': 463,\n",
       " 'worried': 464,\n",
       " 'thanks': 465,\n",
       " 'seem': 466,\n",
       " 'lives': 467,\n",
       " 'alive': 468,\n",
       " 'owe': 469,\n",
       " 'another': 470,\n",
       " 'watching': 471,\n",
       " 'place': 472,\n",
       " 'news': 473,\n",
       " 'happened': 474,\n",
       " 'talking': 475,\n",
       " 'teacher': 476,\n",
       " 'funny': 477,\n",
       " 'age': 478,\n",
       " 'blame': 479,\n",
       " 'dirty': 480,\n",
       " 'boss': 481,\n",
       " 'mind': 482,\n",
       " 'every': 483,\n",
       " 'lazy': 484,\n",
       " 'stopped': 485,\n",
       " 'dance': 486,\n",
       " 'fire': 487,\n",
       " 'around': 488,\n",
       " 'hey': 489,\n",
       " \"they'll\": 490,\n",
       " 'family': 491,\n",
       " 'dark': 492,\n",
       " 'face': 493,\n",
       " 'once': 494,\n",
       " 'ever': 495,\n",
       " \"wouldn't\": 496,\n",
       " 'save': 497,\n",
       " 'small': 498,\n",
       " 'smart': 499,\n",
       " 'tonight': 500,\n",
       " 'fell': 501,\n",
       " 'wrote': 502,\n",
       " 'break': 503,\n",
       " 'week': 504,\n",
       " 'choice': 505,\n",
       " 'waited': 506,\n",
       " 'worked': 507,\n",
       " 'sat': 508,\n",
       " 'singing': 509,\n",
       " 'brother': 510,\n",
       " 'cook': 511,\n",
       " 'night': 512,\n",
       " 'invited': 513,\n",
       " 'reading': 514,\n",
       " 'those': 515,\n",
       " 'awake': 516,\n",
       " 'girl': 517,\n",
       " 'laugh': 518,\n",
       " 'gun': 519,\n",
       " 'dogs': 520,\n",
       " 'send': 521,\n",
       " 'desk': 522,\n",
       " 'story': 523,\n",
       " 'weird': 524,\n",
       " 'yes': 525,\n",
       " 'wear': 526,\n",
       " 'says': 527,\n",
       " 'bored': 528,\n",
       " 'might': 529,\n",
       " 'joke': 530,\n",
       " 'own': 531,\n",
       " 'turned': 532,\n",
       " 'poor': 533,\n",
       " 'waiting': 534,\n",
       " 'books': 535,\n",
       " 'mom': 536,\n",
       " 'surprised': 537,\n",
       " 'hide': 538,\n",
       " 'calm': 539,\n",
       " 'warn': 540,\n",
       " 'stole': 541,\n",
       " 'quickly': 542,\n",
       " 'beautiful': 543,\n",
       " \"what'll\": 544,\n",
       " 'train': 545,\n",
       " 'than': 546,\n",
       " 'explain': 547,\n",
       " 'coat': 548,\n",
       " 'children': 549,\n",
       " 'fair': 550,\n",
       " 'far': 551,\n",
       " 'count': 552,\n",
       " 'smoke': 553,\n",
       " 'knife': 554,\n",
       " 'laughed': 555,\n",
       " 'strange': 556,\n",
       " 'sell': 557,\n",
       " 'secret': 558,\n",
       " 'yesterday': 559,\n",
       " 'clean': 560,\n",
       " 'monday': 561,\n",
       " 'horse': 562,\n",
       " 'brought': 563,\n",
       " \"haven't\": 564,\n",
       " 'catch': 565,\n",
       " 'seat': 566,\n",
       " 'thirsty': 567,\n",
       " 'list': 568,\n",
       " 'closed': 569,\n",
       " 'throw': 570,\n",
       " 'word': 571,\n",
       " 'heart': 572,\n",
       " 'wash': 573,\n",
       " 'pick': 574,\n",
       " 'guy': 575,\n",
       " 'quiet': 576,\n",
       " 'rain': 577,\n",
       " 'looking': 578,\n",
       " 'born': 579,\n",
       " 'quit': 580,\n",
       " 'guilty': 581,\n",
       " 'sleepy': 582,\n",
       " 'also': 583,\n",
       " 'black': 584,\n",
       " 'tie': 585,\n",
       " 'dream': 586,\n",
       " 'bike': 587,\n",
       " 'minute': 588,\n",
       " 'table': 589,\n",
       " 'such': 590,\n",
       " 'shirt': 591,\n",
       " 'hurts': 592,\n",
       " 'drank': 593,\n",
       " 'music': 594,\n",
       " 'finished': 595,\n",
       " 'real': 596,\n",
       " 'fight': 597,\n",
       " 'order': 598,\n",
       " 'together': 599,\n",
       " 'person': 600,\n",
       " 'light': 601,\n",
       " 'nervous': 602,\n",
       " 'boat': 603,\n",
       " 'followed': 604,\n",
       " 'apple': 605,\n",
       " 'weight': 606,\n",
       " \"weren't\": 607,\n",
       " 'slept': 608,\n",
       " 'wet': 609,\n",
       " 'perfect': 610,\n",
       " 'brave': 611,\n",
       " 'blue': 612,\n",
       " 'smell': 613,\n",
       " 'child': 614,\n",
       " 'running': 615,\n",
       " 'things': 616,\n",
       " 'cake': 617,\n",
       " 'picture': 618,\n",
       " 'vote': 619,\n",
       " 'jealous': 620,\n",
       " 'proud': 621,\n",
       " 'sister': 622,\n",
       " 'cool': 623,\n",
       " 'line': 624,\n",
       " 'rules': 625,\n",
       " 'sent': 626,\n",
       " 'laughing': 627,\n",
       " 'opened': 628,\n",
       " 'spoke': 629,\n",
       " 'woke': 630,\n",
       " 'then': 631,\n",
       " 'boring': 632,\n",
       " 'game': 633,\n",
       " 'believed': 634,\n",
       " 'their': 635,\n",
       " 'ill': 636,\n",
       " 'head': 637,\n",
       " 'worry': 638,\n",
       " 'finish': 639,\n",
       " 'song': 640,\n",
       " 'taxi': 641,\n",
       " 'baby': 642,\n",
       " 'same': 643,\n",
       " 'hour': 644,\n",
       " 'movie': 645,\n",
       " 'rude': 646,\n",
       " 'agreed': 647,\n",
       " 'weak': 648,\n",
       " 'short': 649,\n",
       " 'fixed': 650,\n",
       " 'white': 651,\n",
       " 'upstairs': 652,\n",
       " 'betrayed': 653,\n",
       " 'smile': 654,\n",
       " 'failed': 655,\n",
       " 'warm': 656,\n",
       " 'forgive': 657,\n",
       " 'or': 658,\n",
       " 'half': 659,\n",
       " 'afford': 660,\n",
       " 'slowly': 661,\n",
       " 'decided': 662,\n",
       " 'escape': 663,\n",
       " 'parents': 664,\n",
       " 'park': 665,\n",
       " 'truth': 666,\n",
       " 'cried': 667,\n",
       " 'enjoy': 668,\n",
       " 'liar': 669,\n",
       " 'saved': 670,\n",
       " 'fool': 671,\n",
       " 'canadian': 672,\n",
       " 'trusted': 673,\n",
       " 'tree': 674,\n",
       " 'himself': 675,\n",
       " 'drop': 676,\n",
       " 'smiled': 677,\n",
       " 'stayed': 678,\n",
       " 'after': 679,\n",
       " 'begin': 680,\n",
       " 'bread': 681,\n",
       " 'woman': 682,\n",
       " 'sleeping': 683,\n",
       " 'feeling': 684,\n",
       " 'lock': 685,\n",
       " 'full': 686,\n",
       " 'apologize': 687,\n",
       " 'duty': 688,\n",
       " 'meat': 689,\n",
       " 'kidding': 690,\n",
       " 'team': 691,\n",
       " 'draw': 692,\n",
       " 'lawyer': 693,\n",
       " 'smiling': 694,\n",
       " 'somebody': 695,\n",
       " 'tennis': 696,\n",
       " 'window': 697,\n",
       " 'trouble': 698,\n",
       " 'shocked': 699,\n",
       " 'kid': 700,\n",
       " 'finally': 701,\n",
       " 'near': 702,\n",
       " 'mistake': 703,\n",
       " 'chance': 704,\n",
       " 'clothes': 705,\n",
       " 'talked': 706,\n",
       " 'patient': 707,\n",
       " 'cheap': 708,\n",
       " 'pain': 709,\n",
       " 'arm': 710,\n",
       " 'dad': 711,\n",
       " 'glasses': 712,\n",
       " 'daughter': 713,\n",
       " 'dying': 714,\n",
       " 'ice': 715,\n",
       " 'walked': 716,\n",
       " 'snow': 717,\n",
       " 'advice': 718,\n",
       " 'fishing': 719,\n",
       " 'join': 720,\n",
       " 'hired': 721,\n",
       " 'god': 722,\n",
       " 'joking': 723,\n",
       " 'trying': 724,\n",
       " 'return': 725,\n",
       " 'pizza': 726,\n",
       " 'before': 727,\n",
       " 'playing': 728,\n",
       " 'letter': 729,\n",
       " 'slow': 730,\n",
       " 'ugly': 731,\n",
       " 'noticed': 732,\n",
       " 'men': 733,\n",
       " 'town': 734,\n",
       " 'bother': 735,\n",
       " 'warned': 736,\n",
       " 'feet': 737,\n",
       " 'english': 738,\n",
       " 'hug': 739,\n",
       " 'thirty': 740,\n",
       " 'luck': 741,\n",
       " 'cannot': 742,\n",
       " 'pencil': 743,\n",
       " 'office': 744,\n",
       " 'thing': 745,\n",
       " 'naive': 746,\n",
       " 'idiot': 747,\n",
       " 'famous': 748,\n",
       " 'lonely': 749,\n",
       " 'deserve': 750,\n",
       " 'honest': 751,\n",
       " 'regret': 752,\n",
       " 'raining': 753,\n",
       " 'without': 754,\n",
       " 'camera': 755,\n",
       " 'expect': 756,\n",
       " 'shoot': 757,\n",
       " 'marry': 758,\n",
       " 'obey': 759,\n",
       " 'normal': 760,\n",
       " 'unlucky': 761,\n",
       " 'locked': 762,\n",
       " 'student': 763,\n",
       " 'ball': 764,\n",
       " 'making': 765,\n",
       " \"could've\": 766,\n",
       " 'longer': 767,\n",
       " 'anymore': 768,\n",
       " 'stood': 769,\n",
       " 'retired': 770,\n",
       " 'wonderful': 771,\n",
       " 'cooking': 772,\n",
       " 'glass': 773,\n",
       " 'barely': 774,\n",
       " 'bicycle': 775,\n",
       " 'awful': 776,\n",
       " 'ignore': 777,\n",
       " 'eggs': 778,\n",
       " 'studying': 779,\n",
       " 'end': 780,\n",
       " 'writing': 781,\n",
       " 'heavy': 782,\n",
       " 'polite': 783,\n",
       " 'danger': 784,\n",
       " 'terrible': 785,\n",
       " 'drinking': 786,\n",
       " 'missing': 787,\n",
       " 'meant': 788,\n",
       " 'truck': 789,\n",
       " 'chair': 790,\n",
       " 'behind': 791,\n",
       " 'makes': 792,\n",
       " 'visit': 793,\n",
       " 'relax': 794,\n",
       " 'blind': 795,\n",
       " \"who'll\": 796,\n",
       " 'cruel': 797,\n",
       " 'green': 798,\n",
       " 'protect': 799,\n",
       " 'hated': 800,\n",
       " 'gift': 801,\n",
       " 'deal': 802,\n",
       " 'seldom': 803,\n",
       " 'watched': 804,\n",
       " 'smells': 805,\n",
       " 'simple': 806,\n",
       " 'borrow': 807,\n",
       " \"should've\": 808,\n",
       " 'under': 809,\n",
       " 'ours': 810,\n",
       " 'hero': 811,\n",
       " 'bet': 812,\n",
       " 'dancing': 813,\n",
       " 'kissed': 814,\n",
       " 'girls': 815,\n",
       " 'legs': 816,\n",
       " 'prefer': 817,\n",
       " 'hardly': 818,\n",
       " 'hiding': 819,\n",
       " 'golf': 820,\n",
       " 'correct': 821,\n",
       " 'party': 822,\n",
       " 'map': 823,\n",
       " 'women': 824,\n",
       " 'fighting': 825,\n",
       " 'shopping': 826,\n",
       " 'second': 827,\n",
       " 'six': 828,\n",
       " 'point': 829,\n",
       " 'deep': 830,\n",
       " 'choose': 831,\n",
       " 'dressed': 832,\n",
       " 'curious': 833,\n",
       " 'bath': 834,\n",
       " 'pale': 835,\n",
       " 'plans': 836,\n",
       " 'sugar': 837,\n",
       " 'rarely': 838,\n",
       " 'while': 839,\n",
       " 'few': 840,\n",
       " 'continue': 841,\n",
       " 'different': 842,\n",
       " 'listening': 843,\n",
       " 'message': 844,\n",
       " 'guys': 845,\n",
       " 'high': 846,\n",
       " 'fly': 847,\n",
       " 'promise': 848,\n",
       " 'soup': 849,\n",
       " 'washed': 850,\n",
       " 'learn': 851,\n",
       " 'grateful': 852,\n",
       " 'walking': 853,\n",
       " \"everyone's\": 854,\n",
       " 'convinced': 855,\n",
       " 'helping': 856,\n",
       " 'sounds': 857,\n",
       " 'ordered': 858,\n",
       " \"mary's\": 859,\n",
       " 'floor': 860,\n",
       " 'hi': 861,\n",
       " 'ahead': 862,\n",
       " 'passed': 863,\n",
       " 'teach': 864,\n",
       " 'risk': 865,\n",
       " 'bird': 866,\n",
       " 'ignored': 867,\n",
       " 'cup': 868,\n",
       " 'test': 869,\n",
       " 'badly': 870,\n",
       " 'having': 871,\n",
       " 'voice': 872,\n",
       " 'jacket': 873,\n",
       " 'australia': 874,\n",
       " 'probably': 875,\n",
       " 'question': 876,\n",
       " 'wearing': 877,\n",
       " 'moved': 878,\n",
       " 'voted': 879,\n",
       " 'doubt': 880,\n",
       " 'losing': 881,\n",
       " 'contact': 882,\n",
       " 'gas': 883,\n",
       " 'leg': 884,\n",
       " 'comes': 885,\n",
       " 'ride': 886,\n",
       " 'respect': 887,\n",
       " 'bank': 888,\n",
       " 'difficult': 889,\n",
       " 'police': 890,\n",
       " 'totally': 891,\n",
       " 'speaks': 892,\n",
       " 'eye': 893,\n",
       " 'cute': 894,\n",
       " 'sang': 895,\n",
       " 'excuse': 896,\n",
       " 'cheated': 897,\n",
       " 'rice': 898,\n",
       " 'closer': 899,\n",
       " 'selfish': 900,\n",
       " 'apples': 901,\n",
       " 'flowers': 902,\n",
       " 'survive': 903,\n",
       " 'prove': 904,\n",
       " 'exhausted': 905,\n",
       " 'stolen': 906,\n",
       " 'calling': 907,\n",
       " 'doors': 908,\n",
       " 'sound': 909,\n",
       " 'expensive': 910,\n",
       " 'but': 911,\n",
       " \"what're\": 912,\n",
       " 'pass': 913,\n",
       " 'step': 914,\n",
       " 'eaten': 915,\n",
       " 'drives': 916,\n",
       " 'fall': 917,\n",
       " 'unhappy': 918,\n",
       " 'war': 919,\n",
       " 'dress': 920,\n",
       " 'piano': 921,\n",
       " 'unfair': 922,\n",
       " 'rope': 923,\n",
       " 'radio': 924,\n",
       " 'taking': 925,\n",
       " 'other': 926,\n",
       " 'naked': 927,\n",
       " 'picky': 928,\n",
       " 'tough': 929,\n",
       " 'mess': 930,\n",
       " 'pleased': 931,\n",
       " 'touched': 932,\n",
       " 'wonder': 933,\n",
       " 'bleeding': 934,\n",
       " 'confused': 935,\n",
       " 'yelling': 936,\n",
       " 'expert': 937,\n",
       " 'nose': 938,\n",
       " 'fed': 939,\n",
       " 'soccer': 940,\n",
       " 'ring': 941,\n",
       " 'worth': 942,\n",
       " 'number': 943,\n",
       " 'plays': 944,\n",
       " 'travel': 945,\n",
       " 'showed': 946,\n",
       " 'refuse': 947,\n",
       " 'okay': 948,\n",
       " 'huge': 949,\n",
       " 'threw': 950,\n",
       " 'decide': 951,\n",
       " 'law': 952,\n",
       " 'refused': 953,\n",
       " 'ten': 954,\n",
       " 'class': 955,\n",
       " 'singer': 956,\n",
       " 'worse': 957,\n",
       " 'japanese': 958,\n",
       " 'baked': 959,\n",
       " 'important': 960,\n",
       " 'gate': 961,\n",
       " 'bell': 962,\n",
       " 'death': 963,\n",
       " 'arrested': 964,\n",
       " 'fever': 965,\n",
       " 'city': 966,\n",
       " 'punished': 967,\n",
       " 'dangerous': 968,\n",
       " \"shouldn't\": 969,\n",
       " 'following': 970,\n",
       " 'flight': 971,\n",
       " 'drove': 972,\n",
       " 'deaf': 973,\n",
       " 'helps': 974,\n",
       " 'odd': 975,\n",
       " 'clear': 976,\n",
       " 'older': 977,\n",
       " 'promised': 978,\n",
       " \"that'll\": 979,\n",
       " 'set': 980,\n",
       " 'shall': 981,\n",
       " 'surprise': 982,\n",
       " 'cab': 983,\n",
       " 'sun': 984,\n",
       " \"they've\": 985,\n",
       " 'sold': 986,\n",
       " 'gets': 987,\n",
       " 'year': 988,\n",
       " 'enemy': 989,\n",
       " 'vacation': 990,\n",
       " 'matters': 991,\n",
       " 'sweet': 992,\n",
       " 'cars': 993,\n",
       " 'useless': 994,\n",
       " 'winning': 995,\n",
       " 'cost': 996,\n",
       " 'silent': 997,\n",
       " 'nuts': 998,\n",
       " 'anyway': 999,\n",
       " 'add': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targ_lang.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "executionInfo": {
     "elapsed": 1230,
     "status": "ok",
     "timestamp": 1620147503117,
     "user": {
      "displayName": "Roman Zakharov",
      "photoUrl": "",
      "userId": "18255168926005506833"
     },
     "user_tz": -180
    },
    "id": "5buvMlnvyrFm"
   },
   "outputs": [],
   "source": [
    "def evaluate(inp_sentence):\n",
    "  start_token = [1]#[targ_lang.vocab_size]\n",
    "  end_token = [2] #[targ_lang.vocab_size + 1]\n",
    "  \n",
    "  # inp sentence is portuguese, hence adding the start and end token\n",
    "  sentence = preprocess_sentence(inp_sentence)\n",
    "  inp_sentence = [inp_lang.word_index[i] for i in sentence.split(' ')]  \n",
    "  \n",
    "  encoder_input = tf.expand_dims(inp_sentence, 0)\n",
    "  \n",
    "  # as the target is english, the first word to the transformer should be the\n",
    "  # english start token.\n",
    "  decoder_input = [1]\n",
    "  output = tf.expand_dims(decoder_input, 0)\n",
    "    \n",
    "  for i in range(max_length_targ):\n",
    "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(\n",
    "        encoder_input, output)\n",
    "  \n",
    "    # predictions.shape == (batch_size, seq_len, vocab_size)\n",
    "    predictions, attention_weights = transformer(encoder_input, \n",
    "                                                 output,\n",
    "                                                 False,\n",
    "                                                 enc_padding_mask,\n",
    "                                                 combined_mask,\n",
    "                                                 dec_padding_mask)\n",
    "    \n",
    "    # select the last word from the seq_len dimension\n",
    "    predictions = predictions[: ,-1:, :]  # (batch_size, 1, vocab_size)\n",
    "\n",
    "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "    \n",
    "    # return the result if the predicted_id is equal to the end token\n",
    "    if predicted_id == targ_lang.word_index['<end>']:\n",
    "      return tf.squeeze(output, axis=0), attention_weights\n",
    "    \n",
    "    # concatentate the predicted_id to the output which is given to the decoder\n",
    "    # as its input.\n",
    "    output = tf.concat([output, predicted_id], axis=-1)\n",
    "\n",
    "  return tf.squeeze(output, axis=0), attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "executionInfo": {
     "elapsed": 912,
     "status": "ok",
     "timestamp": 1620147503998,
     "user": {
      "displayName": "Roman Zakharov",
      "photoUrl": "",
      "userId": "18255168926005506833"
     },
     "user_tz": -180
    },
    "id": "CN-BV43FMBej"
   },
   "outputs": [],
   "source": [
    "def plot_attention_weights(attention, sentence, result, layer):\n",
    "  fig = plt.figure(figsize=(16, 8))\n",
    "  \n",
    "  sentence = [targ_lang.word_index[i] for i in sentence.split(' ')] \n",
    "  \n",
    "  attention = tf.squeeze(attention[layer], axis=0)\n",
    "  \n",
    "  for head in range(attention.shape[0]):\n",
    "    ax = fig.add_subplot(2, 4, head+1)\n",
    "    \n",
    "    # plot the attention weights\n",
    "    ax.matshow(attention[head][:-1, :], cmap='viridis')\n",
    "\n",
    "    fontdict = {'fontsize': 10}\n",
    "    \n",
    "    ax.set_xticks(range(len(sentence)+2))\n",
    "    ax.set_yticks(range(len(result)))\n",
    "    \n",
    "    ax.set_ylim(len(result)-1.5, -0.5)\n",
    "        \n",
    "    ax.set_xticklabels(\n",
    "        [inp_lang_tokenizer.word_index[i] for i in sentence.split(' ')], \n",
    "        fontdict=fontdict, rotation=90)\n",
    "    \n",
    "    ax.set_yticklabels([inp_lang.word_index([i]) for i in result \n",
    "                        if i < len(inp_lang.word_index)+1], \n",
    "                       fontdict=fontdict)\n",
    "    \n",
    "    ax.set_xlabel('Head {}'.format(head+1))\n",
    "  \n",
    "  plt.tight_layout()\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "executionInfo": {
     "elapsed": 1148,
     "status": "ok",
     "timestamp": 1620147505890,
     "user": {
      "displayName": "Roman Zakharov",
      "photoUrl": "",
      "userId": "18255168926005506833"
     },
     "user_tz": -180
    },
    "id": "lU2_yG_vBGza"
   },
   "outputs": [],
   "source": [
    "def translate(sentence, plot=''):\n",
    "  result, attention_weights = evaluate(sentence)\n",
    "  \n",
    "  predicted_sentence = ([targ_lang.index_word[i] for i in result.numpy()])  \n",
    "\n",
    "  print_sentence = ' '.join(predicted_sentence[1:])\n",
    "\n",
    "  print('Input: {}'.format(sentence))\n",
    "  print('Predicted translation: {}'.format(print_sentence))\n",
    "  \n",
    "  if plot:\n",
    "    plot_attention_weights(attention_weights, sentence, result, plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2327,
     "status": "ok",
     "timestamp": 1620147522147,
     "user": {
      "displayName": "Roman Zakharov",
      "photoUrl": "",
      "userId": "18255168926005506833"
     },
     "user_tz": -180
    },
    "id": "gmLTN9cgL3ed",
    "outputId": "9a540e15-b89b-4dc4-a334-c71e1311e60d"
   },
   "outputs": [],
   "source": [
    "#translate('он собирается домой', plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "id": "QHzndZ1xNHKn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: я не люблю когда ночью идет снег теплая погода гораздо лучше\n",
      "Predicted translation: i didn't like night .\n"
     ]
    }
   ],
   "source": [
    "translate('я не люблю когда ночью идет снег')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: я стараюсь проводить время с друзьями\n",
      "Predicted translation: i try for a walk with friends .\n"
     ]
    }
   ],
   "source": [
    "translate('я стараюсь проводить время с друзьями')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "s_qNSzzyaCbD"
   ],
   "name": "transformer_actual.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3.7 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0012934e6b3749a591c0392dc2e2b314": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2f60ce7062b948a49ce3532b8cecf167",
      "placeholder": "​",
      "style": "IPY_MODEL_7e4c8433608c4975bbc55974881da9b5",
      "value": " 208106/208106 [00:00&lt;00:00, 26.65 examples/s]"
     }
    },
    "00374d1cd271407bb5a34d85c66359fa": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a9535597d09d47ca8aa5e8cdd5e5c8cf",
       "IPY_MODEL_4a62ef4f82e649d088e6aa0d31664423"
      ],
      "layout": "IPY_MODEL_8aa57452be3a4b81b23daf2d0aa1b9e2"
     }
    },
    "052d2996a36f41a29406bdeebb3ae284": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "Generating splits...: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8bcfcbcefe5e4faaa8089744bbb275bf",
      "max": 3,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ec3857746eb24cefb38f3a3a9311d7b5",
      "value": 3
     }
    },
    "0899c6f886e3428e83708ef478b1c4f7": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "08da0fbbb5474965bcd9d740bdfc2b2c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0929e51476ec49c08ca867fa51c82169": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d4cad5549c234f83895ebcc00e578443",
      "placeholder": "​",
      "style": "IPY_MODEL_10c677f6e13042be975996bf12db8dda",
      "value": " 124/124 [00:07&lt;00:00, 15.65 MiB/s]"
     }
    },
    "0fea64ec323749aebe6a8a2fc7090dc4": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "10c677f6e13042be975996bf12db8dda": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1b582ef6b0e94dc2a191215c4e0b9ec1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "1bcc2844f8f7449bb01f530074c78714": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1d791c46665b4c139b682f4f9a52adb6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9e034d6901c1400fa6901962afa87302",
       "IPY_MODEL_e6822d59567e42b89f1c6f6e499b31c8"
      ],
      "layout": "IPY_MODEL_8a620df9673f42da96b823177273ba0c"
     }
    },
    "240deb3292a14d678ccd6359f2f8a3ad": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_da45c44f51184a60b1391a953d5d6f61",
      "placeholder": "​",
      "style": "IPY_MODEL_87e0121c4efa42e8b19de749434d13fc",
      "value": " 1/1 [00:07&lt;00:00,  7.98s/ url]"
     }
    },
    "2e8eb92b8651407ea9cefc54acd599b8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "2e9da43e859e41f589e9d0397a0ac007": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c7ced3b9e6cf4f1da5ca7a1a838870aa",
      "placeholder": "​",
      "style": "IPY_MODEL_f4cfb380b1b44db48eb2fcdb6e4bc988",
      "value": " 4805/4805 [00:01&lt;00:00, 3825.32 examples/s]"
     }
    },
    "2f60ce7062b948a49ce3532b8cecf167": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "39825e80c1ff4941bbb280a42a5c6a6a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "3f270f26d3de41d3a70f5bff0b513b3d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4761eff8c5dc4635a1258ecc50fcfa9c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "Generating validation examples...: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_08da0fbbb5474965bcd9d740bdfc2b2c",
      "max": 4805,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_39825e80c1ff4941bbb280a42a5c6a6a",
      "value": 4805
     }
    },
    "4a62ef4f82e649d088e6aa0d31664423": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1bcc2844f8f7449bb01f530074c78714",
      "placeholder": "​",
      "style": "IPY_MODEL_e7f0bc093be44dfd92df6a6d036ae58f",
      "value": " 5476/5476 [00:00&lt;00:00, 81471.69 examples/s]"
     }
    },
    "4cab8c601a3f4ebe890673c0de1a5368": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4fb90e63bce14f66b969726d3492f859": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_fb7db778d0964e6ebd24663cc4975af9",
       "IPY_MODEL_e2e10821d9de407ab7b9fa538d1353d7"
      ],
      "layout": "IPY_MODEL_ec42c26b440042bfbfe490714afd3b6a"
     }
    },
    "51f4844af9a9492a8ac9f37d08314dd5": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "56be0f61642941a3b1a1525b2f1408de": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_85aef33921f442738d31e61211e183e2",
       "IPY_MODEL_7e9b019bcc554e6cbd56c8253bcf2e14"
      ],
      "layout": "IPY_MODEL_696495599e364be9adfe61e699a1083b"
     }
    },
    "58bfcd64a99c4af58540ad943f74577a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Dl Size...: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3f270f26d3de41d3a70f5bff0b513b3d",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_dc7d7880f9a44dd5aef176b77da51920",
      "value": 1
     }
    },
    "5c6ca3211d8d4e9094a26efd3e61db81": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "Shuffling ted_hrlr_translate-train.tfrecord...: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8b78d674badb45218ae160610e1e50c6",
      "max": 208106,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1b582ef6b0e94dc2a191215c4e0b9ec1",
      "value": 208106
     }
    },
    "5cb4f9d7ef3049c9bd409ccd36bc5c64": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "696495599e364be9adfe61e699a1083b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6aea69d3de59471591c98cebdf7d9a2b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "731c155712d742b88920492c46dbfc82": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "797a294e68f842b485103a672a0c070b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "79e3f02510d141018771ad7355197d4d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "7e4c8433608c4975bbc55974881da9b5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7e9b019bcc554e6cbd56c8253bcf2e14": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_98fe582e02b54a5a92113c0d7be8d0d9",
      "placeholder": "​",
      "style": "IPY_MODEL_f341b51b94d74f67ab6e98a3608fec2e",
      "value": " 1/1 [00:07&lt;00:00,  7.85s/ file]"
     }
    },
    "8397a671776f48f3ab532a70c6e8a83b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "85aef33921f442738d31e61211e183e2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Extraction completed...: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9fc26ed55f2842cea1930c67486cadbb",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c2e29f53c62543e6b8a1f42b71774031",
      "value": 1
     }
    },
    "87e0121c4efa42e8b19de749434d13fc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "882bb37c23414128bf90a046a39015de": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "Generating test examples...: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5cb4f9d7ef3049c9bd409ccd36bc5c64",
      "max": 5476,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ad6d463c03d845858779551116f99c9c",
      "value": 5476
     }
    },
    "8931b1c317484f71ba0c82f2dcbf5f20": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8a620df9673f42da96b823177273ba0c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8aa57452be3a4b81b23daf2d0aa1b9e2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8b35ce822c274cabb501d3eb62a1122e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6aea69d3de59471591c98cebdf7d9a2b",
      "placeholder": "​",
      "style": "IPY_MODEL_c3a278dd5aa94b6abdd9e1f1f72eb8e2",
      "value": " 5476/5476 [00:01&lt;00:00, 3741.79 examples/s]"
     }
    },
    "8b78d674badb45218ae160610e1e50c6": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8bcfcbcefe5e4faaa8089744bbb275bf": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "90e4b59be9b54594b836ee17012d6eb2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9226f041bed94463a5b9ccd0197f93d8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "94bf7679826a4151988aa1dedfdb51e7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5c6ca3211d8d4e9094a26efd3e61db81",
       "IPY_MODEL_0012934e6b3749a591c0392dc2e2b314"
      ],
      "layout": "IPY_MODEL_d78bf48c66b94e4883753fac4f00c646"
     }
    },
    "98fe582e02b54a5a92113c0d7be8d0d9": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9962d60b732c4af7a6e9c375dbb0b3e1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4cab8c601a3f4ebe890673c0de1a5368",
      "placeholder": "​",
      "style": "IPY_MODEL_8397a671776f48f3ab532a70c6e8a83b",
      "value": " 3/3 [00:54&lt;00:00, 25.78s/ splits]"
     }
    },
    "9ada79de420748b9a5f0501e693226b4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "9c4f3636e1b949a58539f265a12340f5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Dl Completed...: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c2d6bafe522d45cdab64f48fcc3558c3",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_cf4a071f59a5427badb8244f82a01138",
      "value": 1
     }
    },
    "9e034d6901c1400fa6901962afa87302": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "Shuffling ted_hrlr_translate-validation.tfrecord...: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0fea64ec323749aebe6a8a2fc7090dc4",
      "max": 4805,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9ada79de420748b9a5f0501e693226b4",
      "value": 4805
     }
    },
    "9fc26ed55f2842cea1930c67486cadbb": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a372124a7d7545ba8790255bc99cb6e0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9c4f3636e1b949a58539f265a12340f5",
       "IPY_MODEL_240deb3292a14d678ccd6359f2f8a3ad"
      ],
      "layout": "IPY_MODEL_0899c6f886e3428e83708ef478b1c4f7"
     }
    },
    "a9535597d09d47ca8aa5e8cdd5e5c8cf": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "Shuffling ted_hrlr_translate-test.tfrecord...: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e118702c2b194c8b85700c625cd908f8",
      "max": 5476,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_79e3f02510d141018771ad7355197d4d",
      "value": 5476
     }
    },
    "ad6d463c03d845858779551116f99c9c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "b1345f4753eb48d0b422a1c4f7f3eb63": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4761eff8c5dc4635a1258ecc50fcfa9c",
       "IPY_MODEL_2e9da43e859e41f589e9d0397a0ac007"
      ],
      "layout": "IPY_MODEL_797a294e68f842b485103a672a0c070b"
     }
    },
    "c2d6bafe522d45cdab64f48fcc3558c3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c2e29f53c62543e6b8a1f42b71774031": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "c3a278dd5aa94b6abdd9e1f1f72eb8e2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c415f55fd6314ca988fbe7d57a46562c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c7ced3b9e6cf4f1da5ca7a1a838870aa": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cf4a071f59a5427badb8244f82a01138": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "d4cad5549c234f83895ebcc00e578443": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d6b125d137854fb69f4aae2515a9306c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_882bb37c23414128bf90a046a39015de",
       "IPY_MODEL_8b35ce822c274cabb501d3eb62a1122e"
      ],
      "layout": "IPY_MODEL_8931b1c317484f71ba0c82f2dcbf5f20"
     }
    },
    "d78bf48c66b94e4883753fac4f00c646": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "da45c44f51184a60b1391a953d5d6f61": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dc7d7880f9a44dd5aef176b77da51920": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "dcf85a9e1436437a9203a2ff13d6106f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e118702c2b194c8b85700c625cd908f8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e2e10821d9de407ab7b9fa538d1353d7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c415f55fd6314ca988fbe7d57a46562c",
      "placeholder": "​",
      "style": "IPY_MODEL_731c155712d742b88920492c46dbfc82",
      "value": " 208106/208106 [00:49&lt;00:00, 4236.10 examples/s]"
     }
    },
    "e6822d59567e42b89f1c6f6e499b31c8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9226f041bed94463a5b9ccd0197f93d8",
      "placeholder": "​",
      "style": "IPY_MODEL_90e4b59be9b54594b836ee17012d6eb2",
      "value": " 4805/4805 [00:00&lt;00:00, 71006.49 examples/s]"
     }
    },
    "e757a85126d54206a37d16d0daebcc33": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_052d2996a36f41a29406bdeebb3ae284",
       "IPY_MODEL_9962d60b732c4af7a6e9c375dbb0b3e1"
      ],
      "layout": "IPY_MODEL_dcf85a9e1436437a9203a2ff13d6106f"
     }
    },
    "e7ca0180e4bd4603b167dce5ea8aae62": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e7f0bc093be44dfd92df6a6d036ae58f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ec3857746eb24cefb38f3a3a9311d7b5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "ec42c26b440042bfbfe490714afd3b6a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f341b51b94d74f67ab6e98a3608fec2e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f38f2892703f48b3bc433614b0c7965f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_58bfcd64a99c4af58540ad943f74577a",
       "IPY_MODEL_0929e51476ec49c08ca867fa51c82169"
      ],
      "layout": "IPY_MODEL_51f4844af9a9492a8ac9f37d08314dd5"
     }
    },
    "f4cfb380b1b44db48eb2fcdb6e4bc988": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fb7db778d0964e6ebd24663cc4975af9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "Generating train examples...: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e7ca0180e4bd4603b167dce5ea8aae62",
      "max": 208106,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2e8eb92b8651407ea9cefc54acd599b8",
      "value": 208106
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
