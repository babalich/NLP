{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 8\n",
    "### На вебинаре мы говорили что долгое время CNN и RNN архитектуры были конурируещими выяснить какая архитектура больше подходит для задачи сантимент анализа на данных с вебинара"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from string import punctuation\n",
    "from stop_words import get_stop_words\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "import re\n",
    "import time\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.layers import Dense, Conv1D, LSTM, Flatten, Dropout, MaxPooling1D, Embedding,\\\n",
    "        GlobalMaxPool1D, BatchNormalization, Bidirectional, SimpleRNN, GRU, Masking\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "from tensorflow.keras import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('data/train.csv', index_col='id')\n",
    "df_val = pd.read_csv('data/val.csv', index_col='id')\n",
    "# test.csv без классов, здесь не пригодиться"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw = set(get_stop_words(\"ru\"))\n",
    "exclude = set(punctuation)\n",
    "morpher = MorphAnalyzer()\n",
    "\n",
    "def preprocess_text(txt):\n",
    "    txt = str(txt)\n",
    "    txt = \"\".join(c for c in txt if c not in exclude)\n",
    "    txt = txt.lower()\n",
    "    txt = re.sub(\"\\sне\", \"не\", txt)\n",
    "    txt = [morpher.parse(word)[0].normal_form for word in txt.split() if word not in sw]\n",
    "    return \" \".join(txt)\n",
    "\n",
    "df_train['text'] = df_train['text'].apply(preprocess_text)\n",
    "df_val['text'] = df_val['text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, 7.0138537585346095)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# считаем количество уникальных слов в отзыве (максимум, в среднем)\n",
    "df_train['text'].apply(lambda x: len(np.unique(str(x).split(' ')))).max(),\\\n",
    "df_train['text'].apply(lambda x: len(np.unique(str(x).split(' ')))).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_corpus_train = df_train['text'].values\n",
    "text_corpus_valid = df_val['text'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=None, \n",
    "                     filters='#$%&()*+-<=>@[\\\\]^_`{|}~\\t\\n',\n",
    "                     lower = False, split = ' ')\n",
    "tokenizer.fit_on_texts(text_corpus_train)\n",
    "\n",
    "sequences_train = tokenizer.texts_to_sequences(text_corpus_train)\n",
    "sequences_val = tokenizer.texts_to_sequences(text_corpus_valid)\n",
    "\n",
    "word_count = len(tokenizer.index_word) + 1\n",
    "training_length = max([len(i.split()) for i in text_corpus_train])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 609 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train = pad_sequences(sequences_train, maxlen=training_length)\n",
    "X_test = pad_sequences(sequences_val, maxlen=training_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train = utils.to_categorical(df_train['class'], num_classes=num_classes)\n",
    "# y_test = utils.to_categorical(df_val['class'], num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_train['class'].values\n",
    "y_test = df_val['class'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(258108, 27)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_count, training_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. построить свёрточные архитектуры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cnn = Sequential([\n",
    "    Embedding(input_dim=word_count, output_dim=64, input_length=training_length),\n",
    "    Conv1D(filters=128, kernel_size=3, padding='same', activation='relu'),\n",
    "    GlobalMaxPool1D(),\n",
    "    Dense(units=32, activation='relu'),\n",
    "    Dense(units=1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_cnn.compile(\n",
    "    optimizer='Adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "355/355 [==============================] - 80s 227ms/step - loss: 0.5374 - accuracy: 0.7179 - val_loss: 0.5023 - val_accuracy: 0.7531\n",
      "Epoch 2/5\n",
      "355/355 [==============================] - 79s 223ms/step - loss: 0.2750 - accuracy: 0.8865 - val_loss: 0.5935 - val_accuracy: 0.7400\n",
      "Epoch 3/5\n",
      "355/355 [==============================] - 83s 234ms/step - loss: 0.0916 - accuracy: 0.9668 - val_loss: 0.8172 - val_accuracy: 0.7246\n",
      "Epoch 4/5\n",
      "355/355 [==============================] - 81s 228ms/step - loss: 0.0336 - accuracy: 0.9891 - val_loss: 0.9860 - val_accuracy: 0.7221\n",
      "Epoch 5/5\n",
      "355/355 [==============================] - 81s 228ms/step - loss: 0.0131 - accuracy: 0.9963 - val_loss: 1.2449 - val_accuracy: 0.7211\n",
      "Wall time: 6min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history = model_cnn.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_test, y_test), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7211127281188965"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history['val_accuracy'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cnn = Sequential([\n",
    "    Embedding(input_dim=word_count, output_dim=32, input_length=training_length),\n",
    "    Conv1D(filters=128, kernel_size=5, padding='same', activation='relu'),\n",
    "    Conv1D(filters=64, kernel_size=5, padding='same', activation='relu'),\n",
    "    GlobalMaxPool1D(),\n",
    "    Dense(units=32, activation='relu'),\n",
    "    Dense(units=1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_cnn.compile(\n",
    "    optimizer='Adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "355/355 [==============================] - 42s 117ms/step - loss: 0.5380 - accuracy: 0.7143 - val_loss: 0.5104 - val_accuracy: 0.7450\n",
      "Epoch 2/5\n",
      "355/355 [==============================] - 41s 117ms/step - loss: 0.2695 - accuracy: 0.8884 - val_loss: 0.6011 - val_accuracy: 0.7371\n",
      "Epoch 3/5\n",
      "355/355 [==============================] - 41s 117ms/step - loss: 0.0961 - accuracy: 0.9655 - val_loss: 0.7904 - val_accuracy: 0.7279\n",
      "Epoch 4/5\n",
      "355/355 [==============================] - 42s 117ms/step - loss: 0.0430 - accuracy: 0.9852 - val_loss: 0.9811 - val_accuracy: 0.7206\n",
      "Epoch 5/5\n",
      "355/355 [==============================] - 42s 117ms/step - loss: 0.0200 - accuracy: 0.9935 - val_loss: 1.2219 - val_accuracy: 0.7160\n",
      "Wall time: 3min 28s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7160428762435913"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "history = model_cnn.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_test, y_test), verbose=1)\n",
    "history.history['val_accuracy'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cnn = Sequential([\n",
    "    Embedding(input_dim=word_count, output_dim=32, input_length=training_length),\n",
    "    Conv1D(filters=128, kernel_size=5, padding='same', activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Conv1D(filters=64, kernel_size=5, padding='same', activation='relu'),\n",
    "    GlobalMaxPool1D(),\n",
    "    Dense(units=32, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(units=1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_cnn.compile(\n",
    "    optimizer='Adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "355/355 [==============================] - 42s 118ms/step - loss: 0.5429 - accuracy: 0.7110 - val_loss: 0.6087 - val_accuracy: 0.7455\n",
      "Epoch 2/5\n",
      "355/355 [==============================] - 42s 119ms/step - loss: 0.2791 - accuracy: 0.8831 - val_loss: 0.5619 - val_accuracy: 0.7324\n",
      "Epoch 3/5\n",
      "355/355 [==============================] - 42s 119ms/step - loss: 0.0874 - accuracy: 0.9684 - val_loss: 0.8286 - val_accuracy: 0.7328\n",
      "Epoch 4/5\n",
      "355/355 [==============================] - 42s 119ms/step - loss: 0.0316 - accuracy: 0.9893 - val_loss: 1.2691 - val_accuracy: 0.7179\n",
      "Epoch 5/5\n",
      "355/355 [==============================] - 42s 119ms/step - loss: 0.0150 - accuracy: 0.9949 - val_loss: 1.4042 - val_accuracy: 0.7253\n",
      "Wall time: 3min 32s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7252568006515503"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "history = model_cnn.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_test, y_test), verbose=1)\n",
    "history.history['val_accuracy'][-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  2. построить различные архитектуры с RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rnn = Sequential([\n",
    "    Embedding(input_dim=word_count, output_dim=32, input_length=training_length, mask_zero=True),\n",
    "    Masking(mask_value=0.0),    \n",
    "    LSTM(32),\n",
    "    Dense(units=32, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(units=1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_rnn.compile(\n",
    "    optimizer='Adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "355/355 [==============================] - 42s 118ms/step - loss: 0.5492 - accuracy: 0.7117 - val_loss: 0.5094 - val_accuracy: 0.7432\n",
      "Epoch 2/5\n",
      "355/355 [==============================] - 41s 116ms/step - loss: 0.3238 - accuracy: 0.8636 - val_loss: 0.5828 - val_accuracy: 0.7363\n",
      "Epoch 3/5\n",
      "355/355 [==============================] - 41s 117ms/step - loss: 0.1628 - accuracy: 0.9382 - val_loss: 0.7281 - val_accuracy: 0.7280\n",
      "Epoch 4/5\n",
      "355/355 [==============================] - 42s 118ms/step - loss: 0.1026 - accuracy: 0.9626 - val_loss: 0.8945 - val_accuracy: 0.7237\n",
      "Epoch 5/5\n",
      "355/355 [==============================] - 42s 119ms/step - loss: 0.0755 - accuracy: 0.9720 - val_loss: 0.9665 - val_accuracy: 0.7186\n",
      "Wall time: 3min 33s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7185998558998108"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "history = model_rnn.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_test, y_test), verbose=1)\n",
    "history.history['val_accuracy'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rnn = Sequential([\n",
    "    Embedding(input_dim=word_count, output_dim=32, input_length=training_length, mask_zero=True),\n",
    "    Masking(mask_value=0.0),    \n",
    "    SimpleRNN(64),\n",
    "    Dense(units=32, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(units=1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_rnn.compile(\n",
    "    optimizer='Adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "355/355 [==============================] - 43s 121ms/step - loss: 0.5526 - accuracy: 0.7051 - val_loss: 0.5199 - val_accuracy: 0.7405\n",
      "Epoch 2/5\n",
      "355/355 [==============================] - 43s 121ms/step - loss: 0.2759 - accuracy: 0.8875 - val_loss: 0.5935 - val_accuracy: 0.7323\n",
      "Epoch 3/5\n",
      "355/355 [==============================] - 43s 120ms/step - loss: 0.0814 - accuracy: 0.9711 - val_loss: 0.8009 - val_accuracy: 0.7209\n",
      "Epoch 4/5\n",
      "355/355 [==============================] - 43s 120ms/step - loss: 0.0344 - accuracy: 0.9884 - val_loss: 0.9849 - val_accuracy: 0.7184\n",
      "Epoch 5/5\n",
      "355/355 [==============================] - 43s 122ms/step - loss: 0.0194 - accuracy: 0.9937 - val_loss: 1.1319 - val_accuracy: 0.7159\n",
      "Wall time: 3min 36s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7159106135368347"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "history = model_rnn.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_test, y_test), verbose=1)\n",
    "history.history['val_accuracy'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer gru will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    }
   ],
   "source": [
    "model_rnn = Sequential([\n",
    "    Embedding(input_dim=word_count, output_dim=32, input_length=training_length, mask_zero=True),\n",
    "    Masking(mask_value=0.0),    \n",
    "    GRU(64, recurrent_dropout=0.2),\n",
    "    Dense(units=32, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(units=1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_rnn.compile(\n",
    "    optimizer='Adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "355/355 [==============================] - 56s 157ms/step - loss: 0.5448 - accuracy: 0.7159 - val_loss: 0.5049 - val_accuracy: 0.7473\n",
      "Epoch 2/5\n",
      "355/355 [==============================] - 55s 156ms/step - loss: 0.3102 - accuracy: 0.8707 - val_loss: 0.5738 - val_accuracy: 0.7404\n",
      "Epoch 3/5\n",
      "355/355 [==============================] - 55s 154ms/step - loss: 0.1540 - accuracy: 0.9417 - val_loss: 0.7215 - val_accuracy: 0.7320\n",
      "Epoch 4/5\n",
      "355/355 [==============================] - 58s 162ms/step - loss: 0.0987 - accuracy: 0.9640 - val_loss: 0.9500 - val_accuracy: 0.7174\n",
      "Epoch 5/5\n",
      "355/355 [==============================] - 55s 155ms/step - loss: 0.0706 - accuracy: 0.9739 - val_loss: 0.9942 - val_accuracy: 0.7212\n",
      "Wall time: 4min 41s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7211568355560303"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "history = model_rnn.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_test, y_test), verbose=1)\n",
    "history.history['val_accuracy'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    }
   ],
   "source": [
    "model_rnn = Sequential([\n",
    "    Embedding(input_dim=word_count, output_dim=32, input_length=training_length, mask_zero=True),\n",
    "    Masking(mask_value=0.0),    \n",
    "    Bidirectional(LSTM(64, recurrent_dropout=0.2)),\n",
    "    Dense(units=32, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(units=1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_rnn.compile(\n",
    "    optimizer='Adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "355/355 [==============================] - 87s 245ms/step - loss: 0.5460 - accuracy: 0.7135 - val_loss: 0.4982 - val_accuracy: 0.7511\n",
      "Epoch 2/5\n",
      "355/355 [==============================] - 86s 243ms/step - loss: 0.3186 - accuracy: 0.8680 - val_loss: 0.5890 - val_accuracy: 0.7392\n",
      "Epoch 3/5\n",
      "355/355 [==============================] - 86s 241ms/step - loss: 0.1613 - accuracy: 0.9390 - val_loss: 0.7621 - val_accuracy: 0.7201\n",
      "Epoch 4/5\n",
      "355/355 [==============================] - 86s 242ms/step - loss: 0.1042 - accuracy: 0.9620 - val_loss: 0.8563 - val_accuracy: 0.7230\n",
      "Epoch 5/5\n",
      "355/355 [==============================] - 87s 245ms/step - loss: 0.0777 - accuracy: 0.9716 - val_loss: 0.9420 - val_accuracy: 0.7184\n",
      "Wall time: 7min 17s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7184234857559204"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "history = model_rnn.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_test, y_test), verbose=1)\n",
    "history.history['val_accuracy'][-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. попробовать использовать совместно CNN и RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    }
   ],
   "source": [
    "model_mix = Sequential([\n",
    "    Embedding(input_dim=word_count, output_dim=64, input_length=training_length),\n",
    "    Conv1D(filters=128, kernel_size=5, padding='same', activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Conv1D(filters=64, kernel_size=5, padding='same', activation='relu'),\n",
    "    Bidirectional(LSTM(64, recurrent_dropout=0.2)),\n",
    "    Dense(units=32, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(units=1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_mix.compile(\n",
    "    optimizer='Adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "355/355 [==============================] - 111s 312ms/step - loss: 0.5272 - accuracy: 0.7259 - val_loss: 0.5730 - val_accuracy: 0.7466\n",
      "Epoch 2/5\n",
      "355/355 [==============================] - 112s 314ms/step - loss: 0.2373 - accuracy: 0.9036 - val_loss: 0.5757 - val_accuracy: 0.7366\n",
      "Epoch 3/5\n",
      "355/355 [==============================] - 111s 313ms/step - loss: 0.0679 - accuracy: 0.9757 - val_loss: 0.8400 - val_accuracy: 0.7321\n",
      "Epoch 4/5\n",
      "355/355 [==============================] - 112s 316ms/step - loss: 0.0230 - accuracy: 0.9925 - val_loss: 1.2007 - val_accuracy: 0.7214\n",
      "Epoch 5/5\n",
      "355/355 [==============================] - 112s 317ms/step - loss: 0.0116 - accuracy: 0.9962 - val_loss: 1.5538 - val_accuracy: 0.7294\n",
      "Wall time: 9min 24s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7294008731842041"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "history = model_mix.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_test, y_test), verbose=1)\n",
    "history.history['val_accuracy'][-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. сделать выводы что получилось лучше"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все подходы показывают соизмеримый результат, около ~0.72. По крайней мере разница не настолько существенна, чтобы какой-то из методов отправлять на свалку. <br>\n",
    "Комбинирование методов усложняет модели, и соответственно время работы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
